<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Advanced ME-NeuralFMU Â· FMIFlux.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="FMIFlux.jl logo"/></a><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox" checked/><label class="tocitem" for="menuitem-2"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../simple_hybrid_CS/">Simple CS-NeuralFMU</a></li><li><a class="tocitem" href="../simple_hybrid_ME/">Simple ME-NeuralFMU</a></li><li class="is-active"><a class="tocitem" href>Advanced ME-NeuralFMU</a><ul class="internal"><li><a class="tocitem" href="#License"><span>License</span></a></li><li><a class="tocitem" href="#Motivation"><span>Motivation</span></a></li><li><a class="tocitem" href="#Introduction-to-the-example"><span>Introduction to the example</span></a></li><li><a class="tocitem" href="#Target-group"><span>Target group</span></a></li><li><a class="tocitem" href="#Other-formats"><span>Other formats</span></a></li><li><a class="tocitem" href="#Getting-started"><span>Getting started</span></a></li><li><a class="tocitem" href="#Code-section"><span>Code section</span></a></li><li><a class="tocitem" href="#NeuralFMU"><span>NeuralFMU</span></a></li></ul></li><li><a class="tocitem" href="../modelica_conference_2021/">Modelica Conference 2021</a></li></ul></li><li><a class="tocitem" href="../../library/">Library Functions</a></li><li><a class="tocitem" href="../../related/">Related Publication</a></li><li><a class="tocitem" href="../../contents/">Contents</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Advanced ME-NeuralFMU</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Advanced ME-NeuralFMU</a></li></ul></nav><div class="docs-right"><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Creation-and-training-of-ME-NeuralFMUs"><a class="docs-heading-anchor" href="#Creation-and-training-of-ME-NeuralFMUs">Creation and training of ME-NeuralFMUs</a><a id="Creation-and-training-of-ME-NeuralFMUs-1"></a><a class="docs-heading-anchor-permalink" href="#Creation-and-training-of-ME-NeuralFMUs" title="Permalink"></a></h1><p>Tutorial by Johannes Stoljar, Tobias Thummerer</p><h2 id="License"><a class="docs-heading-anchor" href="#License">License</a><a id="License-1"></a><a class="docs-heading-anchor-permalink" href="#License" title="Permalink"></a></h2><p>Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons, Johannes Stoljar</p><p>Licensed under the MIT license. See <a href="https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE">LICENSE</a> file in the project root for details.</p><h2 id="Motivation"><a class="docs-heading-anchor" href="#Motivation">Motivation</a><a id="Motivation-1"></a><a class="docs-heading-anchor-permalink" href="#Motivation" title="Permalink"></a></h2><p>The Julia Package <em>FMIFlux.jl</em> is motivated by the application of hybrid modeling. This package enables the user to integrate his simulation model between neural networks (NeuralFMU). For this, the simulation model must be exported as FMU (functional mock-up unit), which corresponds to a widely used standard. The big advantage of hybrid modeling with artificial neural networks is, that effects that are difficult to model (because they might be unknown) can be easily learned by the neural networks. For this purpose, the NeuralFMU is trained with measurement data containing the not modeled physical effect. The final product is a simulation model including the originally not modeled effects. Another big advantage of the NeuralFMU is that it works with little data, because the FMU already contains the characteristic functionality of the simulation and only the missing effects are added.</p><p>NeuralFMUs do not need to be as easy as in this example. Basically a NeuralFMU can combine different ANN topologies that manipulate any FMU-input (system state, system inputs, time) and any FMU-output (system state derivative, system outputs, other system variables). However, for this example a NeuralFMU topology as shown in the following picture is used.</p><p><img src="https://github.com/thummeto/FMIFlux.jl/blob/main/docs/src/examples/pics/NeuralFMU.svg?raw=true" alt="NeuralFMU.svg"/></p><p><em>NeuralFMU (ME) from</em> <a href="#Source">[1]</a>.</p><h2 id="Introduction-to-the-example"><a class="docs-heading-anchor" href="#Introduction-to-the-example">Introduction to the example</a><a id="Introduction-to-the-example-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction-to-the-example" title="Permalink"></a></h2><p>In this example, simplified modeling of a one-dimensional spring pendulum (without friction) is compared to a model of the same system that includes a nonlinear friction model. The FMU with the simplified model will be named <em>simpleFMU</em> in the following and the model with the friction will be named <em>realFMU</em>. At the beginning, the actual state of both simulations is shown, whereby clear deviations can be seen in the graphs. The <em>realFMU</em> serves as a reference graph. The <em>simpleFMU</em> is then integrated into a NeuralFMU architecture and a training of the entire network is performed. After the training the final state is compared again to the <em>realFMU</em>. It can be clearly seen that by using the NeuralFMU, learning of the friction process has taken place.  </p><h2 id="Target-group"><a class="docs-heading-anchor" href="#Target-group">Target group</a><a id="Target-group-1"></a><a class="docs-heading-anchor-permalink" href="#Target-group" title="Permalink"></a></h2><p>The example is primarily intended for users who work in the field of first principle and/or hybrid modeling and are further interested in hybrid model building. The example wants to show how simple it is to combine FMUs with machine learning and to illustrate the advantages of this approach.</p><h2 id="Other-formats"><a class="docs-heading-anchor" href="#Other-formats">Other formats</a><a id="Other-formats-1"></a><a class="docs-heading-anchor-permalink" href="#Other-formats" title="Permalink"></a></h2><p>Besides, this <a href="https://github.com/thummeto/FMIFlux.jl/blob/examples/examples/advanced_hybrid_ME.ipynb">Jupyter Notebook</a> there is also a <a href="https://github.com/thummeto/FMIFlux.jl/blob/examples/examples/advanced_hybrid_ME.jl">Julia file</a> with the same name, which contains only the code cells and for the documentation there is a <a href="https://github.com/thummeto/FMIFlux.jl/blob/examples/examples/advanced_hybrid_ME.md">Markdown file</a> corresponding to the notebook.  </p><h2 id="Getting-started"><a class="docs-heading-anchor" href="#Getting-started">Getting started</a><a id="Getting-started-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-started" title="Permalink"></a></h2><h3 id="Installation-prerequisites"><a class="docs-heading-anchor" href="#Installation-prerequisites">Installation prerequisites</a><a id="Installation-prerequisites-1"></a><a class="docs-heading-anchor-permalink" href="#Installation-prerequisites" title="Permalink"></a></h3><table><tr><th style="text-align: left"></th><th style="text-align: left">Description</th><th style="text-align: left">Command</th><th style="text-align: left">Alternative</th></tr><tr><td style="text-align: left">1.</td><td style="text-align: left">Enter Package Manager via</td><td style="text-align: left">]</td><td style="text-align: left"></td></tr><tr><td style="text-align: left">2.</td><td style="text-align: left">Install FMI via</td><td style="text-align: left">add FMI</td><td style="text-align: left">add &quot; https://github.com/ThummeTo/FMI.jl &quot;</td></tr><tr><td style="text-align: left">3.</td><td style="text-align: left">Install FMIFlux via</td><td style="text-align: left">add FMIFlux</td><td style="text-align: left">add &quot; https://github.com/ThummeTo/FMIFlux.jl &quot;</td></tr><tr><td style="text-align: left">4.</td><td style="text-align: left">Install FMIZoo via</td><td style="text-align: left">add FMIZoo</td><td style="text-align: left">add &quot; https://github.com/ThummeTo/FMIZoo.jl &quot;</td></tr><tr><td style="text-align: left">5.</td><td style="text-align: left">Install Flux via</td><td style="text-align: left">add Flux</td><td style="text-align: left"></td></tr><tr><td style="text-align: left">6.</td><td style="text-align: left">Install DifferentialEquations via</td><td style="text-align: left">add DifferentialEquations</td><td style="text-align: left"></td></tr><tr><td style="text-align: left">7.</td><td style="text-align: left">Install Plots via</td><td style="text-align: left">add Plots</td><td style="text-align: left"></td></tr><tr><td style="text-align: left">8.</td><td style="text-align: left">Install Random via</td><td style="text-align: left">add Random</td><td style="text-align: left"></td></tr></table><h2 id="Code-section"><a class="docs-heading-anchor" href="#Code-section">Code section</a><a id="Code-section-1"></a><a class="docs-heading-anchor-permalink" href="#Code-section" title="Permalink"></a></h2><p>To run the example, the previously installed packages must be included. </p><pre><code class="language-julia hljs"># imports
using FMI
using FMI.FMIImport: fmi2StringToValueReference, fmi2ValueReference, fmi2Real
using FMIFlux
using FMIZoo
using Flux
using DifferentialEquations: Tsit5
using Statistics: mean, std
import Plots

# set seed
import Random
Random.seed!(1234);</code></pre><p>After importing the packages, the path to the <em>Functional Mock-up Units</em> (FMUs) is set. The FMU is a model exported meeting the <em>Functional Mock-up Interface</em> (FMI) Standard. The FMI is a free standard (<a href="http://fmi-standard.org/">fmi-standard.org</a>) that defines a container and an interface to exchange dynamic models using a combination of XML files, binaries and C code zipped into a single file. </p><p>The object-orientated structure of the <em>SpringPendulum1D</em> (<em>simpleFMU</em>) can be seen in the following graphic and corresponds to a simple modeling.</p><p><img src="https://github.com/thummeto/FMIFlux.jl/blob/main/docs/src/examples/pics/SpringPendulum1D.svg?raw=true" alt="svg"/></p><p>In contrast, the model <em>SpringFrictionPendulum1D</em> (<em>realFMU</em>) is somewhat more accurate, because it includes a friction component. </p><p><img src="https://github.com/thummeto/FMIFlux.jl/blob/main/docs/src/examples/pics/SpringFrictionPendulum1D.svg?raw=true" alt="svg"/></p><p>Next, the start time and end time of the simulation are set. Finally, a step size is specified to store the results of the simulation at these time steps.</p><pre><code class="language-julia hljs">tStart = 0.0
tStep = 0.1
tStop = 5.0
tSave = collect(tStart:tStep:tStop)</code></pre><pre><code class="nohighlight hljs">51-element Vector{Float64}:
 0.0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1.0
 1.1
 1.2
 â®
 3.9
 4.0
 4.1
 4.2
 4.3
 4.4
 4.5
 4.6
 4.7
 4.8
 4.9
 5.0</code></pre><h3 id="RealFMU"><a class="docs-heading-anchor" href="#RealFMU">RealFMU</a><a id="RealFMU-1"></a><a class="docs-heading-anchor-permalink" href="#RealFMU" title="Permalink"></a></h3><p>In the next lines of code the FMU of the <em>realFMU</em> model from <em>FMIZoo.jl</em> is loaded and the information about the FMU is shown.</p><pre><code class="language-julia hljs">realFMU = fmiLoad(&quot;SpringFrictionPendulum1D&quot;, &quot;Dymola&quot;, &quot;2022x&quot;)
fmiInfo(realFMU)</code></pre><pre><code class="nohighlight hljs">â Info: fmi2Unzip(...): Successfully unzipped 153 files at `/tmp/fmijl_sdNIjA/SpringFrictionPendulum1D`.
â @ FMIImport /home/runner/.julia/packages/FMIImport/g4GUl/src/FMI2_ext.jl:76
â Info: fmi2Load(...): FMU resources location is `file:////tmp/fmijl_sdNIjA/SpringFrictionPendulum1D/resources`
â @ FMIImport /home/runner/.julia/packages/FMIImport/g4GUl/src/FMI2_ext.jl:192
â Info: fmi2Load(...): FMU supports both CS and ME, using CS as default if nothing specified.
â @ FMIImport /home/runner/.julia/packages/FMIImport/g4GUl/src/FMI2_ext.jl:195


#################### Begin information for FMU ####################
	Model name:			SpringFrictionPendulum1D
	FMI-Version:			2.0
	GUID:				{2e178ad3-5e9b-48ec-a7b2-baa5669efc0c}
	Generation tool:		Dymola Version 2022x (64-bit), 2021-10-08
	Generation time:		2022-05-19T06:54:12Z
	Var. naming conv.:		structured
	Event indicators:		24
	Inputs:				0
	Outputs:			0
	States:				2
		33554432 [&quot;mass.s&quot;]
		33554433 [&quot;mass.v&quot;, &quot;mass.v_relfric&quot;]
	Supports Co-Simulation:		true
		Model identifier:	SpringFrictionPendulum1D
		Get/Set State:		true
		Serialize State:	true
		Dir. Derivatives:	true
		Var. com. steps:	true
		Input interpol.:	true
		Max order out. der.:	1
	Supports Model-Exchange:	true
		Model identifier:	SpringFrictionPendulum1D
		Get/Set State:		true
		Serialize State:	true
		Dir. Derivatives:	true
##################### End information for FMU #####################</code></pre><p>In the function fmiSimulate() the <em>realFMU</em> is simulated, still specifying the start and end time, the parameters and which variables are recorded. After the simulation is finished the result of the <em>realFMU</em> can be plotted. This plot also serves as a reference for the other model (<em>simpleFMU</em>).</p><pre><code class="language-julia hljs">vrs = [&quot;mass.s&quot;, &quot;mass.v&quot;, &quot;mass.a&quot;, &quot;mass.f&quot;]
realSimData = fmiSimulate(realFMU, tStart, tStop; recordValues=vrs, saveat=tSave)
fmiPlot(realSimData)</code></pre><p><img src="../advanced_hybrid_ME_files/advanced_hybrid_ME_9_0.svg" alt="svg"/></p><p>The data from the simulation of the <em>realFMU</em>, are divided into position and velocity data. These data will be needed later. </p><pre><code class="language-julia hljs">posReal = fmi2GetSolutionValue(realSimData, &quot;mass.s&quot;)
velReal = fmi2GetSolutionValue(realSimData, &quot;mass.v&quot;)</code></pre><pre><code class="nohighlight hljs">51-element Vector{Float64}:
  0.0
  0.432852398300982
  0.8401743918610578
  1.1702254881462497
  1.3861768532456016
  1.4649609400224617
  1.397962181945595
  1.1917483098990418
  0.8657325133644009
  0.44821918384886916
 -0.02200493896693855
 -0.380560845401747
 -0.7172068753289351
  â®
 -0.19353187721088116
  0.021605187634145845
  0.12911473439606144
  0.2315130895115627
  0.31667721272388255
  0.37417576531479746
  0.3964197153211615
  0.3795927497483354
  0.3235539803194403
  0.2317738499958648
  0.11061350893737848
 -1.0008118292437196e-10</code></pre><p>The FMU hase two states: The first state is the position of the mass and the second state is the velocity. The initial position of the mass is initilized with <span>$0.5ð$</span>. The initial velocity of the mass is initialized with <span>$0\frac{m}{s}$</span>. </p><pre><code class="language-julia hljs">xâ = [posReal[1], velReal[1]]</code></pre><pre><code class="nohighlight hljs">2-element Vector{Float64}:
 0.5
 0.0</code></pre><p>After extracting the data, the FMU is cleaned-up.</p><pre><code class="language-julia hljs">fmiUnload(realFMU)</code></pre><h3 id="SimpleFMU"><a class="docs-heading-anchor" href="#SimpleFMU">SimpleFMU</a><a id="SimpleFMU-1"></a><a class="docs-heading-anchor-permalink" href="#SimpleFMU" title="Permalink"></a></h3><p>The following lines load, simulate and plot the <em>simpleFMU</em> just like the <em>realFMU</em>. The differences between both systems can be clearly seen from the plots. In the plot for the <em>realFMU</em> it can be seen that the oscillation continues to decrease due to the effect of the friction. If you simulate long enough, the oscillation would come to a standstill in a certain time. The oscillation in the <em>simpleFMU</em> behaves differently, since the friction was not taken into account here. The oscillation in this model would continue to infinity with the same oscillation amplitude. From this observation the desire of an improvement of this model arises.     </p><pre><code class="language-julia hljs">simpleFMU = fmiLoad(&quot;SpringPendulum1D&quot;, &quot;Dymola&quot;, &quot;2022x&quot;)
fmiInfo(simpleFMU)

vrs = [&quot;mass.s&quot;, &quot;mass.v&quot;, &quot;mass.a&quot;]
simpleSimData = fmiSimulate(simpleFMU, tStart, tStop; recordValues=vrs, saveat=tSave)
fmiPlot(simpleSimData)</code></pre><pre><code class="nohighlight hljs">#################### Begin information for FMU ####################
	Model name:			SpringPendulum1D
	FMI-Version:			2.0
	GUID:				{fc15d8c4-758b-48e6-b00e-5bf47b8b14e5}
	Generation tool:		Dymola Version 2022x (64-bit), 2021-10-08
	Generation time:		2022-05-19T06:54:23Z
	Var. naming conv.:		structured
	Event indicators:		0
	Inputs:				0
	Outputs:			0
	States:				2
		33554432 [&quot;mass.s&quot;]
		33554433 [&quot;mass.v&quot;]
	Supports Co-Simulation:		true
		Model identifier:	SpringPendulum1D
		Get/Set State:		true
		Serialize State:	true
		Dir. Derivatives:	true
		Var. com. steps:	true
		Input interpol.:	true
		Max order out. der.:	1
	Supports Model-Exchange:	true
		Model identifier:	SpringPendulum1D
		Get/Set State:		true
		Serialize State:	true
		Dir. Derivatives:	true
##################### End information for FMU #####################


â Info: fmi2Unzip(...): Successfully unzipped 153 files at `/tmp/fmijl_kNkiOz/SpringPendulum1D`.
â @ FMIImport /home/runner/.julia/packages/FMIImport/g4GUl/src/FMI2_ext.jl:76
â Info: fmi2Load(...): FMU resources location is `file:////tmp/fmijl_kNkiOz/SpringPendulum1D/resources`
â @ FMIImport /home/runner/.julia/packages/FMIImport/g4GUl/src/FMI2_ext.jl:192
â Info: fmi2Load(...): FMU supports both CS and ME, using CS as default if nothing specified.
â @ FMIImport /home/runner/.julia/packages/FMIImport/g4GUl/src/FMI2_ext.jl:195</code></pre><p><img src="../advanced_hybrid_ME_files/advanced_hybrid_ME_17_2.svg" alt="svg"/></p><p>The data from the simulation of the <em>simpleFMU</em>, are divided into position and velocity data. These data will be needed later to plot the results. </p><pre><code class="language-julia hljs">posSimple = fmi2GetSolutionValue(simpleSimData, &quot;mass.s&quot;)
velSimple = fmi2GetSolutionValue(simpleSimData, &quot;mass.v&quot;)</code></pre><pre><code class="nohighlight hljs">51-element Vector{Float64}:
  0.0
  0.5899802196326744
  1.1216144329248279
  1.542195620662035
  1.810172737052044
  1.8985676043018223
  1.7983499725303025
  1.5196216961327944
  1.0900958349841172
  0.5523346620786151
 -0.040261546913912205
 -0.6289411637396933
 -1.1552195220019175
  â®
 -0.43297835247721894
  0.1644403574466082
  0.7455652283389829
  1.2527659117804728
  1.6356623403044424
  1.8562751551367387
  1.8926761758140136
  1.7412508664862896
  1.417004896988811
  0.9521088322603164
  0.3926807653512623
 -0.20575332570677826</code></pre><h2 id="NeuralFMU"><a class="docs-heading-anchor" href="#NeuralFMU">NeuralFMU</a><a id="NeuralFMU-1"></a><a class="docs-heading-anchor-permalink" href="#NeuralFMU" title="Permalink"></a></h2><h4 id="Loss-function-with-growing-horizon"><a class="docs-heading-anchor" href="#Loss-function-with-growing-horizon">Loss function with growing horizon</a><a id="Loss-function-with-growing-horizon-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-function-with-growing-horizon" title="Permalink"></a></h4><p>In order to train our model, a loss function must be implemented. The solver of the NeuralFMU can calculate the gradient of the loss function. The gradient descent is needed to adjust the weights in the neural network so that the sum of the error is reduced and the model becomes more accurate.</p><p>The loss function in this implementation consists of the mean squared error (mse) from the real position of the <em>realFMU</em> simulation (posReal) and the position data of the network (posNet). $ mse = \frac{1}{n} \sum\limits_{i=0}^n (posReal[i] - posNet[i])^2 $ A growing horizon is applied, whereby the horizon only goes over the first five values. For this horizon the mse is calculated.</p><pre><code class="language-julia hljs"># loss function for training
global horizon = 5
function lossSum()
    global posReal, neuralFMU, horizon
    solution = neuralFMU(xâ, tStart)

    posNet = fmi2GetSolutionState(solution, 1; isIndex=true)
    
    horizon = min(length(posNet), horizon)

    Flux.Losses.mse(posReal[1:horizon], posNet[1:horizon])
end</code></pre><pre><code class="nohighlight hljs">lossSum (generic function with 1 method)</code></pre><h4 id="Function-for-plotting"><a class="docs-heading-anchor" href="#Function-for-plotting">Function for plotting</a><a id="Function-for-plotting-1"></a><a class="docs-heading-anchor-permalink" href="#Function-for-plotting" title="Permalink"></a></h4><p>In this section the function for plotting is defined. The function <code>plotResults()</code> creates a new figure object. In dieses figure objekt werden dann die aktuellsten Ergebnisse von <em>realFMU</em>, <em>simpleFMU</em> und <em>neuralFMU</em> gegenÃ¼bergestellt. </p><p>To output the loss in certain time intervals, a callback is implemented as a function in the following. Here a counter is incremented, every twentieth pass the loss function is called and the average error is printed out.</p><pre><code class="language-julia hljs">function plotResults()
    global neuralFMU
    solution = neuralFMU(xâ, tStart)

    posNeural = fmi2GetSolutionState(solution, 1; isIndex=true)
    time = fmi2GetSolutionTime(solution)
    
    fig = Plots.plot(xlabel=&quot;t [s]&quot;, ylabel=&quot;mass position [m]&quot;, linewidth=2,
                     xtickfontsize=12, ytickfontsize=12,
                     xguidefontsize=12, yguidefontsize=12,
                     legendfontsize=8, legend=:topright)
    
    Plots.plot!(fig, tSave, posSimple, label=&quot;SimpleFMU&quot;, linewidth=2)
    Plots.plot!(fig, tSave, posReal, label=&quot;RealFMU&quot;, linewidth=2)
    Plots.plot!(fig, time, posNeural, label=&quot;NeuralFMU&quot;, linewidth=2)
    fig
end</code></pre><pre><code class="nohighlight hljs">plotResults (generic function with 1 method)</code></pre><h4 id="Callback"><a class="docs-heading-anchor" href="#Callback">Callback</a><a id="Callback-1"></a><a class="docs-heading-anchor-permalink" href="#Callback" title="Permalink"></a></h4><p>To output the loss in certain time intervals, a callback is implemented as a function in the following. Here a counter is incremented, every twentieth pass the loss function is called and the average error is printed out.  As soon as a limit value (in this example <code>0.1</code>) is undershot, the horizon is extended by the next two values.</p><pre><code class="language-julia hljs"># callback function for training
global counter = 0
function callb()
    global counter, horizon 
    counter += 1
   
    if counter % 20 == 1
        avgLoss = lossSum()
        @info &quot;   Loss [$counter] for horizon $horizon : $(round(avgLoss, digits=5))   
        Avg displacement in data: $(round(sqrt(avgLoss), digits=5))&quot;
        
        if avgLoss &lt;= 0.01
            horizon += 2
        end
   
        # fig = plotResults()
        # println(&quot;Figure update.&quot;)
        # display(fig)
    end
end
</code></pre><pre><code class="nohighlight hljs">callb (generic function with 1 method)</code></pre><h4 id="Pre-and-Postprocessing"><a class="docs-heading-anchor" href="#Pre-and-Postprocessing">Pre- and Postprocessing</a><a id="Pre-and-Postprocessing-1"></a><a class="docs-heading-anchor-permalink" href="#Pre-and-Postprocessing" title="Permalink"></a></h4><p>In the following functions for pre-processing and post-processing are defined. The function <code>preProc</code> is normalized the input values to mean of zero and a standard deviation of one. </p><pre><code class="language-julia hljs">global meanVal = 0.0
global stdVal = 0.0

function preProc!(data)
    global meanVal, stdVal

    meanVal = mean(data)
    stdVal = std(data)
    
    (data .- meanVal) ./ stdVal    
end </code></pre><pre><code class="nohighlight hljs">preProc! (generic function with 1 method)</code></pre><p>For post-processing, the previous normalization is undone by applying the calculation steps in reverse order.</p><pre><code class="language-julia hljs">function postProc!(data)
    global meanVal, stdVal
    
    (data .* stdVal) .+ meanVal
end </code></pre><pre><code class="nohighlight hljs">postProc! (generic function with 1 method)</code></pre><h4 id="Structure-of-the-NeuralFMU"><a class="docs-heading-anchor" href="#Structure-of-the-NeuralFMU">Structure of the NeuralFMU</a><a id="Structure-of-the-NeuralFMU-1"></a><a class="docs-heading-anchor-permalink" href="#Structure-of-the-NeuralFMU" title="Permalink"></a></h4><p>In the following, the topology of the NeuralFMU is constructed. It consists of an input layer, which then leads into the <em>simpleFMU</em> model. The ME-FMU computes the state derivatives for a given system state. Following the <em>simpleFMU</em> is a dense layer that has exactly as many inputs as the model has states (and therefore state derivatives). The output of this layer consists of 16 output nodes and a <em>tanh</em> activation function. The next layer has 16 input and output nodes with the same activation function. The last layer is again a dense layer with 16 input nodes and the number of states as outputs. Here, it is important that no <em>tanh</em>-activation function follows, because otherwise the pendulums state values would be limited to the interval <span>$[-1;1]$</span>.</p><pre><code class="language-julia hljs"># NeuralFMU setup
numStates = fmiGetNumberOfStates(simpleFMU)
additionalVRs = [fmi2StringToValueReference(simpleFMU, &quot;mass.m&quot;)]
numAdditionalVRs = length(additionalVRs)

net = Chain(
    inputs -&gt; fmiEvaluateME(simpleFMU, inputs, -1.0, zeros(fmi2ValueReference, 0), 
                            zeros(fmi2Real, 0), additionalVRs),
    preProc!,
    Dense(numStates+numAdditionalVRs, 16, tanh),
    postProc!,
    preProc!,
    Dense(16, 16, tanh),
    postProc!,
    preProc!,
    Dense(16, numStates),
    postProc!,
)</code></pre><pre><code class="nohighlight hljs">Chain(
  var&quot;#1#2&quot;(),
  preProc!,
  Dense(3 =&gt; 16, tanh),                 [90m# 64 parameters[39m
  postProc!,
  preProc!,
  Dense(16 =&gt; 16, tanh),                [90m# 272 parameters[39m
  postProc!,
  preProc!,
  Dense(16 =&gt; 2),                       [90m# 34 parameters[39m
  postProc!,
) [90m                  # Total: 6 arrays, [39m370 parameters, 1.820 KiB.</code></pre><h4 id="Definition-of-the-NeuralFMU"><a class="docs-heading-anchor" href="#Definition-of-the-NeuralFMU">Definition of the NeuralFMU</a><a id="Definition-of-the-NeuralFMU-1"></a><a class="docs-heading-anchor-permalink" href="#Definition-of-the-NeuralFMU" title="Permalink"></a></h4><p>The instantiation of the ME-NeuralFMU is done as a one-liner. The FMU (<em>simpleFMU</em>), the structure of the network <code>net</code>, start <code>tStart</code> and end time <code>tStop</code>, the numerical solver <code>Tsit5()</code> and the time steps <code>tSave</code> for saving are specified.</p><pre><code class="language-julia hljs">neuralFMU = ME_NeuralFMU(simpleFMU, net, (tStart, tStop), Tsit5(); saveat=tSave);</code></pre><h4 id="Plot-before-training"><a class="docs-heading-anchor" href="#Plot-before-training">Plot before training</a><a id="Plot-before-training-1"></a><a class="docs-heading-anchor-permalink" href="#Plot-before-training" title="Permalink"></a></h4><p>Here the state trajectory of the <em>simpleFMU</em> is recorded. Doesn&#39;t really look like a pendulum yet, but the system is random initialized by default. In the plots later on, the effect of learning can be seen.</p><pre><code class="language-julia hljs">solutionBefore = neuralFMU(xâ, tStart)
fmiPlot(solutionBefore)</code></pre><p><img src="../advanced_hybrid_ME_files/advanced_hybrid_ME_35_0.svg" alt="svg"/></p><h4 id="Training-of-the-NeuralFMU"><a class="docs-heading-anchor" href="#Training-of-the-NeuralFMU">Training of the NeuralFMU</a><a id="Training-of-the-NeuralFMU-1"></a><a class="docs-heading-anchor-permalink" href="#Training-of-the-NeuralFMU" title="Permalink"></a></h4><p>For the training of the NeuralFMU the parameters are extracted. The known ADAM optimizer for minimizing the gradient descent is used as further passing parameters. In addition, the previously defined loss and callback function, as well as the number of epochs are passed.</p><pre><code class="language-julia hljs"># train
paramsNet = Flux.params(neuralFMU)

optim = ADAM()
Flux.train!(lossSum, paramsNet, Iterators.repeated((), 1000), optim; cb=callb) </code></pre><pre><code class="nohighlight hljs">â Info:    Loss [1] for horizon 5 : 0.06331   
â         Avg displacement in data: 0.25162
â @ Main In[12]:9
â Info:    Loss [21] for horizon 5 : 0.00542   
â         Avg displacement in data: 0.0736
â @ Main In[12]:9
â Info:    Loss [41] for horizon 7 : 0.00256   
â         Avg displacement in data: 0.05062
â @ Main In[12]:9
â Info:    Loss [61] for horizon 9 : 0.00296   
â         Avg displacement in data: 0.0544
â @ Main In[12]:9
â Info:    Loss [81] for horizon 11 : 0.00074   
â         Avg displacement in data: 0.02723
â @ Main In[12]:9
â Info:    Loss [101] for horizon 13 : 0.00287   
â         Avg displacement in data: 0.05356
â @ Main In[12]:9
â Info:    Loss [121] for horizon 15 : 0.00708   
â         Avg displacement in data: 0.08416
â @ Main In[12]:9
â Info:    Loss [141] for horizon 17 : 0.01529   
â         Avg displacement in data: 0.12367
â @ Main In[12]:9
â Info:    Loss [161] for horizon 17 : 0.0085   
â         Avg displacement in data: 0.09222
â @ Main In[12]:9
â Info:    Loss [181] for horizon 19 : 0.01067   
â         Avg displacement in data: 0.1033
â @ Main In[12]:9
â Info:    Loss [201] for horizon 19 : 0.00554   
â         Avg displacement in data: 0.07445
â @ Main In[12]:9
â Info:    Loss [221] for horizon 21 : 0.0034   
â         Avg displacement in data: 0.0583
â @ Main In[12]:9
â Info:    Loss [241] for horizon 23 : 0.00149   
â         Avg displacement in data: 0.0386
â @ Main In[12]:9
â Info:    Loss [261] for horizon 25 : 0.00069   
â         Avg displacement in data: 0.0262
â @ Main In[12]:9
â Info:    Loss [281] for horizon 27 : 0.00045   
â         Avg displacement in data: 0.02132
â @ Main In[12]:9
â Info:    Loss [301] for horizon 29 : 0.00042   
â         Avg displacement in data: 0.02054
â @ Main In[12]:9
â Info:    Loss [321] for horizon 31 : 0.00047   
â         Avg displacement in data: 0.02177
â @ Main In[12]:9
â Info:    Loss [341] for horizon 33 : 0.00061   
â         Avg displacement in data: 0.02476
â @ Main In[12]:9
â Info:    Loss [361] for horizon 35 : 0.00061   
â         Avg displacement in data: 0.02465
â @ Main In[12]:9
â Info:    Loss [381] for horizon 37 : 0.00055   
â         Avg displacement in data: 0.02336
â @ Main In[12]:9
â Info:    Loss [401] for horizon 39 : 0.00051   
â         Avg displacement in data: 0.02254
â @ Main In[12]:9
â Info:    Loss [421] for horizon 41 : 0.0005   
â         Avg displacement in data: 0.02233
â @ Main In[12]:9
â Info:    Loss [441] for horizon 43 : 0.00049   
â         Avg displacement in data: 0.02208
â @ Main In[12]:9
â Info:    Loss [461] for horizon 45 : 0.00046   
â         Avg displacement in data: 0.02135
â @ Main In[12]:9
â Info:    Loss [481] for horizon 47 : 0.00056   
â         Avg displacement in data: 0.02377
â @ Main In[12]:9
â Info:    Loss [501] for horizon 49 : 0.00081   
â         Avg displacement in data: 0.02845
â @ Main In[12]:9
â Info:    Loss [521] for horizon 51 : 0.00126   
â         Avg displacement in data: 0.03549
â @ Main In[12]:9
â Info:    Loss [541] for horizon 51 : 0.00122   
â         Avg displacement in data: 0.03496
â @ Main In[12]:9
â Info:    Loss [561] for horizon 51 : 0.00118   
â         Avg displacement in data: 0.03433
â @ Main In[12]:9
â Info:    Loss [581] for horizon 51 : 0.00116   
â         Avg displacement in data: 0.03409
â @ Main In[12]:9
â Info:    Loss [601] for horizon 51 : 0.00112   
â         Avg displacement in data: 0.0334
â @ Main In[12]:9
â Info:    Loss [621] for horizon 51 : 0.0011   
â         Avg displacement in data: 0.03316
â @ Main In[12]:9
â Info:    Loss [641] for horizon 51 : 0.0011   
â         Avg displacement in data: 0.03309
â @ Main In[12]:9
â Info:    Loss [661] for horizon 51 : 0.00107   
â         Avg displacement in data: 0.03272
â @ Main In[12]:9
â Info:    Loss [681] for horizon 51 : 0.00101   
â         Avg displacement in data: 0.03171
â @ Main In[12]:9
â Info:    Loss [701] for horizon 51 : 0.00098   
â         Avg displacement in data: 0.03136
â @ Main In[12]:9
â Info:    Loss [721] for horizon 51 : 0.00097   
â         Avg displacement in data: 0.03114
â @ Main In[12]:9
â Info:    Loss [741] for horizon 51 : 0.00096   
â         Avg displacement in data: 0.03104
â @ Main In[12]:9
â Info:    Loss [761] for horizon 51 : 0.00093   
â         Avg displacement in data: 0.03052
â @ Main In[12]:9
â Info:    Loss [781] for horizon 51 : 0.00088   
â         Avg displacement in data: 0.02974
â @ Main In[12]:9
â Info:    Loss [801] for horizon 51 : 0.00087   
â         Avg displacement in data: 0.02951
â @ Main In[12]:9
â Info:    Loss [821] for horizon 51 : 0.00086   
â         Avg displacement in data: 0.02926
â @ Main In[12]:9
â Info:    Loss [841] for horizon 51 : 0.00084   
â         Avg displacement in data: 0.02892
â @ Main In[12]:9
â Info:    Loss [861] for horizon 51 : 0.00082   
â         Avg displacement in data: 0.02866
â @ Main In[12]:9
â Info:    Loss [881] for horizon 51 : 0.00079   
â         Avg displacement in data: 0.02809
â @ Main In[12]:9
â Info:    Loss [901] for horizon 51 : 0.00077   
â         Avg displacement in data: 0.02777
â @ Main In[12]:9
â Info:    Loss [921] for horizon 51 : 0.00076   
â         Avg displacement in data: 0.02749
â @ Main In[12]:9
â Info:    Loss [941] for horizon 51 : 0.00076   
â         Avg displacement in data: 0.0276
â @ Main In[12]:9
â Info:    Loss [961] for horizon 51 : 0.00077   
â         Avg displacement in data: 0.02775
â @ Main In[12]:9
â Info:    Loss [981] for horizon 51 : 0.00071   
â         Avg displacement in data: 0.02664
â @ Main In[12]:9</code></pre><h4 id="Comparison-of-the-plots"><a class="docs-heading-anchor" href="#Comparison-of-the-plots">Comparison of the plots</a><a id="Comparison-of-the-plots-1"></a><a class="docs-heading-anchor-permalink" href="#Comparison-of-the-plots" title="Permalink"></a></h4><p>Here three plots are compared with each other and only the position of the mass is considered. The first plot represents the <em>simpleFMU</em>, the second represents the <em>realFMU</em> (reference) and the third plot represents the result after training the NeuralFMU. </p><pre><code class="language-julia hljs"># plot results mass.s
plotResults()</code></pre><p><img src="../advanced_hybrid_ME_files/advanced_hybrid_ME_39_0.svg" alt="svg"/></p><p>Finally, the FMU is cleaned-up.</p><pre><code class="language-julia hljs">fmiUnload(simpleFMU)</code></pre><h3 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h3><p>Based on the plots, it can be seen that the NeuralFMU is able to adapt the friction model of the <em>realFMU</em>. After 300 runs, the curves do not overlap very well, but this can be achieved by longer training (1000 runs) or a better initialization.</p><h3 id="Source"><a class="docs-heading-anchor" href="#Source">Source</a><a id="Source-1"></a><a class="docs-heading-anchor-permalink" href="#Source" title="Permalink"></a></h3><p>[1] Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. <strong>NeuralFMU: towards structural integration of FMUs into neural networks.</strong> Martin SjÃ¶lund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, LinkÃ¶ping, Sweden, September 20-24, 2021. LinkÃ¶ping University Electronic Press, LinkÃ¶ping (LinkÃ¶ping Electronic Conference Proceedings ; 181), 297-306. <a href="https://doi.org/10.3384/ecp21181297">DOI: 10.3384/ecp21181297</a></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../simple_hybrid_ME/">Â« Simple ME-NeuralFMU</a><a class="docs-footer-nextpage" href="../modelica_conference_2021/">Modelica Conference 2021 Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Friday 30 September 2022 19:21">Friday 30 September 2022</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
