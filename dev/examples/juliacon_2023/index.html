<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>JuliaCon 2023 Â· FMIFlux.jl</title><meta name="title" content="JuliaCon 2023 Â· FMIFlux.jl"/><meta property="og:title" content="JuliaCon 2023 Â· FMIFlux.jl"/><meta property="twitter:title" content="JuliaCon 2023 Â· FMIFlux.jl"/><meta name="description" content="Documentation for FMIFlux.jl."/><meta property="og:description" content="Documentation for FMIFlux.jl."/><meta property="twitter:description" content="Documentation for FMIFlux.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="FMIFlux.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><a class="tocitem" href="../../faq/">FAQ</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../simple_hybrid_CS/">Simple CS-NeuralFMU</a></li><li><a class="tocitem" href="../simple_hybrid_ME/">Simple ME-NeuralFMU</a></li><li class="is-active"><a class="tocitem" href>JuliaCon 2023</a><ul class="internal"><li><a class="tocitem" href="#Workshop-Video"><span>Workshop Video</span></a></li><li><a class="tocitem" href="#License"><span>License</span></a></li><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#1.-Installing-/-Loading-the-Packages"><span>1. Installing / Loading the Packages</span></a></li><li><a class="tocitem" href="#2.-Loading-FMU-and-Data"><span>2. Loading FMU &amp; Data</span></a></li><li><a class="tocitem" href="#3.-NeuralFMU-setup"><span>3. NeuralFMU setup</span></a></li><li><a class="tocitem" href="#4.-Training-the-NeuralFMU"><span>4. Training the NeuralFMU</span></a></li><li class="toplevel"><a class="tocitem" href="#5.-Results"><span>5. Results</span></a></li><li class="toplevel"><a class="tocitem" href="#Optional:-Organize-as-module"><span>Optional: Organize as module</span></a></li></ul></li><li><a class="tocitem" href="../modelica_conference_2021/">Modelica Conference 2021</a></li><li><a class="tocitem" href="../workshops/">Pluto Workshops</a></li></ul></li><li><a class="tocitem" href="../../library/">Library Functions</a></li><li><a class="tocitem" href="../../related/">Related Publication</a></li><li><a class="tocitem" href="../../contents/">Contents</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>JuliaCon 2023</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>JuliaCon 2023</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ThummeTo/FMIFlux.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ï‚›</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Using-NeuralODEs-in-real-life-applications"><a class="docs-heading-anchor" href="#Using-NeuralODEs-in-real-life-applications">Using NeuralODEs in real life applications</a><a id="Using-NeuralODEs-in-real-life-applications-1"></a><a class="docs-heading-anchor-permalink" href="#Using-NeuralODEs-in-real-life-applications" title="Permalink"></a></h1><hr/><p>Tutorial by Tobias Thummerer | Last edit: September 24 2024</p><p>This workshop was held at the JuliaCon 2023 | July 25 2023 | MIT (Boston, USA)</p><p>Keywords: <em>#NeuralODE, #NeuralFMU, #SciML, #PeNODE, #HybridModeling</em></p><h2 id="Workshop-Video"><a class="docs-heading-anchor" href="#Workshop-Video">Workshop Video</a><a id="Workshop-Video-1"></a><a class="docs-heading-anchor-permalink" href="#Workshop-Video" title="Permalink"></a></h2><p><a href="https://www.youtube.com/watch?v=X_u0KlZizD4"><img src="https://img.youtube.com/vi/X_u0KlZizD4/0.jpg" alt="YouTube Video of Workshop"/></a></p><h2 id="License"><a class="docs-heading-anchor" href="#License">License</a><a id="License-1"></a><a class="docs-heading-anchor-permalink" href="#License" title="Permalink"></a></h2><pre><code class="language-julia hljs"># Copyright (c) 2023 Tobias Thummerer, Lars Mikelsons
# Licensed under the MIT license. 
# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details.

# This workshop was held at the JuliaCon2023 @ MIT (Boston)</code></pre><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>NeuralODEs lead to amazing results in academic examples. But the expectations are often being disappointed as soon as one tries to adapt this concept for real life use cases. Bad convergence behavior, handling of discontinuities and/or instabilities are just some of the stumbling blocks that might pop up during the first steps. During the workshop, we want to show how to integrate real life industrial models in NeuralODEs using FMI and present sophisticated training strategies.</p><p>This tutorial can be used in two ways:</p><ol><li>As a single script, showing how a NeuralFMU can be setup and trained. Results can be loaded from a precomputed hyperparameter optimization.</li><li>As a module (see sections <em>Optional: Organize as module</em>) together with the file <code>juliacon_2023_distributedhyperopt.jl</code> to perform your own distributed hyperparameter optimization.</li></ol><p>This workshops divides into five sections:</p><ol><li>Installing / Loading the Packages</li><li>Loading FMU &amp; Data</li><li>NeuralFMU setup</li><li>Training the NeuralFMU</li><li>Results</li></ol><h2 id="1.-Installing-/-Loading-the-Packages"><a class="docs-heading-anchor" href="#1.-Installing-/-Loading-the-Packages">1. Installing / Loading the Packages</a><a id="1.-Installing-/-Loading-the-Packages-1"></a><a class="docs-heading-anchor-permalink" href="#1.-Installing-/-Loading-the-Packages" title="Permalink"></a></h2><p>Before we start modeling our NeuralODE, we load all required packages. If some packages are still missing, install them by typing <code>import Pkg; Pkg.add(&quot;[PKG-NAME]&quot;)</code>.</p><pre><code class="language-julia hljs"># Loading the required libraries
using FMI           # import FMUs into Julia 
using FMIFlux       # for NeuralFMUs
using FMIZoo        # a collection of demo models, including the VLDM
using FMIFlux.Flux  # Machine Learning in Julia
using DifferentialEquations: Tsit5 # for picking a NeuralFMU solver

import JLD2         # data format for saving/loading parameters

import Random       # for fixing the random seed
using Plots         # plotting results</code></pre><p>Beside the packages, we use another little script that includes some nice plotting functions specially for this workshop.</p><pre><code class="language-julia hljs"># a helper file with some predefined functions to make &quot;things look nicer&quot;, but are not really relevant to the topic
include(joinpath(@__DIR__, &quot;juliacon_2023_helpers.jl&quot;));</code></pre><p>Because notebooks can&#39;t handle progress bars, we disable <em>progress bar printing</em> - but feel free to enable it if you are using the code outside of a jupyter notebook. The progress bar gives further helpful information, like the estimated remaining computation time for simulation and training.</p><pre><code class="language-julia hljs"># disable progress bars in jupyter notebook
showProgress=false;</code></pre><h2 id="2.-Loading-FMU-and-Data"><a class="docs-heading-anchor" href="#2.-Loading-FMU-and-Data">2. Loading FMU &amp; Data</a><a id="2.-Loading-FMU-and-Data-1"></a><a class="docs-heading-anchor-permalink" href="#2.-Loading-FMU-and-Data" title="Permalink"></a></h2><p>Before starting with hybrid modeling, we load in the used training data and our FMU of the VLDM. We simulate the FMU, plot the results and compare them to data. </p><h3 id="2.1-Loading-measurement-data"><a class="docs-heading-anchor" href="#2.1-Loading-measurement-data">2.1 Loading measurement data</a><a id="2.1-Loading-measurement-data-1"></a><a class="docs-heading-anchor-permalink" href="#2.1-Loading-measurement-data" title="Permalink"></a></h3><p>We start by loading in the data (training and validation) used in this tutorial from <em>FMIZoo.jl</em> - a container library for different system model FMUs and corresponding data.</p><p><strong>Note:</strong> There where two measurements done, so data is a mean value with some deviation around (not an exact line).</p><pre><code class="language-julia hljs"># FMIZoo.jl supports different data sampling rates (by interpolation), sample length for data is 0.1s
dt = 0.1 

# load data (training) from FMIZoo.jl
data = VLDM(:train, dt=dt) 

# plot the velocity consumption (training data)
plot(data.speed_t,              # the time points the speed was captures (from data)
     data.speed_val;            # the speeds at the considered time points (from data)
     ribbon=data.speed_dev,     # a `ribbon` for the speed deviation - so the `uncertainty` because we made two measurements - but don&#39;t expect too much to see (very little uncertainty)
     fillalpha=0.3,             # alpha value for the ribbon
     label=&quot;Data&quot;,              # the plot label
     title=&quot;WLTC (first 40%)&quot;,  # plot title
     xlabel=&quot;t [s]&quot;,            # plot x-label
     ylabel=&quot;velocity [m/s]&quot;)   # plot y-label</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_11_0.svg" alt="svg"/></p><p>Further, we load validation data and have a look on it, too.</p><pre><code class="language-julia hljs"># load data (validation) from FMIZoo.jl
data_validation = VLDM(:validate, dt=dt)

# plot the velocity consumption (validation data)
plot(data_validation.speed_t, data_validation.speed_val; label=&quot;Data&quot;, ribbon=data_validation.speed_dev, fillalpha=0.3, title=&quot;WLTC (complete)&quot;, xlabel=&quot;t [s]&quot;, ylabel=&quot;velocity [m/s]&quot;)</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_13_0.svg" alt="svg"/></p><p>Let&#39;s extract a simulation starting time <code>tStart</code> and stopping time <code>tStop</code> from data - so we simulate as far as data is available. <code>tSave</code> are the points in time we want our ODE solution being saved later.</p><pre><code class="language-julia hljs"># start (`tStart`) and stop time (`tStop`) for simulation, saving time points for ODE solver (`tSave`)
tStart = data.consumption_t[1]
tStop = data.consumption_t[end]
tSave = data.consumption_t</code></pre><pre><code class="nohighlight hljs">5838-element Vector{Float64}:
   0.0
   0.1
   0.2
   0.3
   0.4
   0.5
   0.6
   0.7
   0.8
   0.9
   1.0
   1.1
   1.2
   â‹®
 582.6
 582.7
 582.8
 582.9
 583.0
 583.1
 583.2
 583.3
 583.4
 583.5
 583.6
 583.7</code></pre><p>So you can see time points are sampled with <code>dt=0.1</code> as specified and the cycle ranges from <span>$0.0s$</span> to <span>$583.7s$</span>.</p><p>Next is to get a value for the start state <code>x0</code>, so the initial state to solve the FMU and NeuralFMU.</p><pre><code class="language-julia hljs"># get start state vector from data (FMIZoo)
x0 = FMIZoo.getStateVector(data,    # the data container
                           tStart)  # the point in time where we want the state</code></pre><pre><code class="nohighlight hljs">6-element Vector{Float64}:
 0.0
 0.0
 0.0
 0.0
 0.0
 0.0</code></pre><p>In this special case, it&#39;s all zero, but this is not the default over different system!</p><p>Further, we can check for the loaded FMU parameters, that are paths to the used characteristic maps used in the model.</p><pre><code class="language-julia hljs"># have a look on the FMU parameters (these are the file paths to the characteristic maps, remaining parameters are set to default by the FMU)
display(data.params)</code></pre><pre><code class="nohighlight hljs">Dict{String, Any} with 3 entries:
  &quot;peFileName&quot; =&gt; &quot;C:\\Users\\runneradmin\\.julia\\packages\\FMIZoo\\WtBM9\\srcâ€¦
  &quot;edFileName&quot; =&gt; &quot;C:\\Users\\runneradmin\\.julia\\packages\\FMIZoo\\WtBM9\\srcâ€¦
  &quot;dcFileName&quot; =&gt; &quot;C:\\Users\\runneradmin\\.julia\\packages\\FMIZoo\\WtBM9\\srcâ€¦</code></pre><p>After that, we load the FMU and have a look on its model meta data.</p><pre><code class="language-julia hljs"># load our FMU of the VLDM (we take it from the FMIZoo.jl, exported with Dymola 2020x)
fmu = loadFMU(&quot;VLDM&quot;, &quot;Dymola&quot;, &quot;2020x&quot;; type=:ME) 

# let&#39;s have a look on the model meta data
info(fmu)</code></pre><pre><code class="nohighlight hljs">#################### Begin information for FMU ####################
	Model name:			Longitudinaldynamic.LongitudinaldynamicmodelContinuous
	FMI-Version:			2.0
	GUID:				{669889ab-7ab7-4fac-be92-96b6cd0b86a6}
	Generation tool:		Dymola Version 2020x (64-bit), 2019-10-10
	Generation time:		2022-07-22T09:32:50Z
	Var. naming conv.:		structured
	Event indicators:		28
	Inputs:				0
	Outputs:			0
	States:				6
		33554432 [&quot;driver.accelerationPedalController.PI.x&quot;]
		33554433 [&quot;driver.brakePedalController.PI.x&quot;]
		33554434 [&quot;drivingCycle.s&quot;]
		33554435 [&quot;dynamics.accelerationCalculation.integrator.y&quot;]
		33554436 [&quot;dynamics.accelerationCalculation.limiter.u&quot;, &quot;dynamics.accelerationCalculation.limIntegrator.y&quot;, &quot;dynamics.accelerationCalculation.limiter.simplifiedExpr&quot;]
		33554437 [&quot;result.integrator.y&quot;]


	Parameters:			102
		16777216 [&quot;i_gear&quot;]
		16777217 [&quot;rho_L&quot;]
		16777218 [&quot;vehMass&quot;]
		16777219 [&quot;payload&quot;]
		...
		16777303 [&quot;dynamics.accelerationCalculation.limIntegrator.y_start&quot;]
		16777304 [&quot;dynamics.accelerationCalculation.limiter.uMax&quot;]
		16777305 [&quot;dynamics.accelerationCalculation.limiter.uMin&quot;]
		16777306 [&quot;result.integrator.k&quot;]
		16777307 [&quot;result.integrator.y_start&quot;]
	Supports Co-Simulation:		true
		Model identifier:	Longitudinaldynamic_LongitudinaldynamicmodelContinuous
		Get/Set State:		true
		Serialize State:	true
		Dir. Derivatives:	true
		Var. com. steps:	true
		Input interpol.:	true
		Max order out. der.:	1
	Supports Model-Exchange:	true
		Model identifier:	Longitudinaldynamic_LongitudinaldynamicmodelContinuous
		Get/Set State:		true
		Serialize State:	true
		Dir. Derivatives:	true
##################### End information for FMU #####################</code></pre><p>One can find many useful things, like the number of states (6), inputs (0) and outputs (0), their names and information about supported features. </p><h3 id="2.2-Simulating-the-FMU"><a class="docs-heading-anchor" href="#2.2-Simulating-the-FMU">2.2 Simulating the FMU</a><a id="2.2-Simulating-the-FMU-1"></a><a class="docs-heading-anchor-permalink" href="#2.2-Simulating-the-FMU" title="Permalink"></a></h3><p>Simulating is as easy as calling <code>simulate</code>. Note, that we are putting in the parameter dictionary <code>data.params</code> from above. This FMU has many events, these are detected and handled automatically by <em>FMI.jl</em>.</p><pre><code class="language-julia hljs"># let&#39;s run a simulation from `tStart` to `tStop`, use the parameters we just viewed for the simulation run
resultFMU = simulate(fmu,                       # the loaded FMU of the VLDM 
                    (tStart, tStop);            # the simulation time range
                    parameters=data.params,     # the parameters for the VLDM
                    showProgress=showProgress,  # show (or don&#39;t) the progres bar
                    recordValues=:derivatives,  # record all state derivatives
                    saveat=tSave)               # save solution points at `tSave`
display(resultFMU)</code></pre><pre><code class="nohighlight hljs">Model name:
	Longitudinaldynamic.LongitudinaldynamicmodelContinuous
Success:
	true
f(x)-Evaluations:
	In-place: 441149
	Out-of-place: 0
Jacobian-Evaluations:
	âˆ‚xÌ‡_âˆ‚p: 0
	âˆ‚xÌ‡_âˆ‚x: 0
	âˆ‚xÌ‡_âˆ‚u: 0
	âˆ‚y_âˆ‚p: 0
	âˆ‚y_âˆ‚x: 0
	âˆ‚y_âˆ‚u: 0
	âˆ‚e_âˆ‚p: 0
	âˆ‚e_âˆ‚x: 0
	âˆ‚e_âˆ‚u: 0
	âˆ‚xr_âˆ‚xl: 0
Gradient-Evaluations:
	âˆ‚xÌ‡_âˆ‚t: 0
	âˆ‚y_âˆ‚t: 0
	âˆ‚e_âˆ‚t: 0
Callback-Evaluations:
	Condition (event-indicators): 756903
	Time-Choice (event-instances): 58371
	Affect (event-handling): 58409
	Save values: 5838
	Steps completed: 62982
States [5838]:
	0.0	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
	0.1	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 14.260000000955804]
	0.2	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 28.52000000095581]
	0.3	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 42.78000000095581]
	0.4	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 57.04000000095582]
	0.5	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 71.30000000095582]
	0.6	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 85.56000000095582]
	0.7	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 99.82000000095582]
	0.8	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 114.08000000095585]
	...
	583.7	[-0.001916469855443799, -0.054120690516540136, 3131.826061088337, 3131.346886892768, -4.101183271996665e-5, 1.425987553834784e6]
Values [5838]:
	0.0	(0.0, 0.0, 0.0, 0.0, -0.1773972602739726, 142.6)
	0.1	(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)
	0.2	(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)
	0.3	(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)
	0.4	(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)
	0.5	(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)
	0.6	(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)
	0.7	(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)
	0.8	(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)
	...
	583.7	(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)
Events [58409]:
	Time-Event @ 0.01s (state-change: false)
	Time-Event @ 0.02s (state-change: false)
	Time-Event @ 0.03s (state-change: false)
	Time-Event @ 0.04s (state-change: false)
	Time-Event @ 0.05s (state-change: false)
	Time-Event @ 0.06s (state-change: false)
	Time-Event @ 0.07s (state-change: false)
	Time-Event @ 0.08s (state-change: false)
	Time-Event @ 0.09s (state-change: false)
	...
	Time-Event @ 583.7s (state-change: false)</code></pre><p>This way, you can see interesting metadata on the solution process, like the number of evaluations of the ODE-function, sensitivity or callback evaluations. </p><p>We can use the <code>plot</code> command to plot simulation results from FMUs, too!</p><pre><code class="language-julia hljs"># Plot the simulation results
fig = plot(resultFMU;                               # the simulation result from above 
           values=false,                            # don&#39;t plot values (:derivatives)
           stateIndices=6:6,                        # only plot states 6 to 6 -&gt; so state 6 ;-)
           ylabel=&quot;Cumulative consumption [Ws]&quot;,    # set the title for the y-label
           label=&quot;FMU&quot;)                             # title the plot line 

# further plot the (measurement) data values `consumption_val` and deviation between measurements `consumption_dev`
plot!(fig, data.cumconsumption_t, data.cumconsumption_val; label=&quot;Data&quot;, ribbon=data.cumconsumption_dev, fillalpha=0.3)</code></pre><pre><code class="nohighlight hljs">[36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmiPlot(...): Number of time events (58370) exceeding 100, disabling automatic plotting of time events (can be forced with keyword `timeEvents=true`).</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_25_1.svg" alt="svg"/></p><p>The simulation result we already know from the introduction!</p><h2 id="3.-NeuralFMU-setup"><a class="docs-heading-anchor" href="#3.-NeuralFMU-setup">3. NeuralFMU setup</a><a id="3.-NeuralFMU-setup-1"></a><a class="docs-heading-anchor-permalink" href="#3.-NeuralFMU-setup" title="Permalink"></a></h2><p><img src="https://github.com/thummeto/FMIFlux.jl/blob/main/docs/src/examples/img/juliacon_2023/neuralfmu_topology.png?raw=true" alt="NeuralFMU"/></p><p>Equipped with data and a simulation model, we can setup the NeuralFMU as introduced in the workshop.</p><h3 id="3.1-Pre-and-Post-Processing"><a class="docs-heading-anchor" href="#3.1-Pre-and-Post-Processing">3.1 Pre- and Post-Processing</a><a id="3.1-Pre-and-Post-Processing-1"></a><a class="docs-heading-anchor-permalink" href="#3.1-Pre-and-Post-Processing" title="Permalink"></a></h3><p>We gather the three derivative values from the last simulation run, to have values for initialization of the pre- and post-processing layers.</p><pre><code class="language-julia hljs"># variable we want to manipulate - why we are picking exactly these three is shown a few lines later ;-)
manipulatedDerVars = [&quot;der(dynamics.accelerationCalculation.integrator.y)&quot;,
                      &quot;der(dynamics.accelerationCalculation.limIntegrator.y)&quot;,
                      &quot;der(result.integrator.y)&quot;]
manipulatedDerVals = getValue(resultFMU, manipulatedDerVars)

# what happens without proper transformation between FMU- and ANN-domain?
plot(resultFMU.values.t, manipulatedDerVals[1,:][1]; label=&quot;original&quot;, xlabel=&quot;t [s]&quot;, ylabel=&quot;velocity [m/s]&quot;)</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_29_0.svg" alt="svg"/></p><p>But what happens if we put the velocity into the hyperbolic tangent function?</p><pre><code class="language-julia hljs">plot!(resultFMU.values.t, tanh.(manipulatedDerVals[1,:][1]); label=&quot;tanh(velocity)&quot;)</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_31_0.svg" alt="svg"/></p><p>It gets saturated drastically! That&#39;s why we need shift- and scale layers for online pre- and post-processing!</p><p>We introduce the <code>ShiftScale</code>-layer for pre-processing our data.</p><pre><code class="language-julia hljs"># pre- and post-processing
preProcess = ShiftScale(manipulatedDerVals);    # we put in the derivatives recorded above, FMIFlux shift and scales so we have a data mean of 0 and a standard deivation of 1 (other activation functions / ranges are possible!)</code></pre><p>How does the velocity look after pushing it through the <code>ShiftScale</code>-layer?</p><pre><code class="language-julia hljs">testVals = collect(tanh(preProcess(collect(val[t] for val in manipulatedDerVals))[1]) for t in 1:length(resultFMU.values.t))
plot!(resultFMU.values.t, 
      testVals; 
      label=&quot;tanh(preProcess(velocity))&quot;)</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_35_0.svg" alt="svg"/></p><p>You can clearly see, that after pre-processing, the trajectory (green) still mirrors the dynamical behavior of the original system (blue), while the not pre-processed option (orange) just saturates values. </p><pre><code class="language-julia hljs"># we add some additional &quot;buffer&quot; - this is not necessary but helps to preserve peaks
preProcess.scale[:] *= 0.25;    

# initialize the postProcess as inverse of the preProcess, but only take indices 2 and 3 (we don&#39;t need 1, the vehicle velocity)
postProcess = ScaleShift(preProcess; indices=2:3);</code></pre><h3 id="3.2-Building-the-NeuralFMU"><a class="docs-heading-anchor" href="#3.2-Building-the-NeuralFMU">3.2 Building the NeuralFMU</a><a id="3.2-Building-the-NeuralFMU-1"></a><a class="docs-heading-anchor-permalink" href="#3.2-Building-the-NeuralFMU" title="Permalink"></a></h3><p>To make this more usable, we put the entire NeuralFMU building process (including the pre- and post-processing we had a detailed look on) into a dedicated function <code>build_FMU</code>.</p><pre><code class="language-julia hljs"># function that builds the considered NeuralFMU on basis of a given FMU (FMI-Version 2.0) `f`
function build_NFMU(f::FMU2)
    
    # pre- and post-processing
    preProcess = ShiftScale(manipulatedDerVals)         # we put in the derivatives recorded above, FMIFlux shift and scales so we have a data mean of 0 and a standard deviation of 1
    preProcess.scale[:] *= 0.25                         # add some additional &quot;buffer&quot;
    postProcess = ScaleShift(preProcess; indices=2:3)   # initialize the postProcess as inverse of the preProcess, but only take indices 2 and 3 (we don&#39;t need 1, the vehicle velocity)

    # cache
    cache = CacheLayer()                        # allocate a cache layer
    cacheRetrieve = CacheRetrieveLayer(cache)   # allocate a cache retrieve layer, link it to the cache layer

    # we have two signals (acceleration, consumption) and two sources (ANN, FMU), so four gates:
    # (1) acceleration from FMU (gate=1.0 | open)
    # (2) consumption  from FMU (gate=1.0 | open)
    # (3) acceleration from ANN (gate=0.0 | closed)
    # (4) consumption  from ANN (gate=0.0 | closed)
    # the accelerations [1,3] and consumptions [2,4] are paired
    gates = ScaleSum([1.0, 1.0, 0.0, 0.0], [[1,3], [2,4]]) # gates with sum

    # setup the NeuralFMU topology
    model = Chain(x -&gt; f(; x=x, dx_refs=:all),        # take `x`, put it into the FMU, retrieve all derivatives `dx`
                  dx -&gt; cache(dx),                    # cache `dx`
                  dx -&gt; dx[4:6],                      # forward only dx[4, 5, 6]
                  preProcess,                         # pre-process `dx`
                  Dense(3, 32, tanh),                 # Dense Layer 3 -&gt; 32 with `tanh` activation
                  Dense(32, 2, tanh),                 # Dense Layer 32 -&gt; 2 with `tanh` activation 
                  postProcess,                        # post process `dx`
                  dx -&gt; cacheRetrieve(5:6, dx),       # dynamics FMU | dynamics ANN
                  gates,                              # compute resulting dx from ANN + FMU
                  dx -&gt; cacheRetrieve(1:4, dx))       # stack together: dx[1,2,3,4] from cache + dx[5,6] from gates

    solver = Tsit5()
    
    # new NeuralFMU 
    neuralFMU = ME_NeuralFMU(f,                 # the FMU used in the NeuralFMU 
                             model,             # the model we specified above 
                             (tStart, tStop),   # a default start ad stop time for solving the NeuralFMU
                             solver;
                             saveat=tSave)      # the time points to save the solution at
    neuralFMU.modifiedState = false             # speed optimization (NeuralFMU state equals FMU state)
    
    return neuralFMU 
end</code></pre><pre><code class="nohighlight hljs">build_NFMU (generic function with 1 method)</code></pre><p>Let&#39;s test the NeuralFMU: First, load the FMU und built a NeuralFMU from it.</p><pre><code class="language-julia hljs"># build NeuralFMU
neuralFMU = build_NFMU(fmu);</code></pre><p>Next, do a simulation for a given start state <code>x0</code> from <em>FMIZoo.jl</em>.</p><pre><code class="language-julia hljs"># simulate and plot the (uninitialized) NeuralFMU
resultNFMU = neuralFMU(x0,                          # the start state to solve the ODE
                       (tStart, tStop);             # the simulation range
                       parameters=data.params,      # the parameters for the VLDM
                       showProgress=showProgress,   # show progress (or not)
                       saveat=tSave)                # the time points to save the solution at

display(resultNFMU)     </code></pre><pre><code class="nohighlight hljs">Model name:
	Longitudinaldynamic.LongitudinaldynamicmodelContinuous
Success:
	true
f(x)-Evaluations:
	In-place: 409926
	Out-of-place: 0
Jacobian-Evaluations:
	âˆ‚xÌ‡_âˆ‚p: 0
	âˆ‚xÌ‡_âˆ‚x: 0
	âˆ‚xÌ‡_âˆ‚u: 0
	âˆ‚y_âˆ‚p: 0
	âˆ‚y_âˆ‚x: 0
	âˆ‚y_âˆ‚u: 0
	âˆ‚e_âˆ‚p: 0
	âˆ‚e_âˆ‚x: 0
	âˆ‚e_âˆ‚u: 0
	âˆ‚xr_âˆ‚xl: 0
Gradient-Evaluations:
	âˆ‚xÌ‡_âˆ‚t: 0
	âˆ‚y_âˆ‚t: 0
	âˆ‚e_âˆ‚t: 0
Callback-Evaluations:
	Condition (event-indicators): 702407
	Time-Choice (event-instances): 58371
	Affect (event-handling): 58409
	Save values: 0
	Steps completed: 58440
States [5838]:
	0.0	[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
	0.1	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 14.260000000955804]
	0.2	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 28.52000000095581]
	0.3	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 42.78000000095581]
	0.4	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 57.04000000095582]
	0.5	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 71.30000000095582]
	0.6	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 85.56000000095582]
	0.7	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 99.82000000095582]
	0.8	[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 114.08000000095585]
	...
	583.7	[-0.0019167094095930257, -0.05412068948173644, 3131.826061088355, 3131.346887534511, -4.3267310775923446e-5, 1.4259877656765594e6]
Events [58409]:
	Time-Event @ 0.01s (state-change: false)
	Time-Event @ 0.02s (state-change: false)
	Time-Event @ 0.03s (state-change: false)
	Time-Event @ 0.04s (state-change: false)
	Time-Event @ 0.05s (state-change: false)
	Time-Event @ 0.06s (state-change: false)
	Time-Event @ 0.07s (state-change: false)
	Time-Event @ 0.08s (state-change: false)
	Time-Event @ 0.09s (state-change: false)
	...
	Time-Event @ 583.7s (state-change: false)</code></pre><p>As for the FMU, we can display the NeuralFMU simulation result and check some statistics.</p><p>Now, let&#39;s have a look on the cumulative consumption plot ...</p><pre><code class="language-julia hljs"># plot the NeuralFMU, original FMU and data (cumulative consumption)
fig = plot(resultNFMU; stateIndices=6:6, stateEvents=false, timeEvents=false, label=&quot;NeuralFMU (untrained)&quot;, ylabel=&quot;cumulative consumption [Ws]&quot;)
plot!(fig, resultFMU; stateIndices=6:6, values=false, stateEvents=false, timeEvents=false, label=&quot;FMU&quot;)
plot!(fig, data.cumconsumption_t, data.cumconsumption_val, label=&quot;Data&quot;)</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_45_0.svg" alt="svg"/></p><p>As you can see, the FMU und NeuralFMU result looks identically - and this is what we expect for a fully open FMU gate and a fully closed ANN gate!</p><p>Finally, unload the FMU and invalidate the NeuralFMU.</p><pre><code class="language-julia hljs"># unload FMU / invalidate NeuralFMU
unloadFMU(fmu)
neuralFMU = nothing</code></pre><h2 id="4.-Training-the-NeuralFMU"><a class="docs-heading-anchor" href="#4.-Training-the-NeuralFMU">4. Training the NeuralFMU</a><a id="4.-Training-the-NeuralFMU-1"></a><a class="docs-heading-anchor-permalink" href="#4.-Training-the-NeuralFMU" title="Permalink"></a></h2><p>An untrained NeuralFMU is not that impressive - so let&#39;s train it a bit. </p><p>We start by defining a time sequence (the time points of data measurements) and the cumulative consumption values we want to train for.</p><pre><code class="language-julia hljs"># prepare training data 
train_t = data.consumption_t 

# data is as &quot;array of arrays&quot; required (often we have multidimensional data)
train_data = collect([d] for d in data.cumconsumption_val)</code></pre><pre><code class="nohighlight hljs">5838-element Vector{Vector{Float64}}:
 [0.0]
 [-0.41296068176650935]
 [0.26787411983582043]
 [0.7202168791949798]
 [1.0714482470335085]
 [1.390037422822217]
 [2.1200151652794643]
 [2.5196535613914306]
 [2.656369007464336]
 [2.993187294279602]
 [3.4693116134235407]
 [4.049369938809381]
 [4.673174216401814]
 â‹®
 [1.3879359188013095e6]
 [1.3879515067827937e6]
 [1.3879669882976608e6]
 [1.3879825294049252e6]
 [1.3879980607748663e6]
 [1.3880134565080018e6]
 [1.3880287579379592e6]
 [1.388044098663902e6]
 [1.388059371012591e6]
 [1.388074504338062e6]
 [1.3880896849414955e6]
 [1.3881049434185931e6]</code></pre><p>The data sequence is too long to train on it all at once - so we <strong>need to batch</strong> our data.</p><p>First, we introduce some hyperparameters. Training success always depends on a good choice of hyperparameters, we use the following hyperparameters in this workshop:</p><ul><li><code>BATCHDUR</code> the duration of a single batch element (length) in seconds.</li><li><code>TRAINDUR</code> specifies the training duration (measured on data) in seconds.</li><li><code>ETA</code> the update rate <span>$\eta$</span> of the <em>Adam</em> optimizer.</li><li><code>BETA1</code> the first momentum coefficient <span>$\beta_1$</span> of the <em>Adam</em> optimizer.</li><li><code>BETA2</code> the second momentum coefficient <span>$\beta_2$</span> of the <em>Adam</em> optimizer. </li><li><code>LASTWEIGHT</code> a weighting factor between the last solution point and all remaining solution points.</li><li><code>SCHEDULER</code> an identifier for the batch scheduler, can be <code>:Sequential</code>, <code>:Random</code> or <code>:LossAccumulation</code>.</li><li><code>LOSS</code> an identifier for the loss function to use, <code>:MAE</code> or <code>:MSE</code>.</li></ul><p>Next, the loss function is defined. The loss is computed on basis of a given <code>solution</code> and <code>data</code>. Dependent on the hyperparameter <code>LOSS</code>, either <code>:MAE</code> or <code>:MSE</code> is used to compute the loss. The hyperparameter <code>LASTWEIGHT</code> determines how much the last solution point is weight against the remaining solution points. For example a value of <span>$0.3$</span> determines that the last point of the solution contributes <span>$30\%$</span> to the loss, whereas all remaining solution points contribute <span>$70\%$</span> in total.</p><pre><code class="language-julia hljs">function _lossFct(solution::FMUSolution, data::VLDM_Data, LOSS::Symbol, LASTWEIGHT::Real=1.0/length(data.consumption_t) )

    # determine the start/end indices `ts` and `te` in the data array (sampled with 10Hz)
    ts = dataIndexForTime(solution.states.t[1])
    te = dataIndexForTime(solution.states.t[end])
    
    # retrieve the data from NeuralODE (&quot;where we are&quot;) and data from measurements (&quot;where we want to be&quot;) and an allowed deviation (&quot;we are unsure about&quot;)
    nfmu_cumconsumption = getState(solution, 6; isIndex=true)
    cumconsumption = data.cumconsumption_val[ts:te]
    cumconsumption_dev = data.cumconsumption_dev[ts:te]

    Î”cumconsumption = 0.0
    if LOSS == :MAE
        Î”cumconsumption = FMIFlux.Losses.mae_last_element_rel_dev(nfmu_cumconsumption,  # NeuralFMU 
                                                                  cumconsumption,       # data target
                                                                  cumconsumption_dev,   # data uncertainty
                                                                  LASTWEIGHT)           # how much do we scale the last point compared to the remaining ones?
    elseif LOSS == :MSE
        Î”cumconsumption = FMIFlux.Losses.mse_last_element_rel_dev(nfmu_cumconsumption, 
                                                                  cumconsumption, 
                                                                  cumconsumption_dev, 
                                                                  LASTWEIGHT)
    else
        @assert false, &quot;Unknown LOSS: `$(LOSS)`&quot;
    end
    
    return Î”cumconsumption 
end</code></pre><pre><code class="nohighlight hljs">_lossFct (generic function with 2 methods)</code></pre><p>Finally, the function <code>train!</code> is defined, that triggers a new training run for a given set of hyperparameters <code>hyper_params</code>, a training resource <code>resource</code> and the current training index <code>ind</code>.</p><pre><code class="language-julia hljs"># resource = training time horizon (duration of data seen)
function train!(hyper_params, resource, ind)

    # make the runs deterministic by fixing the random seed
    Random.seed!(1234)

    # training duration (in seconds) equals the given resource
    TRAINDUR = resource

    # unpack the hyperparameters
    ETA, BETA1, BETA2, BATCHDUR, LASTWEIGHT, SCHEDULER, LOSS = hyper_params

    # compute the number of training steps TRAINDUR / BATCHDUR, but do at least one step
    steps = max(round(Int, TRAINDUR/BATCHDUR), 1) 

    # print a bit of info
    @info &quot;--------------\nStarting run $(ind) with parameters: $(hyper_params) and resource $(resource) doing $(steps) step(s).\n--------------------&quot;

    # load our FMU (we take one from the FMIZoo.jl, exported with Dymola 2020x)
    fmu = loadFMU(&quot;VLDM&quot;, &quot;Dymola&quot;, &quot;2020x&quot;; type=:ME) 

    # built the NeuralFMU on basis of the loaded FMU `fmu`
    neuralFMU = build_NFMU(fmu)

    # a more efficient execution mode
    singleInstanceMode(fmu, true)
    
    # batch the data (time, targets), train only on model output index 6, plot batch elements
    batch = batchDataSolution(neuralFMU,                            # our NeuralFMU model
                              t -&gt; FMIZoo.getStateVector(data, t),  # a function returning a start state for a given time point `t`, to determine start states for batch elements
                              train_t,                              # data time points
                              train_data;                           # data cumulative consumption 
                              batchDuration=BATCHDUR,               # duration of one batch element
                              indicesModel=6:6,                     # model indices to train on (6 equals the state `cumulative consumption`)
                              plot=false,                           # don&#39;t show intermediate plots (try this outside of Jupyter)
                              parameters=data.params,               # use the parameters (map file paths) from *FMIZoo.jl*
                              showProgress=showProgress)            # show or don&#39;t show progress bar, as specified at the very beginning

    # limit the maximum number of solver steps to 1000 * BATCHDUR (longer batch elements get more steps)
    # this allows the NeuralFMU to do 10x more steps (average) than the original FMU, but more should not be tolerated (to stiff system)
    solverKwargsTrain = Dict{Symbol, Any}(:maxiters =&gt; round(Int, 1000*BATCHDUR)) 
    
    # a smaller dispatch for our custom loss function, only taking the solution object
    lossFct = (solution::FMUSolution) -&gt; _lossFct(solution, data, LOSS, LASTWEIGHT)

    # selecting a scheduler for training
    scheduler = nothing
    if SCHEDULER == :Random
        # a scheduler that picks a random batch element
        scheduler = RandomScheduler(neuralFMU, batch; applyStep=1, plotStep=0)
    elseif SCHEDULER == :Sequential
        # a scheduler that picks one batch element after another (in chronological order)
        scheduler = SequentialScheduler(neuralFMU, batch; applyStep=1, plotStep=0)
    elseif SCHEDULER == :LossAccumulation
        # a scheduler that picks the element with largest accumulated loss:
        # - after every training step, the accumulated loss for every batch element is increased by the current loss value 
        # - when picking a batch element, the accumulated loss is reset to zero
        # - this promotes selecting elements with larger losses more often, but also prevents starving of elements with small losses
        scheduler = LossAccumulationScheduler(neuralFMU, batch, lossFct; applyStep=1, plotStep=0, updateStep=1)
    else 
        @error &quot;Unknown SCHEDULER: Â´$(SCHEDULER)Â´.&quot;
        return nothing
    end

    # loss for training, do a simulation run on a batch element taken from the scheduler
    loss = p -&gt; FMIFlux.Losses.loss(neuralFMU,                          # the NeuralFMU to simulate
                                    batch;                              # the batch to take an element from
                                    p=p,                                # the NeuralFMU training parameters (given as input)
                                    parameters=data.params,             # the FMU parameters
                                    lossFct=lossFct,                    # our custom loss function
                                    batchIndex=scheduler.elementIndex,  # the index of the batch element to take, determined by the chosen scheduler
                                    logLoss=true,                       # log losses after every evaluation
                                    showProgress=showProgress,          # show progress bar (or don&#39;t)
                                    solverKwargsTrain...)               # the solver kwargs defined above

    # gather the parameters from the NeuralFMU
    params = FMIFlux.params(neuralFMU)

    # initialize the scheduler, keywords are passed to the NeuralFMU
    FMIFlux.initialize!(scheduler; parameters=data.params, p=params[1], showProgress=showProgress)
    
    # initialize Adam optimizer with our hyperparameters
    optim = Adam(ETA, (BETA1, BETA2))
   
    # the actual training
    FMIFlux.train!(loss,                            # the loss function for training
                   neuralFMU,                       # the neural FMU including the parameters to train
                   Iterators.repeated((), steps),   # an iterator repeating `steps` times
                   optim;                           # the optimizer to train
                   gradient=:ReverseDiff,           # ForwardDiff leads to good results for multi-event systems
                   chunk_size=32,                   # ForwardDiff chunk_size (=number of parameter estimations per run) - only if ForwardDiff is used
                   cb=() -&gt; FMIFlux.update!(scheduler),     # update the scheduler after every step 
                   proceed_on_assert=true)          # proceed, even if assertions are thrown, with the next step
    
    # the default execution mode
    singleInstanceMode(fmu, false)

    # save our result parameters
    FMIFlux.saveParameters(neuralFMU, joinpath(@__DIR__, &quot;params&quot;, &quot;$(ind).jld2&quot;))
    
    # simulate the NeuralFMU on a validation trajectory
    resultNFMU = neuralFMU(x0, (data_validation.consumption_t[1], data_validation.consumption_t[end]); parameters=data_validation.params, showProgress=showProgress, maxiters=1e7, saveat=data_validation.consumption_t)

    # determine loss on validation data (if the simulation was successful)
    validation_loss = nothing 
    if resultNFMU.success
        # compute the loss on VALIDATION data 
        validation_loss = _lossFct(resultNFMU,      # the NeuralFMU
                                  data_validation,  # the validation data set 
                                  :MSE)             # use MSE 
    end        

    # unload FMU
    unloadFMU(fmu)

    # return the loss (or `nothing` if no loss can be determined)
    return validation_loss
end</code></pre><pre><code class="nohighlight hljs">train! (generic function with 1 method)</code></pre><p>If you want to do hyper parameter optimization, uncomment/remove all code that comes from here on. The following is for demonstration purpose only. </p><p>Let&#39;s check if the train function is working for a given set of hyperparameters.</p><pre><code class="language-julia hljs"># check if the train function is working for a set of given (random) hyperparameters
#     ([  ETA, BETA1,  BETA2, BATCHDUR, LASTWEIGHT, SCHEDULER, LOSS], RESOURCE, INDEX)
train!([0.0001,  0.9,  0.999,      4.0,        0.7,   :Random, :MSE],      8.0,     1)</code></pre><pre><code class="nohighlight hljs">[36m[1mâ”Œ [22m[39m[36m[1mInfo: [22m[39m--------------
[36m[1mâ”‚ [22m[39mStarting run 1 with parameters: Any[0.0001, 0.9, 0.999, 4.0, 0.7, :Random, :MSE] and resource 8.0 doing 2 step(s).
[36m[1mâ”” [22m[39m--------------------


[36m[1m[ [22m[39m[36m[1mInfo: [22m[39mCurrent step: 0 | Current element=0 | Next element=92


[36m[1m[ [22m[39m[36m[1mInfo: [22m[39mCurrent step: 1 | Current element=92 | Next element=55


[36m[1m[ [22m[39m[36m[1mInfo: [22m[39mAVG: 1.20e+04 | MAX: 1.75e+06 | SUM: 1.75e+06


[36m[1m[ [22m[39m[36m[1mInfo: [22m[39mCurrent step: 2 | Current element=55 | Next element=106
[36m[1m[ [22m[39m[36m[1mInfo: [22m[39mAVG: 1.21e+04 | MAX: 1.75e+06 | SUM: 1.75e+06





9.046692788787865e9</code></pre><h1 id="5.-Results"><a class="docs-heading-anchor" href="#5.-Results">5. Results</a><a id="5.-Results-1"></a><a class="docs-heading-anchor-permalink" href="#5.-Results" title="Permalink"></a></h1><p>After training with a set of good hyperparameters, results can be loaded (one set is already prepared if you skipped the optimization).</p><pre><code class="language-julia hljs"># load our FMU (we take one from the FMIZoo.jl, exported with Dymola 2020x)
fmu = loadFMU(&quot;VLDM&quot;, &quot;Dymola&quot;, &quot;2020x&quot;; type=:ME)

# build NeuralFMU
neuralFMU = build_NFMU(fmu)

# load parameters from hyperparameter optimization
FMIFlux.loadParameters(neuralFMU, joinpath(@__DIR__, &quot;juliacon_2023.jld2&quot;))

# simulate and plot the NeuralFMU
resultNFMU = neuralFMU(x0,  (tStart, tStop); parameters=data.params, showProgress=showProgress, saveat=tSave) 
resultFMU  =  simulate(fmu, (tStart, tStop); parameters=data.params, showProgress=showProgress, saveat=tSave) 

# plot the NeuralFMU, original FMU and data (cumulative consumption)
fig = plot(resultNFMU; stateIndices=6:6, stateEvents=false, timeEvents=false, label=&quot;NeuralFMU&quot;, ylabel=&quot;cumulative consumption [m/s]&quot;)
plot!(fig, resultFMU; stateIndices=6:6, values=false, stateEvents=false, timeEvents=false, label=&quot;FMU&quot;)
plot!(fig, data.cumconsumption_t, data.cumconsumption_val, label=&quot;Data&quot;)</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_58_0.svg" alt="svg"/></p><p>We also have a ready-to-use function that calculates different errors and plots them.</p><pre><code class="language-julia hljs">plotCumulativeConsumption(resultNFMU, resultFMU, data; filename=joinpath(@__DIR__, &quot;comparison_train_100.png&quot;))</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_60_0.svg" alt="svg"/></p><p>Because the deviation is small, let&#39;s check the last 10% of WLTC focussed, so from 90% to 100%.</p><pre><code class="language-julia hljs">plotCumulativeConsumption(resultNFMU, resultFMU, data; range=(0.9, 1.0), filename=joinpath(@__DIR__, &quot;comparison_train_10.png&quot;))</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_62_0.svg" alt="svg"/></p><p>Finally, we should check the results on validation data: The full WLTC cycle.</p><pre><code class="language-julia hljs"># get start and stop for the validation cycle (full WLTC)
tStart_validation = data_validation.cumconsumption_t[1]
tStop_validation = data_validation.cumconsumption_t[end]
tSave_validation = data_validation.cumconsumption_t

# simulate the NeuralFMU on validation data
resultNFMU = neuralFMU(x0,  (tStart_validation, tStop_validation); parameters=data_validation.params, showProgress=showProgress, saveat=tSave_validation) 
resultFMU  =  simulate(fmu, (tStart_validation, tStop_validation); parameters=data_validation.params, showProgress=showProgress, saveat=tSave_validation) 

plotCumulativeConsumption(resultNFMU, resultFMU, data_validation; filename=joinpath(@__DIR__, &quot;comparison_validation_100.png&quot;))</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_64_0.svg" alt="svg"/></p><p>... and the last 10% ...</p><pre><code class="language-julia hljs">plotCumulativeConsumption(resultNFMU, resultFMU, data_validation; range=(0.9, 1.0), filename=joinpath(@__DIR__, &quot;comparison_validation_10.png&quot;))</code></pre><p><img src="../juliacon_2023_files/juliacon_2023_66_0.svg" alt="svg"/></p><p>Check out the <strong>error values</strong> in the legend: This is an enhancement of factor x326 on MSE, x22 on MAE and x11 on MAX error, wow!</p><p>Finally some plotting &quot;sugar&quot;: A plot showing for which locations in derivative-space the model enhanced the cumulative consumption prediction the most:</p><pre><code class="language-julia hljs">plotEnhancements(neuralFMU, fmu, data; filename=joinpath(@__DIR__, &quot;gif_1.gif&quot;))</code></pre><pre><code class="nohighlight hljs">[36m[1m[ [22m[39m[36m[1mInfo: [22m[39mSaved animation to D:\a\FMIFlux.jl\FMIFlux.jl\examples\jupyter-src\gif_1.gif</code></pre><p><img src="../juliacon_2023_files/gif_1.gif" alt="gif"/></p><p>After we finished, let&#39;s finally unload the FMU and invalidate the NeuralFMU.</p><pre><code class="language-julia hljs"># unload FMU / invalidate NeuralFMU
unloadFMU(fmu)
neuralFMU = nothing</code></pre><p><strong>But:</strong> We did look on some results, but did not talk about where the used hyperparameters came from ...</p><p>They come from hyperparameter optimization - and this step is necessary for NeuralODEs too! </p><h1 id="Optional:-Organize-as-module"><a class="docs-heading-anchor" href="#Optional:-Organize-as-module">Optional: Organize as module</a><a id="Optional:-Organize-as-module-1"></a><a class="docs-heading-anchor-permalink" href="#Optional:-Organize-as-module" title="Permalink"></a></h1><p>If you want, you can place all code inside of a module named <code>NODE_Training</code>, this simplifies hyper parameter optimization (if you want to do one).</p><pre><code class="language-julia hljs"># for hyper parameter optimization, place the code in a `module`
# uncomment the following three lines and place them at the very beginning
 
#module NODE_Training 
#using DistributedHyperOpt
#using DistributedHyperOpt.Distributed 

# ... and uncomment the following line
#end # NODE_Training </code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../simple_hybrid_ME/">Â« Simple ME-NeuralFMU</a><a class="docs-footer-nextpage" href="../modelica_conference_2021/">Modelica Conference 2021 Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Wednesday 16 October 2024 11:51">Wednesday 16 October 2024</span>. Using Julia version 1.11.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
