var documenterSearchIndex = {"docs":
[{"location":"library/overview/#library","page":"Library Functions","title":"Library Functions","text":"","category":"section"},{"location":"library/overview/#FMIFlux-functions","page":"Library Functions","title":"FMIFlux functions","text":"","category":"section"},{"location":"library/overview/","page":"Library Functions","title":"Library Functions","text":"ME_NeuralFMU\nCS_NeuralFMU\nNeuralFMU\nNeuralFMUInputLayer\nNeuralFMUOutputLayer\n\nNeuralFMUCacheTime\nNeuralFMUCacheState","category":"page"},{"location":"library/overview/#FMIFlux.ME_NeuralFMU","page":"Library Functions","title":"FMIFlux.ME_NeuralFMU","text":"Structure definition for a NeuralFMU, that runs in mode Model Exchange (ME).\n\n\n\n\n\n","category":"type"},{"location":"library/overview/#FMIFlux.CS_NeuralFMU","page":"Library Functions","title":"FMIFlux.CS_NeuralFMU","text":"Structure definition for a NeuralFMU, that runs in mode Co-Simulation (CS).\n\n\n\n\n\n","category":"type"},{"location":"library/overview/#FMIFlux.NeuralFMU","page":"Library Functions","title":"FMIFlux.NeuralFMU","text":"The mutable struct representing an abstract (simulation mode unknown) NeuralFMU.\n\n\n\n\n\n","category":"type"},{"location":"library/overview/#FMI-version-independent-functions","page":"Library Functions","title":"FMI version independent functions","text":"","category":"section"},{"location":"library/overview/","page":"Library Functions","title":"Library Functions","text":"fmiDoStepME\nfmiDoStepCS\nfmiInputDoStepCSOutput","category":"page"},{"location":"library/overview/#FMIFlux.fmiDoStepME","page":"Library Functions","title":"FMIFlux.fmiDoStepME","text":"Wrapper. Call fmi2DoStepME for more information.\n\n\n\n\n\n","category":"function"},{"location":"library/overview/#FMIFlux.fmiDoStepCS","page":"Library Functions","title":"FMIFlux.fmiDoStepCS","text":"Wrapper. Call fmi2DoStepCS for more information.\n\n\n\n\n\n","category":"function"},{"location":"library/overview/#FMIFlux.fmiInputDoStepCSOutput","page":"Library Functions","title":"FMIFlux.fmiInputDoStepCSOutput","text":"Wrapper. Call fmi2InputDoStepCSOutput for more information.\n\n\n\n\n\n","category":"function"},{"location":"library/overview/#Additional-functions","page":"Library Functions","title":"Additional functions","text":"","category":"section"},{"location":"library/overview/","page":"Library Functions","title":"Library Functions","text":"mse_interpolate\ntransferParams!","category":"page"},{"location":"library/overview/#FMIFlux.mse_interpolate","page":"Library Functions","title":"FMIFlux.mse_interpolate","text":"Compares non-equidistant (or equdistant) datapoints by linear interpolating and comparing at given interpolation points t_comp.  (Zygote-friendly: Zygote can differentiate through via AD.)\n\n\n\n\n\n","category":"function"},{"location":"library/overview/#FMIFlux.transferParams!","page":"Library Functions","title":"FMIFlux.transferParams!","text":"Writes/Copies training parameters from p_net to net with data offset c.\n\n\n\n\n\n","category":"function"},{"location":"library/overview/#FMI-2-version-dependent-functions","page":"Library Functions","title":"FMI 2 version dependent functions","text":"","category":"section"},{"location":"library/overview/","page":"Library Functions","title":"Library Functions","text":"fmi2DoStepME\nfmi2DoStepCS\nfmi2InputDoStepCSOutput","category":"page"},{"location":"library/overview/#FMIFlux.fmi2DoStepME","page":"Library Functions","title":"FMIFlux.fmi2DoStepME","text":"Performs something similar to fmiDoStep for ME-FMUs (note, that fmiDoStep is for CS-FMUs only). Event handling (state- and time-events) is supported. If you don't want events to be handled, you can disable event-handling for the NeuralFMU nfmu with the attribute eventHandling = false.\n\nOptional, additional FMU-values can be set via keyword arguments setValueReferences and setValues. Optional, additional FMU-values can be retrieved by keyword argument getValueReferences.\n\nFunction takes the current system state array (\"x\") and returns an array with state derivatives (\"x dot\") and optionally the FMU-values for getValueReferences. Setting the FMU time via argument t is optional, if not set, the current time of the ODE solver around the NeuralFMU is used.\n\n\n\n\n\n","category":"function"},{"location":"library/overview/#FMIFlux.fmi2DoStepCS","page":"Library Functions","title":"FMIFlux.fmi2DoStepCS","text":"Performs a fmiDoStep for CS-FMUs (note, that fmiDoStep is for CS-FMUs only).\n\nOptional, FMU-values can be set via keyword arguments setValueReferences and setValues. Optional, FMU-values can be retrieved by keyword argument getValueReferences.\n\nFunction returns the FMU-values for the optional keyword argument getValueReferences. The CS-FMU performs one macro step with step size dt. Dependent on the integrated numerical solver, the FMU may perform multiple (internal) micro steps if needed to meet solver requirements (stability/accuracy). These micro steps are hidden by FMI2.\n\n\n\n\n\n","category":"function"},{"location":"library/overview/#FMIFlux.fmi2InputDoStepCSOutput","page":"Library Functions","title":"FMIFlux.fmi2InputDoStepCSOutput","text":"Sets all FMU inputs to u, performs a ´´´fmi2DoStep´´´ and returns all FMU outputs.\n\n\n\n\n\n","category":"function"},{"location":"contents/","page":"Contents","title":"Contents","text":"Pages = [\"index.md\", \"library.md\", \"fmu2.md\", \"parameterize.md\", \"simulateCS.md\", \"simulateME.md\"]","category":"page"},{"location":"related/#Related-Publications","page":"Related Publications","title":"Related Publications","text":"","category":"section"},{"location":"related/","page":"Related Publications","title":"Related Publications","text":"Thummerer T, Kircher J and Mikelsons L: Neural FMU: Towards structual integration of FMUs into neural networks (Preprint, accepted 14th International Modelica Conference) pdf|DOI","category":"page"},{"location":"related/","page":"Related Publications","title":"Related Publications","text":"Thummerer T, Tintenherr J, Mikelsons L: Hybrid modeling of the human cardiovascular system using NeuralFMUs (Preprint, accepted 10th International Conference on Mathematical Modeling in Physical Sciences) pdf|DOI","category":"page"},{"location":"examples/overview/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"This section discusses the included examples of the FMIFlux.jl library. So you can execute them on your machine and get detailed information about all of the steps. If you require further information about the function calls, see library functions section. For more information related to the setup and simulation of an FMU see FMI.jl library.","category":"page"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"The examples are:","category":"page"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"Simple hybrid CS: Showing how to train a Neural CS FMU.\nsimple hybrid ME: Showing how to train a Neural ME FMU.\nadvanced hybrid ME: Showing how to train an advanced Neural ME FMU.","category":"page"},{"location":"tutorials/overview/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"tutorials/overview/","page":"Overview","title":"Overview","text":"This section gives an overview and short examples on how to work with the FMIFlux.jl library. For further advise on working with FMUs, it is recommended to check the Documentation of the FMI.jl library","category":"page"},{"location":"tutorials/overview/","page":"Overview","title":"Overview","text":"The tutorials are grouped as followed:","category":"page"},{"location":"tutorials/overview/","page":"Overview","title":"Overview","text":"Still work in progress\nHow to set up a neural FMU\nHow to train a neural FMU\nPlot the results","category":"page"},{"location":"examples/simple_hybrid_ME/#Creation-and-training-of-ME-NeuralFMUs","page":"Simple ME-NeuralFMU","title":"Creation and training of ME-NeuralFMUs","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Tutorial by Johannes Stoljar, Tobias Thummerer","category":"page"},{"location":"examples/simple_hybrid_ME/#License","page":"Simple ME-NeuralFMU","title":"License","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons, Johannes Stoljar","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Licensed under the MIT license. See LICENSE file in the project root for details.","category":"page"},{"location":"examples/simple_hybrid_ME/#Motivation","page":"Simple ME-NeuralFMU","title":"Motivation","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"This Julia Package is motivated by the application of hybrid modeling. This package enables the user to integrate his simulation model between neural networks (NeuralFMU). For this, the simulation model must be exported as FMU (functional mock-up unit), which corresponds to a widely used standard. The big advantage of hybrid modeling with artificial neural networks is, that effects that are difficult to model (because they might be unknown) can be easily learned by the neural networks. For this purpose, the NeuralFMU is trained with measurement data containing the unmodeled physical effect. The final product is a simulation model including the orignially unmodeled effects. Another big advantage of the NeuralFMU is that it works with little data, because the FMU already contains the characterisitic functionality of the simulation and only the missing effects are added.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"NeuralFMUs need not to be as easy as in this example. Basically a NeuralFMU can combine different ANN topologies that manipulate any FMU-input (system state, system inputs, time) and any FMU-output (system state derivative, system outputs, other system variables). However, for this example a NeuralFMU topology as shown in the following picture is used.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: NeuralFMU.svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"NeuralFMU (ME) from [1].","category":"page"},{"location":"examples/simple_hybrid_ME/#Introduction-to-the-example","page":"Simple ME-NeuralFMU","title":"Introduction to the example","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In this example, simplified modeling of a one-dimensional spring pendulum (without friction) is compared to a model of the same system that includes a nonlinear friction model. The FMU with the simplified model will be named simpleFmu in the following and the model with the friction will be named realFmu. At the beginning, the actual state of both simulations is shown, whereby clear deviations can be seen in the graphs. The realFmu serves as a reference graph. The simpleFmu is then integrated into a NeuralFMU architecture and a training of the entire network is performed. After the training the final state is compared again to the realFmu. It can be clearly seen that by using the NeuralFMU, learning of the friction process has taken place.  ","category":"page"},{"location":"examples/simple_hybrid_ME/#Target-group","page":"Simple ME-NeuralFMU","title":"Target group","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The example is primarily intended for users who work in the field of first principle and/or hybrid modeling and are further interested in hybrid model building. The example wants to show how simple it is to combine FMUs with machine learning and to illustrate the advantages of this approach.","category":"page"},{"location":"examples/simple_hybrid_ME/#Other-formats","page":"Simple ME-NeuralFMU","title":"Other formats","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Besides this Jupyter Notebook there is also a Julia file with the same name, which contains only the code cells and for the documentation there is a Markdown file corresponding to the notebook.  ","category":"page"},{"location":"examples/simple_hybrid_ME/#Getting-started","page":"Simple ME-NeuralFMU","title":"Getting started","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/#Installation-prerequisites","page":"Simple ME-NeuralFMU","title":"Installation prerequisites","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":" Description Command Alternative\n1. Enter Package Manager via ] \n2. Install FMI via add FMI add \" https://github.com/ThummeTo/FMI.jl \"\n3. Install FMIFlux via add FMIFlux add \" https://github.com/ThummeTo/FMIFlux.jl \"\n4. Install Flux via add Flux \n5. Install DifferentialEquations via add DifferentialEquations \n6. Install Plots via add Plots ","category":"page"},{"location":"examples/simple_hybrid_ME/#Code-section","page":"Simple ME-NeuralFMU","title":"Code section","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"To run the example, the previously installed packages must be included. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# imports\nusing FMI\nusing FMIFlux\nusing Flux\nusing DifferentialEquations: Tsit5\nimport Plots","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"After importing the packages, the path to the Functional Mock-up Units (FMUs) is set. The FMU is a model exported meeting the Functional Mock-up Interface (FMI) Standard. The FMI is a free standard (fmi-standard.org) that defines a container and an interface to exchange dynamic models using a combination of XML files, binaries and C code zipped into a single file. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The objec-orientated structure of the SpringPendulum1D (simpleFmu) can be seen in the following graphic and corresponds to a simple modeling.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In contrast, the model SpringFrictionPendulum1D (realFmu) is somewhat more accurate, because it includes a friction component. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Here the path for the SpringPendulum1D and the SpringFrictionPendulum1D model is set: ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"simpleFmuPath = joinpath(dirname(@__FILE__), \"../model/SpringPendulum1D.fmu\")\nrealFmuPath = joinpath(dirname(@__FILE__), \"../model/SpringFrictionPendulum1D.fmu\")\nprintln(\"SimpleFmu path: \", simpleFmuPath)\nprintln(\"RealFmu path: \", realFmuPath)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"SimpleFmu path: ../model/SpringPendulum1D.fmu\nRealFmu path: ../model/SpringFrictionPendulum1D.fmu","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Next, the start time and end time of the simulation are set. Finally, a step size is specified to store the results of the simulation at these time steps.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"tStart = 0.0\ntStep = 0.01\ntStop = 5.0\ntSave = collect(tStart:tStep:tStop)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"501-element Vector{Float64}:\n 0.0\n 0.01\n 0.02\n 0.03\n 0.04\n 0.05\n 0.06\n 0.07\n 0.08\n 0.09\n 0.1\n 0.11\n 0.12\n ⋮\n 4.89\n 4.9\n 4.91\n 4.92\n 4.93\n 4.94\n 4.95\n 4.96\n 4.97\n 4.98\n 4.99\n 5.0","category":"page"},{"location":"examples/simple_hybrid_ME/#RealFmu","page":"Simple ME-NeuralFMU","title":"RealFmu","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In the next lines of code the FMU of the realFMU model is loaded and instantiated.  ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"realFmu = fmiLoad(realFmuPath)\nfmiInstantiate!(realFmu; loggingOn=false)\nfmiInfo(realFmu)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"┌ Info: fmi2Unzip(...): Successfully unzipped 28 files at `C:\\Users\\JOHANN~1\\AppData\\Local\\Temp\\fmijl_XcT5D4\\SpringFrictionPendulum1D`.\n└ @ FMI C:\\Users\\Johannes Stoljar\\.julia\\packages\\FMI\\l4qPg\\src\\FMI2.jl:273\n┌ Info: fmi2Load(...): FMU supports both CS and ME, using CS as default if nothing specified.\n└ @ FMI C:\\Users\\Johannes Stoljar\\.julia\\packages\\FMI\\l4qPg\\src\\FMI2.jl:376\n┌ Info: fmi2Load(...): FMU resources location is `file:///C:/Users/JOHANN~1/AppData/Local/Temp/fmijl_XcT5D4/SpringFrictionPendulum1D/resources`\n└ @ FMI C:\\Users\\Johannes Stoljar\\.julia\\packages\\FMI\\l4qPg\\src\\FMI2.jl:384\n\n\n#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringFrictionPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{b02421b8-652a-4d48-9ffc-c2b223aa1b94}\n\tGeneration tool:\t\tDymola Version 2020x (64-bit), 2019-10-10\n\tGeneration time:\t\t2021-11-23T13:36:30Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t24\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\", \"mass.v_relfric\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Both the start and end time are set via the fmiSetupExperiment() function. The experiment is initialized to get the information of the continuous states. You can get all continuous states of a FMU by the function fmiGetContinuousStates() and this is also done for the realFmu. It has two states: The first state is the position of the mass, which is initilized with 05m, the second state is the velocity, which is initialized with 0fracms.   ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"fmiSetupExperiment(realFmu, tStart, tStop)\n\nfmiEnterInitializationMode(realFmu)\nfmiExitInitializationMode(realFmu)\n\nx₀ = fmiGetContinuousStates(realFmu)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"2-element Vector{Float64}:\n 0.5\n 0.0","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In the following code block the realFmu is simulated, still specifying which variables are included. After the simulation is finished the result of the realFmu can be plotted. This plot also serves as a reference for the other model (simpleFmu).","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"vrs = [\"mass.s\", \"mass.v\", \"mass.a\", \"mass.f\"]\n_, realSimData = fmiSimulate(realFmu, tStart, tStop; recordValues=vrs, saveat=tSave, setup=false, reset=false)\nfmiPlot(realFmu, vrs, realSimData)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"After the plots are created, the FMU is unloaded.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"fmiUnload(realFmu)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The data from the simualtion of the realFmu, are divided into position and velocity data. These data will be needed later. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"velReal = collect(data[2] for data in realSimData.saveval)\nposReal = collect(data[1] for data in realSimData.saveval)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"501-element Vector{Float64}:\n 0.5\n 0.5002147350958549\n 0.5008572068150906\n 0.5019307343013393\n 0.5034377791759037\n 0.5053797361931734\n 0.507757421354132\n 0.5105710760625108\n 0.5138202661486302\n 0.5175035429290001\n 0.5216187663581402\n 0.5261643784845171\n 0.5311361825547609\n ⋮\n 1.0618338496933084\n 1.0629441718413108\n 1.0639256972572486\n 1.0647763670106132\n 1.06549412855799\n 1.0660771282511987\n 1.066523587371857\n 1.066831801521633\n 1.0670001400125004\n 1.0670339828286313\n 1.0670339828276312\n 1.067033982826631","category":"page"},{"location":"examples/simple_hybrid_ME/#SimpleFmu","page":"Simple ME-NeuralFMU","title":"SimpleFmu","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The following lines load, instantiate, simulate and plot the simpleFmu just like the realFmu. The differences between both systems can be clearly seen from the plots. In the plot for the realFmu it can be seen that the oscillation continues to decrease due to the effect of the friction. If you would simulate long enough, the oscillation would come to a standstill in a certain time. The oscillation in the simpleFmu behaves differently, since the friction was not taken into account here. The oscillation in this model would continue to infinity with the same oscillation amplitude. From this observation the desire of an improvement of this model arises.     ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"simpleFmu = fmiLoad(simpleFmuPath)\n\nfmiInstantiate!(simpleFmu; loggingOn=false)\nfmiInfo(simpleFmu)\n\nvrs = [\"mass.s\", \"mass.v\", \"mass.a\"]\n_, simpleSimData = fmiSimulate(simpleFmu, tStart, tStop; recordValues=vrs, saveat=tSave, reset=false)\nfmiPlot(simpleFmu, vrs, simpleSimData)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{5030e5a4-87c0-42cf-8779-74ebea1906aa}\n\tGeneration tool:\t\tDymola Version 2020x (64-bit), 2019-10-10\n\tGeneration time:\t\t2021-07-21T05:28:53Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t0\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################\n\n\n┌ Info: fmi2Unzip(...): Successfully unzipped 28 files at `C:\\Users\\JOHANN~1\\AppData\\Local\\Temp\\fmijl_bWEjI0\\SpringPendulum1D`.\n└ @ FMI C:\\Users\\Johannes Stoljar\\.julia\\packages\\FMI\\l4qPg\\src\\FMI2.jl:273\n┌ Info: fmi2Load(...): FMU supports both CS and ME, using CS as default if nothing specified.\n└ @ FMI C:\\Users\\Johannes Stoljar\\.julia\\packages\\FMI\\l4qPg\\src\\FMI2.jl:376\n┌ Info: fmi2Load(...): FMU resources location is `file:///C:/Users/JOHANN~1/AppData/Local/Temp/fmijl_bWEjI0/SpringPendulum1D/resources`\n└ @ FMI C:\\Users\\Johannes Stoljar\\.julia\\packages\\FMI\\l4qPg\\src\\FMI2.jl:384","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The data from the simualtion of the simpleFmu, are divided into position and velocity data. These data will be needed later to plot the results. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"velSimple = collect(data[2] for data in simpleSimData.saveval)\nposSimple = collect(data[1] for data in simpleSimData.saveval)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"501-element Vector{Float64}:\n 0.5\n 0.5003017486819993\n 0.5012013738965729\n 0.5026995396955733\n 0.5047948922822549\n 0.5074848828353776\n 0.5107669098963398\n 0.5146380970115599\n 0.5190939866425227\n 0.5241313516074874\n 0.5297437685244978\n 0.5359273025527665\n 0.5426739933868466\n ⋮\n 1.6817454106640481\n 1.6860262621029507\n 1.6897211631373532\n 1.6928264987575015\n 1.6953392775960465\n 1.6972564609104965\n 1.698576276381512\n 1.6992975610979462\n 1.6994196580640215\n 1.6989425410415007\n 1.6978667510389276\n 1.6961926527257059","category":"page"},{"location":"examples/simple_hybrid_ME/#Loss-function","page":"Simple ME-NeuralFMU","title":"Loss function","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In order to train our model, a loss function must be implemented. The solver of the NeuralFMU can calculate the gradient of the loss function. The gradient descent is needed to adjust the weights in the neural network so that the sum of the error is reduced and the model becomes more accurate.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The loss function in this implmentation consists of the mean squared error (mse) from the real position of the realFmu simulation (posReal) and the position data of the network (posNet). $ mse = \\frac{1}{n} \\sum\\limits_{i=0}^n (posReal[i] - posNet[i])^2 $","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"As it is indicated with the comments, one could also additionally consider the mse from the real velocity (velReal) and the velocity from the network (velNet). The error in this case would be calculated from the sum of both errors.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# loss function for training\nfunction lossSum()\n    solution = neuralFmu(x₀, tStart)\n\n    posNet = collect(data[1] for data in solution.u)\n    #velNet = collect(data[2] for data in solution.u)\n\n    Flux.Losses.mse(posReal, posNet) #+ Flux.Losses.mse(velReal, velNet)\nend","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"lossSum (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_ME/#Callback","page":"Simple ME-NeuralFMU","title":"Callback","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"To output the loss in certain time intervals, a callback is implemented as a function in the following. Here a counter is incremented, every tenth pass the loss function is called and the average error is printed out.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# callback function for training\nglobal counter = 0\nfunction callb()\n    global counter += 1\n\n    if counter % 20 == 1\n        avgLoss = lossSum()\n        @info \"Loss [$counter]: $(round(avgLoss, digits=5))   Avg displacement in data: $(round(sqrt(avgLoss), digits=5))\"\n    end\nend","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"callb (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_ME/#Structure-of-the-NeuralFMU","page":"Simple ME-NeuralFMU","title":"Structure of the NeuralFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In the following, the topology of the NeuralFMU is constructed. It consists of an input layer, which then leads into the simpleFmu model. The ME-FMU computes the state derivatives for a given system state. Following the simpleFmu is a dense layer that has exactly as many inputs as the model has states (and therefore state derivatives). The output of this layer consists of 16 output nodes and a tanh activation function. The next layer has 16 input and output nodes with the same activation function. The last layer is again a dense layer with 16 input nodes and the number of states as outputs. Here, it is important that no tanh-activation function follows, because otherwise the pendulums state values would be limited to the interval -11.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# NeuralFMU setup\nnumStates = fmiGetNumberOfStates(simpleFmu)\n\nnet = Chain(inputs -> fmiDoStepME(simpleFmu, inputs),\n            Dense(numStates, 16, tanh),\n            Dense(16, 16, tanh),\n            Dense(16, numStates))","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Chain(\n  var\"#11#12\"(),\n  Dense(2, 16, tanh),                   \u001b[90m# 48 parameters\u001b[39m\n  Dense(16, 16, tanh),                  \u001b[90m# 272 parameters\u001b[39m\n  Dense(16, 2),                         \u001b[90m# 34 parameters\u001b[39m\n)\u001b[90m                   # Total: 6 arrays, \u001b[39m354 parameters, 1.758 KiB.","category":"page"},{"location":"examples/simple_hybrid_ME/#Definition-of-the-NeuralFMU","page":"Simple ME-NeuralFMU","title":"Definition of the NeuralFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The instantiation of the ME-NeuralFMU is done as a one-liner. The FMU (simpleFmu), the structure of the network net, start tStart and end time tStop, the numerical solver Tsit5() and the time steps tSave for saving are specified.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"neuralFmu = ME_NeuralFMU(simpleFmu, net, (tStart, tStop), Tsit5(); saveat=tSave);","category":"page"},{"location":"examples/simple_hybrid_ME/#Plot-before-training","page":"Simple ME-NeuralFMU","title":"Plot before training","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Here the state trajactory of the simpleFmu is recorded. Doesn't really look like a pendulum yet, but the system is random initialized by default. In the later plots, the effect of learning can be seen.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"solutionBefore = neuralFmu(x₀, tStart)\nfmiPlot(simpleFmu, solutionBefore)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/#Training-of-the-NeuralFMU","page":"Simple ME-NeuralFMU","title":"Training of the NeuralFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"For the training of the NeuralFMU the parameters are extracted. The known ADAM optimizer for minimizing the gradient descent is used as further passing parameters. In addition, the previously defined loss and callback function, as well as the number of epochs are passed.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# train\nparamsNet = Flux.params(neuralFmu)\n\noptim = ADAM()\nFlux.train!(lossSum, paramsNet, Iterators.repeated((), 300), optim; cb=callb) ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"┌ Info: Loss [1]: 0.06754   Avg displacement in data: 0.25988\n└ @ Main In[12]:8\n┌ Info: Loss [21]: 0.04504   Avg displacement in data: 0.21223\n└ @ Main In[12]:8\n┌ Info: Loss [41]: 0.04205   Avg displacement in data: 0.20507\n└ @ Main In[12]:8\n┌ Info: Loss [61]: 0.04021   Avg displacement in data: 0.20053\n└ @ Main In[12]:8\n┌ Info: Loss [81]: 0.03964   Avg displacement in data: 0.1991\n└ @ Main In[12]:8\n┌ Info: Loss [101]: 0.03928   Avg displacement in data: 0.19819\n└ @ Main In[12]:8\n┌ Info: Loss [121]: 0.03893   Avg displacement in data: 0.19731\n└ @ Main In[12]:8\n┌ Info: Loss [141]: 0.03866   Avg displacement in data: 0.19662\n└ @ Main In[12]:8\n┌ Info: Loss [161]: 0.03815   Avg displacement in data: 0.19532\n└ @ Main In[12]:8\n┌ Info: Loss [181]: 0.03756   Avg displacement in data: 0.1938\n└ @ Main In[12]:8\n┌ Info: Loss [201]: 0.03656   Avg displacement in data: 0.1912\n└ @ Main In[12]:8\n┌ Info: Loss [221]: 0.03433   Avg displacement in data: 0.18529\n└ @ Main In[12]:8\n┌ Info: Loss [241]: 0.02628   Avg displacement in data: 0.16212\n└ @ Main In[12]:8\n┌ Info: Loss [261]: 0.00817   Avg displacement in data: 0.09037\n└ @ Main In[12]:8\n┌ Info: Loss [281]: 0.00476   Avg displacement in data: 0.069\n└ @ Main In[12]:8","category":"page"},{"location":"examples/simple_hybrid_ME/#Comparison-of-the-plots","page":"Simple ME-NeuralFMU","title":"Comparison of the plots","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Here three plots are compared with each other and only the position of the mass is considered. The first plot represents the simpleFmu, the second represents the realFmu (reference) and the third plot represents the result after training the NeuralFMU. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# plot results mass.s\nsolutionAfter = neuralFmu(x₀, tStart)\n\nfig = Plots.plot(xlabel=\"t [s]\", ylabel=\"mass position [m]\", linewidth=2,\n                 xtickfontsize=12, ytickfontsize=12,\n                 xguidefontsize=12, yguidefontsize=12,\n                 legendfontsize=8, legend=:topright)\n\nposNeuralFmu = collect(data[1] for data in solutionAfter.u)\n\nPlots.plot!(fig, tSave, posSimple, label=\"SimpleFMU\", linewidth=2)\nPlots.plot!(fig, tSave, posReal, label=\"RealFMU\", linewidth=2)\nPlots.plot!(fig, tSave, posNeuralFmu, label=\"NeuralFMU (300 epochs)\", linewidth=2)\nfig ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/#Continue-training-and-plotting","page":"Simple ME-NeuralFMU","title":"Continue training and plotting","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"As can be seen from the previous figure, the plot of the NeuralFMU has not yet fully converged against the realFmu, so the training of the NeuralFMU is continued. After further training, the plot of NeuralFMU is added to the figure again. The effect of the longer training is well recognizable, since the plot of the NeuralFMU had further converged. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Flux.train!(lossSum, paramsNet, Iterators.repeated((), 700), optim; cb=callb) \n# plot results mass.s\nsolutionAfter = neuralFmu(x₀, tStart)\nposNeuralFmu = collect(data[1] for data in solutionAfter.u)\nPlots.plot!(fig, tSave, posNeuralFmu, label=\"NeuralFMU (1000 epochs)\", linewidth=2)\nfig ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"┌ Info: Loss [301]: 0.00413   Avg displacement in data: 0.06423\n└ @ Main In[12]:8\n┌ Info: Loss [321]: 0.00381   Avg displacement in data: 0.06172\n└ @ Main In[12]:8\n┌ Info: Loss [341]: 0.00353   Avg displacement in data: 0.05937\n└ @ Main In[12]:8\n┌ Info: Loss [361]: 0.00329   Avg displacement in data: 0.05739\n└ @ Main In[12]:8\n┌ Info: Loss [381]: 0.00309   Avg displacement in data: 0.05559\n└ @ Main In[12]:8\n┌ Info: Loss [401]: 0.00291   Avg displacement in data: 0.05393\n└ @ Main In[12]:8\n┌ Info: Loss [421]: 0.00274   Avg displacement in data: 0.05236\n└ @ Main In[12]:8\n┌ Info: Loss [441]: 0.00259   Avg displacement in data: 0.05085\n└ @ Main In[12]:8\n┌ Info: Loss [461]: 0.00244   Avg displacement in data: 0.04939\n└ @ Main In[12]:8\n┌ Info: Loss [481]: 0.0023   Avg displacement in data: 0.04796\n└ @ Main In[12]:8\n┌ Info: Loss [501]: 0.00217   Avg displacement in data: 0.04654\n└ @ Main In[12]:8\n┌ Info: Loss [521]: 0.00204   Avg displacement in data: 0.04513\n└ @ Main In[12]:8\n┌ Info: Loss [541]: 0.00191   Avg displacement in data: 0.04372\n└ @ Main In[12]:8\n┌ Info: Loss [561]: 0.00179   Avg displacement in data: 0.04228\n└ @ Main In[12]:8\n┌ Info: Loss [581]: 0.00167   Avg displacement in data: 0.04082\n└ @ Main In[12]:8\n┌ Info: Loss [601]: 0.00155   Avg displacement in data: 0.03933\n└ @ Main In[12]:8\n┌ Info: Loss [621]: 0.00143   Avg displacement in data: 0.03777\n└ @ Main In[12]:8\n┌ Info: Loss [641]: 0.0013   Avg displacement in data: 0.0361\n└ @ Main In[12]:8\n┌ Info: Loss [661]: 0.00118   Avg displacement in data: 0.03439\n└ @ Main In[12]:8\n┌ Info: Loss [681]: 0.00106   Avg displacement in data: 0.03263\n└ @ Main In[12]:8\n┌ Info: Loss [701]: 0.00094   Avg displacement in data: 0.03073\n└ @ Main In[12]:8\n┌ Info: Loss [721]: 0.00083   Avg displacement in data: 0.0288\n└ @ Main In[12]:8\n┌ Info: Loss [741]: 0.00072   Avg displacement in data: 0.02683\n└ @ Main In[12]:8\n┌ Info: Loss [761]: 0.00062   Avg displacement in data: 0.02483\n└ @ Main In[12]:8\n┌ Info: Loss [781]: 0.00052   Avg displacement in data: 0.02287\n└ @ Main In[12]:8\n┌ Info: Loss [801]: 0.00044   Avg displacement in data: 0.02096\n└ @ Main In[12]:8\n┌ Info: Loss [821]: 0.00037   Avg displacement in data: 0.01913\n└ @ Main In[12]:8\n┌ Info: Loss [841]: 0.00031   Avg displacement in data: 0.01749\n└ @ Main In[12]:8\n┌ Info: Loss [861]: 0.00026   Avg displacement in data: 0.01605\n└ @ Main In[12]:8\n┌ Info: Loss [881]: 0.00022   Avg displacement in data: 0.01482\n└ @ Main In[12]:8\n┌ Info: Loss [901]: 0.00019   Avg displacement in data: 0.01377\n└ @ Main In[12]:8\n┌ Info: Loss [921]: 0.00017   Avg displacement in data: 0.0129\n└ @ Main In[12]:8\n┌ Info: Loss [941]: 0.00015   Avg displacement in data: 0.01219\n└ @ Main In[12]:8\n┌ Info: Loss [961]: 0.00013   Avg displacement in data: 0.01161\n└ @ Main In[12]:8\n┌ Info: Loss [981]: 0.00012   Avg displacement in data: 0.01113\n└ @ Main In[12]:8","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Finally, the FMU is cleaned-up.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"fmiUnload(simpleFmu)","category":"page"},{"location":"examples/simple_hybrid_ME/#Summary","page":"Simple ME-NeuralFMU","title":"Summary","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Based on the plots, it can be seen that the NeuralFMU is able to adapt the friction model of the realFmu. After 300 runs, the curves do not overlap very well, but this can be achieved by longer training (1000 runs) or a better initialization.","category":"page"},{"location":"examples/simple_hybrid_ME/#Source","page":"Simple ME-NeuralFMU","title":"Source","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"[1] Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. NeuralFMU: towards structural integration of FMUs into neural networks. Martin Sjölund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, Linköping, Sweden, September 20-24, 2021. Linköping University Electronic Press, Linköping (Linköping Electronic Conference Proceedings ; 181), 297-306. DOI: 10.3384/ecp21181297","category":"page"},{"location":"#FMIFlux.jl-Documentation","page":"Introduction","title":"FMIFlux.jl Documentation","text":"","category":"section"},{"location":"#What-is-FMIFlux.jl?","page":"Introduction","title":"What is FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"FMIFlux.jl is a free-to-use software library for the Julia programming language, which offers the ability to setup NeuralFMUs: You can place FMUs (fmi-standard.org) simply inside any feed-forward NN topology and still keep the resulting hybrid model trainable with a standard AD training process.","category":"page"},{"location":"#How-can-I-install-FMIFlux.jl?","page":"Introduction","title":"How can I install FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"open a Julia-Command-Window, activate your preferred environment\ngo to package manager using ] and type add FMIFlux","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> ]\n\n(v.1.5.4)> add FMIFlux","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"If you want to check that everything works correctly, you can run the tests bundled with FMIFlux.jl:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> using Pkg\n\njulia> Pkg.test(\"FMIFlux\")","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Additionally, you can check the version of FMIFlux.jl that you have installed with the status command.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> ]\n(v.1.5.4)> status FMIFlux","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Throughout the rest of the tutorial we assume that you have installed the FMIFlux.jl package and have typed using FMIFlux which loads the package:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> using FMIFlux","category":"page"},{"location":"#How-the-documentation-is-structured?","page":"Introduction","title":"How the documentation is structured?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Having a high-level overview of how this documentation is structured will help you know where to look for certain things. The three main parts of the documentation are :","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The Tutorials section explains all the necessary steps to work with the library.\nThe examples section gives insight in what is possible with this Library while using short and easily understandable code snippets\nThe library functions sections contains all the documentation to the functions provided by this library","category":"page"},{"location":"#What-is-currently-supported-in-FMIFlux.jl?","page":"Introduction","title":"What is currently supported in FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"building and training ME-NeuralFMUs with the default Flux-Front-End\nbuilding and training CS-NeuralFMUs","category":"page"},{"location":"#What-is-under-development-in-FMIFlux.jl?","page":"Introduction","title":"What is under development in FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"different modes for sensitivity estimation\ndocumentation\nmore examples","category":"page"},{"location":"#FMIFlux.jl-Index","page":"Introduction","title":"FMIFlux.jl Index","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"","category":"page"}]
}
