var documenterSearchIndex = {"docs":
[{"location":"examples/workshops/","page":"Pluto Workshops","title":"Pluto Workshops","text":"Pluto based notebooks, that can easyly be executed on your own Pluto-Setup.","category":"page"},{"location":"examples/workshops/","page":"Pluto Workshops","title":"Pluto Workshops","text":"<iframe src=\"../pluto-src/index.html\" style=\"height:500px;width:100%;\"></iframe>","category":"page"},{"location":"contents/","page":"Contents","title":"Contents","text":"Depth = 2","category":"page"},{"location":"examples/juliacon_2023/#Using-NeuralODEs-in-real-life-applications","page":"JuliaCon 2023","title":"Using NeuralODEs in real life applications","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Tutorial by Tobias Thummerer | Last edit: September 24 2024","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"This workshop was held at the JuliaCon 2023 | July 25 2023 | MIT (Boston, USA)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Keywords: #NeuralODE, #NeuralFMU, #SciML, #PeNODE, #HybridModeling","category":"page"},{"location":"examples/juliacon_2023/#Workshop-Video","page":"JuliaCon 2023","title":"Workshop Video","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: YouTube Video of Workshop)","category":"page"},{"location":"examples/juliacon_2023/#License","page":"JuliaCon 2023","title":"License","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# Copyright (c) 2023 Tobias Thummerer, Lars Mikelsons\n# Licensed under the MIT license. \n# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details.\n\n# This workshop was held at the JuliaCon2023 @ MIT (Boston)","category":"page"},{"location":"examples/juliacon_2023/#Introduction","page":"JuliaCon 2023","title":"Introduction","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"NeuralODEs lead to amazing results in academic examples. But the expectations are often being disappointed as soon as one tries to adapt this concept for real life use cases. Bad convergence behavior, handling of discontinuities and/or instabilities are just some of the stumbling blocks that might pop up during the first steps. During the workshop, we want to show how to integrate real life industrial models in NeuralODEs using FMI and present sophisticated training strategies.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"This tutorial can be used in two ways:","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"As a single script, showing how a NeuralFMU can be setup and trained. Results can be loaded from a precomputed hyperparameter optimization.\nAs a module (see sections Optional: Organize as module) together with the file juliacon_2023_distributedhyperopt.jl to perform your own distributed hyperparameter optimization.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"This workshops divides into five sections:","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Installing / Loading the Packages\nLoading FMU & Data\nNeuralFMU setup\nTraining the NeuralFMU\nResults","category":"page"},{"location":"examples/juliacon_2023/#1.-Installing-/-Loading-the-Packages","page":"JuliaCon 2023","title":"1. Installing / Loading the Packages","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Before we start modeling our NeuralODE, we load all required packages. If some packages are still missing, install them by typing import Pkg; Pkg.add(\"[PKG-NAME]\").","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# Loading the required libraries\nusing FMI           # import FMUs into Julia \nusing FMIFlux       # for NeuralFMUs\nusing FMIZoo        # a collection of demo models, including the VLDM\nusing FMIFlux.Flux  # Machine Learning in Julia\nusing DifferentialEquations: Tsit5 # for picking a NeuralFMU solver\n\nimport JLD2         # data format for saving/loading parameters\n\nimport Random       # for fixing the random seed\nusing Plots         # plotting results","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Beside the packages, we use another little script that includes some nice plotting functions specially for this workshop.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# a helper file with some predefined functions to make \"things look nicer\", but are not really relevant to the topic\ninclude(joinpath(@__DIR__, \"juliacon_2023_helpers.jl\"));","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Because notebooks can't handle progress bars, we disable progress bar printing - but feel free to enable it if you are using the code outside of a jupyter notebook. The progress bar gives further helpful information, like the estimated remaining computation time for simulation and training.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# disable progress bars in jupyter notebook\nshowProgress=false;","category":"page"},{"location":"examples/juliacon_2023/#2.-Loading-FMU-and-Data","page":"JuliaCon 2023","title":"2. Loading FMU & Data","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Before starting with hybrid modeling, we load in the used training data and our FMU of the VLDM. We simulate the FMU, plot the results and compare them to data. ","category":"page"},{"location":"examples/juliacon_2023/#2.1-Loading-measurement-data","page":"JuliaCon 2023","title":"2.1 Loading measurement data","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We start by loading in the data (training and validation) used in this tutorial from FMIZoo.jl - a container library for different system model FMUs and corresponding data.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Note: There where two measurements done, so data is a mean value with some deviation around (not an exact line).","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# FMIZoo.jl supports different data sampling rates (by interpolation), sample length for data is 0.1s\ndt = 0.1 \n\n# load data (training) from FMIZoo.jl\ndata = VLDM(:train, dt=dt) \n\n# plot the velocity consumption (training data)\nplot(data.speed_t,              # the time points the speed was captures (from data)\n     data.speed_val;            # the speeds at the considered time points (from data)\n     ribbon=data.speed_dev,     # a `ribbon` for the speed deviation - so the `uncertainty` because we made two measurements - but don't expect too much to see (very little uncertainty)\n     fillalpha=0.3,             # alpha value for the ribbon\n     label=\"Data\",              # the plot label\n     title=\"WLTC (first 40%)\",  # plot title\n     xlabel=\"t [s]\",            # plot x-label\n     ylabel=\"velocity [m/s]\")   # plot y-label","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Further, we load validation data and have a look on it, too.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# load data (validation) from FMIZoo.jl\ndata_validation = VLDM(:validate, dt=dt)\n\n# plot the velocity consumption (validation data)\nplot(data_validation.speed_t, data_validation.speed_val; label=\"Data\", ribbon=data_validation.speed_dev, fillalpha=0.3, title=\"WLTC (complete)\", xlabel=\"t [s]\", ylabel=\"velocity [m/s]\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Let's extract a simulation starting time tStart and stopping time tStop from data - so we simulate as far as data is available. tSave are the points in time we want our ODE solution being saved later.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# start (`tStart`) and stop time (`tStop`) for simulation, saving time points for ODE solver (`tSave`)\ntStart = data.consumption_t[1]\ntStop = data.consumption_t[end]\ntSave = data.consumption_t","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"5838-element Vector{Float64}:\n   0.0\n   0.1\n   0.2\n   0.3\n   0.4\n   0.5\n   0.6\n   0.7\n   0.8\n   0.9\n   1.0\n   1.1\n   1.2\n   â‹®\n 582.6\n 582.7\n 582.8\n 582.9\n 583.0\n 583.1\n 583.2\n 583.3\n 583.4\n 583.5\n 583.6\n 583.7","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"So you can see time points are sampled with dt=0.1 as specified and the cycle ranges from 00s to 5837s.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Next is to get a value for the start state x0, so the initial state to solve the FMU and NeuralFMU.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# get start state vector from data (FMIZoo)\nx0 = FMIZoo.getStateVector(data,    # the data container\n                           tStart)  # the point in time where we want the state","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"6-element Vector{Float64}:\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"In this special case, it's all zero, but this is not the default over different system!","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Further, we can check for the loaded FMU parameters, that are paths to the used characteristic maps used in the model.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# have a look on the FMU parameters (these are the file paths to the characteristic maps, remaining parameters are set to default by the FMU)\ndisplay(data.params)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Dict{String, Any} with 3 entries:\n  \"peFileName\" => \"C:\\\\Users\\\\runneradmin\\\\.julia\\\\packages\\\\FMIZoo\\\\WtBM9\\\\srcâ€¦\n  \"edFileName\" => \"C:\\\\Users\\\\runneradmin\\\\.julia\\\\packages\\\\FMIZoo\\\\WtBM9\\\\srcâ€¦\n  \"dcFileName\" => \"C:\\\\Users\\\\runneradmin\\\\.julia\\\\packages\\\\FMIZoo\\\\WtBM9\\\\srcâ€¦","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"After that, we load the FMU and have a look on its model meta data.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# load our FMU of the VLDM (we take it from the FMIZoo.jl, exported with Dymola 2020x)\nfmu = loadFMU(\"VLDM\", \"Dymola\", \"2020x\"; type=:ME) \n\n# let's have a look on the model meta data\ninfo(fmu)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tLongitudinaldynamic.LongitudinaldynamicmodelContinuous\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{669889ab-7ab7-4fac-be92-96b6cd0b86a6}\n\tGeneration tool:\t\tDymola Version 2020x (64-bit), 2019-10-10\n\tGeneration time:\t\t2022-07-22T09:32:50Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t28\n\tInputs:\t\t\t\t0\n\n\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t6\n\t\t33554432 [\"driver.accelerationPedalController.PI.x\"]\n\t\t33554433 [\"driver.brakePedalController.PI.x\"]\n\t\t33554434 [\"drivingCycle.s\"]\n\t\t33554435 [\"dynamics.accelerationCalculation.integrator.y\"]\n\t\t33554436 [\"dynamics.accelerationCalculation.limiter.u\", \"dynamics.accelerationCalculation.limIntegrator.y\", \"dynamics.accelerationCalculation.limiter.simplifiedExpr\"]\n\t\t33554437 [\"result.integrator.y\"]\n\tParameters:\t\t\t102\n\t\t16777216 [\"i_gear\"]\n\t\t16777217 [\"rho_L\"]\n\t\t16777218 [\"vehMass\"]\n\t\t16777219 [\"payload\"]\n\t\t...\n\t\t16777303 [\"dynamics.accelerationCalculation.limIntegrator.y_start\"]\n\t\t16777304 [\"dynamics.accelerationCalculation.limiter.uMax\"]\n\t\t16777305 [\"dynamics.accelerationCalculation.limiter.uMin\"]\n\t\t16777306 [\"result.integrator.k\"]\n\t\t16777307 [\"result.integrator.y_start\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tLongitudinaldynamic_LongitudinaldynamicmodelContinuous\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tLongitudinaldynamic_LongitudinaldynamicmodelContinuous\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"One can find many useful things, like the number of states (6), inputs (0) and outputs (0), their names and information about supported features. ","category":"page"},{"location":"examples/juliacon_2023/#2.2-Simulating-the-FMU","page":"JuliaCon 2023","title":"2.2 Simulating the FMU","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Simulating is as easy as calling simulate. Note, that we are putting in the parameter dictionary data.params from above. This FMU has many events, these are detected and handled automatically by FMI.jl.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# let's run a simulation from `tStart` to `tStop`, use the parameters we just viewed for the simulation run\nresultFMU = simulate(fmu,                       # the loaded FMU of the VLDM \n                    (tStart, tStop);            # the simulation time range\n                    parameters=data.params,     # the parameters for the VLDM\n                    showProgress=showProgress,  # show (or don't) the progres bar\n                    recordValues=:derivatives,  # record all state derivatives\n                    saveat=tSave)               # save solution points at `tSave`\ndisplay(resultFMU)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Model name:\n\tLongitudinaldynamic.LongitudinaldynamicmodelContinuous\nSuccess:\n\ttrue\nf(x)-Evaluations:\n\tIn-place: 441149\n\tOut-of-place: 0\nJacobian-Evaluations:\n\tâˆ‚xÌ‡_âˆ‚p: 0\n\tâˆ‚xÌ‡_âˆ‚x: 0\n\tâˆ‚xÌ‡_âˆ‚u: 0\n\tâˆ‚y_âˆ‚p: 0\n\tâˆ‚y_âˆ‚x: 0\n\tâˆ‚y_âˆ‚u: 0\n\tâˆ‚e_âˆ‚p: 0\n\tâˆ‚e_âˆ‚x: 0\n\tâˆ‚e_âˆ‚u: 0\n\tâˆ‚xr_âˆ‚xl: 0\nGradient-Evaluations:\n\tâˆ‚xÌ‡_âˆ‚t: 0\n\tâˆ‚y_âˆ‚t: 0\n\tâˆ‚e_âˆ‚t: 0\nCallback-Evaluations:\n\tCondition (event-indicators): 756903\n\tTime-Choice (event-instances): 58371\n\tAffect (event-handling): 58409\n\tSave values: 5838\n\tSteps completed: 62982\nStates [5838]:\n\t0.0\t[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n\t0.1\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 14.260000000955804]\n\t0.2\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 28.52000000095581]\n\t0.3\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 42.78000000095581]\n\t0.4\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 57.04000000095582]\n\t0.5\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 71.30000000095582]\n\t0.6\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 85.56000000095582]\n\t0.7\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 99.82000000095582]\n\t0.8\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 114.08000000095585]\n\t...\n\t583.7\t[-0.001916469855443799, -0.054120690516540136, 3131.826061088337, 3131.346886892768, -4.101183271996665e-5, 1.425987553834784e6]\nValues [5838]:\n\t0.0\t(0.0, 0.0, 0.0, 0.0, -0.1773972602739726, 142.6)\n\t0.1\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.2\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.3\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.4\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.5\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.6\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.7\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.8\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t...\n\t583.7\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\nEvents [58409]:\n\tTime-Event @ 0.01s (state-change: false)\n\tTime-Event @ 0.02s (state-change: false)\n\tTime-Event @ 0.03s (state-change: false)\n\tTime-Event @ 0.04s (state-change: false)\n\tTime-Event @ 0.05s (state-change: false)\n\tTime-Event @ 0.06s (state-change: false)\n\tTime-Event @ 0.07s (state-change: false)\n\tTime-Event @ 0.08s (state-change: false)\n\tTime-Event @ 0.09s (state-change: false)\n\t...\n\tTime-Event @ 583.7s (state-change: false)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"This way, you can see interesting metadata on the solution process, like the number of evaluations of the ODE-function, sensitivity or callback evaluations. ","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We can use the plot command to plot simulation results from FMUs, too!","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# Plot the simulation results\nfig = plot(resultFMU;                               # the simulation result from above \n           values=false,                            # don't plot values (:derivatives)\n           stateIndices=6:6,                        # only plot states 6 to 6 -> so state 6 ;-)\n           ylabel=\"Cumulative consumption [Ws]\",    # set the title for the y-label\n           label=\"FMU\")                             # title the plot line \n\n# further plot the (measurement) data values `consumption_val` and deviation between measurements `consumption_dev`\nplot!(fig, data.cumconsumption_t, data.cumconsumption_val; label=\"Data\", ribbon=data.cumconsumption_dev, fillalpha=0.3)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mfmiPlot(...): Number of time events (58370) exceeding 100, disabling automatic plotting of time events (can be forced with keyword `timeEvents=true`).","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"The simulation result we already know from the introduction!","category":"page"},{"location":"examples/juliacon_2023/#3.-NeuralFMU-setup","page":"JuliaCon 2023","title":"3. NeuralFMU setup","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: NeuralFMU)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Equipped with data and a simulation model, we can setup the NeuralFMU as introduced in the workshop.","category":"page"},{"location":"examples/juliacon_2023/#3.1-Pre-and-Post-Processing","page":"JuliaCon 2023","title":"3.1 Pre- and Post-Processing","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We gather the three derivative values from the last simulation run, to have values for initialization of the pre- and post-processing layers.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# variable we want to manipulate - why we are picking exactly these three is shown a few lines later ;-)\nmanipulatedDerVars = [\"der(dynamics.accelerationCalculation.integrator.y)\",\n                      \"der(dynamics.accelerationCalculation.limIntegrator.y)\",\n                      \"der(result.integrator.y)\"]\nmanipulatedDerVals = getValue(resultFMU, manipulatedDerVars)\n\n# what happens without proper transformation between FMU- and ANN-domain?\nplot(resultFMU.values.t, manipulatedDerVals[1,:][1]; label=\"original\", xlabel=\"t [s]\", ylabel=\"velocity [m/s]\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"But what happens if we put the velocity into the hyperbolic tangent function?","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"plot!(resultFMU.values.t, tanh.(manipulatedDerVals[1,:][1]); label=\"tanh(velocity)\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"It gets saturated drastically! That's why we need shift- and scale layers for online pre- and post-processing!","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We introduce the ShiftScale-layer for pre-processing our data.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# pre- and post-processing\npreProcess = ShiftScale(manipulatedDerVals);    # we put in the derivatives recorded above, FMIFlux shift and scales so we have a data mean of 0 and a standard deivation of 1 (other activation functions / ranges are possible!)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"How does the velocity look after pushing it through the ShiftScale-layer?","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"testVals = collect(tanh(preProcess(collect(val[t] for val in manipulatedDerVals))[1]) for t in 1:length(resultFMU.values.t))\nplot!(resultFMU.values.t, \n      testVals; \n      label=\"tanh(preProcess(velocity))\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"You can clearly see, that after pre-processing, the trajectory (green) still mirrors the dynamical behavior of the original system (blue), while the not pre-processed option (orange) just saturates values. ","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# we add some additional \"buffer\" - this is not necessary but helps to preserve peaks\npreProcess.scale[:] *= 0.25;    \n\n# initialize the postProcess as inverse of the preProcess, but only take indices 2 and 3 (we don't need 1, the vehicle velocity)\npostProcess = ScaleShift(preProcess; indices=2:3);","category":"page"},{"location":"examples/juliacon_2023/#3.2-Building-the-NeuralFMU","page":"JuliaCon 2023","title":"3.2 Building the NeuralFMU","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"To make this more usable, we put the entire NeuralFMU building process (including the pre- and post-processing we had a detailed look on) into a dedicated function build_FMU.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# function that builds the considered NeuralFMU on basis of a given FMU (FMI-Version 2.0) `f`\nfunction build_NFMU(f::FMU2)\n    \n    # pre- and post-processing\n    preProcess = ShiftScale(manipulatedDerVals)         # we put in the derivatives recorded above, FMIFlux shift and scales so we have a data mean of 0 and a standard deviation of 1\n    preProcess.scale[:] *= 0.25                         # add some additional \"buffer\"\n    postProcess = ScaleShift(preProcess; indices=2:3)   # initialize the postProcess as inverse of the preProcess, but only take indices 2 and 3 (we don't need 1, the vehicle velocity)\n\n    # cache\n    cache = CacheLayer()                        # allocate a cache layer\n    cacheRetrieve = CacheRetrieveLayer(cache)   # allocate a cache retrieve layer, link it to the cache layer\n\n    # we have two signals (acceleration, consumption) and two sources (ANN, FMU), so four gates:\n    # (1) acceleration from FMU (gate=1.0 | open)\n    # (2) consumption  from FMU (gate=1.0 | open)\n    # (3) acceleration from ANN (gate=0.0 | closed)\n    # (4) consumption  from ANN (gate=0.0 | closed)\n    # the accelerations [1,3] and consumptions [2,4] are paired\n    gates = ScaleSum([1.0, 1.0, 0.0, 0.0], [[1,3], [2,4]]) # gates with sum\n\n    # setup the NeuralFMU topology\n    model = Chain(x -> f(; x=x, dx_refs=:all),        # take `x`, put it into the FMU, retrieve all derivatives `dx`\n                  dx -> cache(dx),                    # cache `dx`\n                  dx -> dx[4:6],                      # forward only dx[4, 5, 6]\n                  preProcess,                         # pre-process `dx`\n                  Dense(3, 32, tanh),                 # Dense Layer 3 -> 32 with `tanh` activation\n                  Dense(32, 2, tanh),                 # Dense Layer 32 -> 2 with `tanh` activation \n                  postProcess,                        # post process `dx`\n                  dx -> cacheRetrieve(5:6, dx),       # dynamics FMU | dynamics ANN\n                  gates,                              # compute resulting dx from ANN + FMU\n                  dx -> cacheRetrieve(1:4, dx))       # stack together: dx[1,2,3,4] from cache + dx[5,6] from gates\n\n    solver = Tsit5()\n    \n    # new NeuralFMU \n    neuralFMU = ME_NeuralFMU(f,                 # the FMU used in the NeuralFMU \n                             model,             # the model we specified above \n                             (tStart, tStop),   # a default start ad stop time for solving the NeuralFMU\n                             solver;\n                             saveat=tSave)      # the time points to save the solution at\n    neuralFMU.modifiedState = false             # speed optimization (NeuralFMU state equals FMU state)\n    \n    return neuralFMU \nend","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"build_NFMU (generic function with 1 method)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Let's test the NeuralFMU: First, load the FMU und built a NeuralFMU from it.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# build NeuralFMU\nneuralFMU = build_NFMU(fmu);","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Next, do a simulation for a given start state x0 from FMIZoo.jl.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# simulate and plot the (uninitialized) NeuralFMU\nresultNFMU = neuralFMU(x0,                          # the start state to solve the ODE\n                       (tStart, tStop);             # the simulation range\n                       parameters=data.params,      # the parameters for the VLDM\n                       showProgress=showProgress,   # show progress (or not)\n                       saveat=tSave)                # the time points to save the solution at\n\ndisplay(resultNFMU)     ","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Model name:\n\tLongitudinaldynamic.LongitudinaldynamicmodelContinuous\nSuccess:\n\ttrue\nf(x)-Evaluations:\n\tIn-place: 409926\n\tOut-of-place: 0\nJacobian-Evaluations:\n\tâˆ‚xÌ‡_âˆ‚p: 0\n\tâˆ‚xÌ‡_âˆ‚x: 0\n\tâˆ‚xÌ‡_âˆ‚u: 0\n\tâˆ‚y_âˆ‚p: 0\n\tâˆ‚y_âˆ‚x: 0\n\tâˆ‚y_âˆ‚u: 0\n\tâˆ‚e_âˆ‚p: 0\n\tâˆ‚e_âˆ‚x: 0\n\tâˆ‚e_âˆ‚u: 0\n\tâˆ‚xr_âˆ‚xl: 0\nGradient-Evaluations:\n\tâˆ‚xÌ‡_âˆ‚t: 0\n\tâˆ‚y_âˆ‚t: 0\n\tâˆ‚e_âˆ‚t: 0\nCallback-Evaluations:\n\tCondition (event-indicators): 702407\n\tTime-Choice (event-instances): 58371\n\tAffect (event-handling): 58409\n\tSave values: 0\n\tSteps completed: 58440\nStates [5838]:\n\t0.0\t[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n\t0.1\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 14.260000000955804]\n\t0.2\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 28.52000000095581]\n\t0.3\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 42.78000000095581]\n\t0.4\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 57.04000000095582]\n\t0.5\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 71.30000000095582]\n\t0.6\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 85.56000000095582]\n\t0.7\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 99.82000000095582]\n\t0.8\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 114.08000000095585]\n\t...\n\t583.7\t[-0.0019167094095930257, -0.05412068948173644, 3131.826061088355, 3131.346887534511, -4.3267310775923446e-5, 1.4259877656765594e6]\nEvents [58409]:\n\tTime-Event @ 0.01s (state-change: false)\n\tTime-Event @ 0.02s (state-change: false)\n\tTime-Event @ 0.03s (state-change: false)\n\tTime-Event @ 0.04s (state-change: false)\n\tTime-Event @ 0.05s (state-change: false)\n\tTime-Event @ 0.06s (state-change: false)\n\tTime-Event @ 0.07s (state-change: false)\n\tTime-Event @ 0.08s (state-change: false)\n\tTime-Event @ 0.09s (state-change: false)\n\t...\n\tTime-Event @ 583.7s (state-change: false)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"As for the FMU, we can display the NeuralFMU simulation result and check some statistics.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Now, let's have a look on the cumulative consumption plot ...","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# plot the NeuralFMU, original FMU and data (cumulative consumption)\nfig = plot(resultNFMU; stateIndices=6:6, stateEvents=false, timeEvents=false, label=\"NeuralFMU (untrained)\", ylabel=\"cumulative consumption [Ws]\")\nplot!(fig, resultFMU; stateIndices=6:6, values=false, stateEvents=false, timeEvents=false, label=\"FMU\")\nplot!(fig, data.cumconsumption_t, data.cumconsumption_val, label=\"Data\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"As you can see, the FMU und NeuralFMU result looks identically - and this is what we expect for a fully open FMU gate and a fully closed ANN gate!","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Finally, unload the FMU and invalidate the NeuralFMU.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# unload FMU / invalidate NeuralFMU\nunloadFMU(fmu)\nneuralFMU = nothing","category":"page"},{"location":"examples/juliacon_2023/#4.-Training-the-NeuralFMU","page":"JuliaCon 2023","title":"4. Training the NeuralFMU","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"An untrained NeuralFMU is not that impressive - so let's train it a bit. ","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We start by defining a time sequence (the time points of data measurements) and the cumulative consumption values we want to train for.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# prepare training data \ntrain_t = data.consumption_t \n\n# data is as \"array of arrays\" required (often we have multidimensional data)\ntrain_data = collect([d] for d in data.cumconsumption_val)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"5838-element Vector{Vector{Float64}}:\n [0.0]\n [-0.41296068176650935]\n [0.26787411983582043]\n [0.7202168791949798]\n [1.0714482470335085]\n [1.390037422822217]\n [2.1200151652794643]\n [2.5196535613914306]\n [2.656369007464336]\n [2.993187294279602]\n [3.4693116134235407]\n [4.049369938809381]\n [4.673174216401814]\n â‹®\n [1.3879359188013095e6]\n [1.3879515067827937e6]\n [1.3879669882976608e6]\n [1.3879825294049252e6]\n [1.3879980607748663e6]\n [1.3880134565080018e6]\n [1.3880287579379592e6]\n [1.388044098663902e6]\n [1.388059371012591e6]\n [1.388074504338062e6]\n [1.3880896849414955e6]\n [1.3881049434185931e6]","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"The data sequence is too long to train on it all at once - so we need to batch our data.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"First, we introduce some hyperparameters. Training success always depends on a good choice of hyperparameters, we use the following hyperparameters in this workshop:","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"BATCHDUR the duration of a single batch element (length) in seconds.\nTRAINDUR specifies the training duration (measured on data) in seconds.\nETA the update rate eta of the Adam optimizer.\nBETA1 the first momentum coefficient beta_1 of the Adam optimizer.\nBETA2 the second momentum coefficient beta_2 of the Adam optimizer. \nLASTWEIGHT a weighting factor between the last solution point and all remaining solution points.\nSCHEDULER an identifier for the batch scheduler, can be :Sequential, :Random or :LossAccumulation.\nLOSS an identifier for the loss function to use, :MAE or :MSE.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Next, the loss function is defined. The loss is computed on basis of a given solution and data. Dependent on the hyperparameter LOSS, either :MAE or :MSE is used to compute the loss. The hyperparameter LASTWEIGHT determines how much the last solution point is weight against the remaining solution points. For example a value of 03 determines that the last point of the solution contributes 30 to the loss, whereas all remaining solution points contribute 70 in total.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"function _lossFct(solution::FMUSolution, data::VLDM_Data, LOSS::Symbol, LASTWEIGHT::Real=1.0/length(data.consumption_t) )\n\n    # determine the start/end indices `ts` and `te` in the data array (sampled with 10Hz)\n    ts = dataIndexForTime(solution.states.t[1])\n    te = dataIndexForTime(solution.states.t[end])\n    \n    # retrieve the data from NeuralODE (\"where we are\") and data from measurements (\"where we want to be\") and an allowed deviation (\"we are unsure about\")\n    nfmu_cumconsumption = getState(solution, 6; isIndex=true)\n    cumconsumption = data.cumconsumption_val[ts:te]\n    cumconsumption_dev = data.cumconsumption_dev[ts:te]\n\n    Î”cumconsumption = 0.0\n    if LOSS == :MAE\n        Î”cumconsumption = FMIFlux.Losses.mae_last_element_rel_dev(nfmu_cumconsumption,  # NeuralFMU \n                                                                  cumconsumption,       # data target\n                                                                  cumconsumption_dev,   # data uncertainty\n                                                                  LASTWEIGHT)           # how much do we scale the last point compared to the remaining ones?\n    elseif LOSS == :MSE\n        Î”cumconsumption = FMIFlux.Losses.mse_last_element_rel_dev(nfmu_cumconsumption, \n                                                                  cumconsumption, \n                                                                  cumconsumption_dev, \n                                                                  LASTWEIGHT)\n    else\n        @assert false, \"Unknown LOSS: `$(LOSS)`\"\n    end\n    \n    return Î”cumconsumption \nend","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"_lossFct (generic function with 2 methods)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Finally, the function train! is defined, that triggers a new training run for a given set of hyperparameters hyper_params, a training resource resource and the current training index ind.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# resource = training time horizon (duration of data seen)\nfunction train!(hyper_params, resource, ind)\n\n    # make the runs deterministic by fixing the random seed\n    Random.seed!(1234)\n\n    # training duration (in seconds) equals the given resource\n    TRAINDUR = resource\n\n    # unpack the hyperparameters\n    ETA, BETA1, BETA2, BATCHDUR, LASTWEIGHT, SCHEDULER, LOSS = hyper_params\n\n    # compute the number of training steps TRAINDUR / BATCHDUR, but do at least one step\n    steps = max(round(Int, TRAINDUR/BATCHDUR), 1) \n\n    # print a bit of info\n    @info \"--------------\\nStarting run $(ind) with parameters: $(hyper_params) and resource $(resource) doing $(steps) step(s).\\n--------------------\"\n\n    # load our FMU (we take one from the FMIZoo.jl, exported with Dymola 2020x)\n    fmu = loadFMU(\"VLDM\", \"Dymola\", \"2020x\"; type=:ME) \n\n    # built the NeuralFMU on basis of the loaded FMU `fmu`\n    neuralFMU = build_NFMU(fmu)\n\n    # a more efficient execution mode\n    singleInstanceMode(fmu, true)\n    \n    # batch the data (time, targets), train only on model output index 6, plot batch elements\n    batch = batchDataSolution(neuralFMU,                            # our NeuralFMU model\n                              t -> FMIZoo.getStateVector(data, t),  # a function returning a start state for a given time point `t`, to determine start states for batch elements\n                              train_t,                              # data time points\n                              train_data;                           # data cumulative consumption \n                              batchDuration=BATCHDUR,               # duration of one batch element\n                              indicesModel=6:6,                     # model indices to train on (6 equals the state `cumulative consumption`)\n                              plot=false,                           # don't show intermediate plots (try this outside of Jupyter)\n                              parameters=data.params,               # use the parameters (map file paths) from *FMIZoo.jl*\n                              showProgress=showProgress)            # show or don't show progress bar, as specified at the very beginning\n\n    # limit the maximum number of solver steps to 1000 * BATCHDUR (longer batch elements get more steps)\n    # this allows the NeuralFMU to do 10x more steps (average) than the original FMU, but more should not be tolerated (to stiff system)\n    solverKwargsTrain = Dict{Symbol, Any}(:maxiters => round(Int, 1000*BATCHDUR)) \n    \n    # a smaller dispatch for our custom loss function, only taking the solution object\n    lossFct = (solution::FMUSolution) -> _lossFct(solution, data, LOSS, LASTWEIGHT)\n\n    # selecting a scheduler for training\n    scheduler = nothing\n    if SCHEDULER == :Random\n        # a scheduler that picks a random batch element\n        scheduler = RandomScheduler(neuralFMU, batch; applyStep=1, plotStep=0)\n    elseif SCHEDULER == :Sequential\n        # a scheduler that picks one batch element after another (in chronological order)\n        scheduler = SequentialScheduler(neuralFMU, batch; applyStep=1, plotStep=0)\n    elseif SCHEDULER == :LossAccumulation\n        # a scheduler that picks the element with largest accumulated loss:\n        # - after every training step, the accumulated loss for every batch element is increased by the current loss value \n        # - when picking a batch element, the accumulated loss is reset to zero\n        # - this promotes selecting elements with larger losses more often, but also prevents starving of elements with small losses\n        scheduler = LossAccumulationScheduler(neuralFMU, batch, lossFct; applyStep=1, plotStep=0, updateStep=1)\n    else \n        @error \"Unknown SCHEDULER: Â´$(SCHEDULER)Â´.\"\n        return nothing\n    end\n\n    # loss for training, do a simulation run on a batch element taken from the scheduler\n    loss = p -> FMIFlux.Losses.loss(neuralFMU,                          # the NeuralFMU to simulate\n                                    batch;                              # the batch to take an element from\n                                    p=p,                                # the NeuralFMU training parameters (given as input)\n                                    parameters=data.params,             # the FMU parameters\n                                    lossFct=lossFct,                    # our custom loss function\n                                    batchIndex=scheduler.elementIndex,  # the index of the batch element to take, determined by the chosen scheduler\n                                    logLoss=true,                       # log losses after every evaluation\n                                    showProgress=showProgress,          # show progress bar (or don't)\n                                    solverKwargsTrain...)               # the solver kwargs defined above\n\n    # gather the parameters from the NeuralFMU\n    params = FMIFlux.params(neuralFMU)\n\n    # initialize the scheduler, keywords are passed to the NeuralFMU\n    FMIFlux.initialize!(scheduler; parameters=data.params, p=params[1], showProgress=showProgress)\n    \n    # initialize Adam optimizer with our hyperparameters\n    optim = Adam(ETA, (BETA1, BETA2))\n   \n    # the actual training\n    FMIFlux.train!(loss,                            # the loss function for training\n                   neuralFMU,                       # the neural FMU including the parameters to train\n                   Iterators.repeated((), steps),   # an iterator repeating `steps` times\n                   optim;                           # the optimizer to train\n                   gradient=:ReverseDiff,           # ForwardDiff leads to good results for multi-event systems\n                   chunk_size=32,                   # ForwardDiff chunk_size (=number of parameter estimations per run) - only if ForwardDiff is used\n                   cb=() -> FMIFlux.update!(scheduler),     # update the scheduler after every step \n                   proceed_on_assert=true)          # proceed, even if assertions are thrown, with the next step\n    \n    # the default execution mode\n    singleInstanceMode(fmu, false)\n\n    # save our result parameters\n    FMIFlux.saveParameters(neuralFMU, joinpath(@__DIR__, \"params\", \"$(ind).jld2\"))\n    \n    # simulate the NeuralFMU on a validation trajectory\n    resultNFMU = neuralFMU(x0, (data_validation.consumption_t[1], data_validation.consumption_t[end]); parameters=data_validation.params, showProgress=showProgress, maxiters=1e7, saveat=data_validation.consumption_t)\n\n    # determine loss on validation data (if the simulation was successful)\n    validation_loss = nothing \n    if resultNFMU.success\n        # compute the loss on VALIDATION data \n        validation_loss = _lossFct(resultNFMU,      # the NeuralFMU\n                                  data_validation,  # the validation data set \n                                  :MSE)             # use MSE \n    end        \n\n    # unload FMU\n    unloadFMU(fmu)\n\n    # return the loss (or `nothing` if no loss can be determined)\n    return validation_loss\nend","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"train! (generic function with 1 method)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"If you want to do hyper parameter optimization, uncomment/remove all code that comes from here on. The following is for demonstration purpose only. ","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Let's check if the train function is working for a given set of hyperparameters.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# check if the train function is working for a set of given (random) hyperparameters\n#     ([  ETA, BETA1,  BETA2, BATCHDUR, LASTWEIGHT, SCHEDULER, LOSS], RESOURCE, INDEX)\ntrain!([0.0001,  0.9,  0.999,      4.0,        0.7,   :Random, :MSE],      8.0,     1)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m--------------\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39mStarting run 1 with parameters: Any[0.0001, 0.9, 0.999, 4.0, 0.7, :Random, :MSE] and resource 8.0 doing 2 step(s).\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m--------------------\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCurrent step: 0 | Current element=0 | Next element=92\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCurrent step: 1 | Current element=92 | Next element=55\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAVG: 1.20e+04 | MAX: 1.75e+06 | SUM: 1.75e+06\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCurrent step: 2 | Current element=55 | Next element=106\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAVG: 1.21e+04 | MAX: 1.75e+06 | SUM: 1.75e+06\n\n\n\n\n\n9.046692788787865e9","category":"page"},{"location":"examples/juliacon_2023/#5.-Results","page":"JuliaCon 2023","title":"5. Results","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"After training with a set of good hyperparameters, results can be loaded (one set is already prepared if you skipped the optimization).","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# load our FMU (we take one from the FMIZoo.jl, exported with Dymola 2020x)\nfmu = loadFMU(\"VLDM\", \"Dymola\", \"2020x\"; type=:ME)\n\n# build NeuralFMU\nneuralFMU = build_NFMU(fmu)\n\n# load parameters from hyperparameter optimization\nFMIFlux.loadParameters(neuralFMU, joinpath(@__DIR__, \"juliacon_2023.jld2\"))\n\n# simulate and plot the NeuralFMU\nresultNFMU = neuralFMU(x0,  (tStart, tStop); parameters=data.params, showProgress=showProgress, saveat=tSave) \nresultFMU  =  simulate(fmu, (tStart, tStop); parameters=data.params, showProgress=showProgress, saveat=tSave) \n\n# plot the NeuralFMU, original FMU and data (cumulative consumption)\nfig = plot(resultNFMU; stateIndices=6:6, stateEvents=false, timeEvents=false, label=\"NeuralFMU\", ylabel=\"cumulative consumption [m/s]\")\nplot!(fig, resultFMU; stateIndices=6:6, values=false, stateEvents=false, timeEvents=false, label=\"FMU\")\nplot!(fig, data.cumconsumption_t, data.cumconsumption_val, label=\"Data\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We also have a ready-to-use function that calculates different errors and plots them.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"plotCumulativeConsumption(resultNFMU, resultFMU, data; filename=joinpath(@__DIR__, \"comparison_train_100.png\"))","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Because the deviation is small, let's check the last 10% of WLTC focussed, so from 90% to 100%.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"plotCumulativeConsumption(resultNFMU, resultFMU, data; range=(0.9, 1.0), filename=joinpath(@__DIR__, \"comparison_train_10.png\"))","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Finally, we should check the results on validation data: The full WLTC cycle.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# get start and stop for the validation cycle (full WLTC)\ntStart_validation = data_validation.cumconsumption_t[1]\ntStop_validation = data_validation.cumconsumption_t[end]\ntSave_validation = data_validation.cumconsumption_t\n\n# simulate the NeuralFMU on validation data\nresultNFMU = neuralFMU(x0,  (tStart_validation, tStop_validation); parameters=data_validation.params, showProgress=showProgress, saveat=tSave_validation) \nresultFMU  =  simulate(fmu, (tStart_validation, tStop_validation); parameters=data_validation.params, showProgress=showProgress, saveat=tSave_validation) \n\nplotCumulativeConsumption(resultNFMU, resultFMU, data_validation; filename=joinpath(@__DIR__, \"comparison_validation_100.png\"))","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"... and the last 10% ...","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"plotCumulativeConsumption(resultNFMU, resultFMU, data_validation; range=(0.9, 1.0), filename=joinpath(@__DIR__, \"comparison_validation_10.png\"))","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Check out the error values in the legend: This is an enhancement of factor x326 on MSE, x22 on MAE and x11 on MAX error, wow!","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Finally some plotting \"sugar\": A plot showing for which locations in derivative-space the model enhanced the cumulative consumption prediction the most:","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"plotEnhancements(neuralFMU, fmu, data; filename=joinpath(@__DIR__, \"gif_1.gif\"))","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSaved animation to D:\\a\\FMIFlux.jl\\FMIFlux.jl\\examples\\jupyter-src\\gif_1.gif","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: gif)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"After we finished, let's finally unload the FMU and invalidate the NeuralFMU.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# unload FMU / invalidate NeuralFMU\nunloadFMU(fmu)\nneuralFMU = nothing","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"But: We did look on some results, but did not talk about where the used hyperparameters came from ...","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"They come from hyperparameter optimization - and this step is necessary for NeuralODEs too! ","category":"page"},{"location":"examples/juliacon_2023/#Optional:-Organize-as-module","page":"JuliaCon 2023","title":"Optional: Organize as module","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"If you want, you can place all code inside of a module named NODE_Training, this simplifies hyper parameter optimization (if you want to do one).","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# for hyper parameter optimization, place the code in a `module`\n# uncomment the following three lines and place them at the very beginning\n \n#module NODE_Training \n#using DistributedHyperOpt\n#using DistributedHyperOpt.Distributed \n\n# ... and uncomment the following line\n#end # NODE_Training ","category":"page"},{"location":"library/#library","page":"Library Functions","title":"Library Functions","text":"","category":"section"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"","category":"page"},{"location":"library/#FMIFlux-functions","page":"Library Functions","title":"FMIFlux functions","text":"","category":"section"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"CS_NeuralFMU\nME_NeuralFMU\nNeuralFMU","category":"page"},{"location":"library/#FMIFlux.CS_NeuralFMU","page":"Library Functions","title":"FMIFlux.CS_NeuralFMU","text":"Structure definition for a NeuralFMU, that runs in mode Co-Simulation (CS).\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.ME_NeuralFMU","page":"Library Functions","title":"FMIFlux.ME_NeuralFMU","text":"Structure definition for a NeuralFMU, that runs in mode Model Exchange (ME).\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.NeuralFMU","page":"Library Functions","title":"FMIFlux.NeuralFMU","text":"The mutable struct representing an abstract (simulation mode unknown) NeuralFMU.\n\n\n\n\n\n","category":"type"},{"location":"library/#FMI-2-version-dependent-functions","page":"Library Functions","title":"FMI 2 version dependent functions","text":"","category":"section"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"fmiDoStepCS\nfmi2EvaluateME\nfmi2InputDoStepCSOutput","category":"page"},{"location":"library/#FMIFlux.fmiDoStepCS","page":"Library Functions","title":"FMIFlux.fmiDoStepCS","text":"DEPRECATED:\n\nWrapper. Call fmi2DoStepCS for more information.\n\n\n\n\n\n","category":"function"},{"location":"library/#FMIFlux.fmi2EvaluateME","page":"Library Functions","title":"FMIFlux.fmi2EvaluateME","text":"DEPRECATED:\n\nPerforms something similar to fmiDoStep for ME-FMUs (note, that fmiDoStep is for CS-FMUs only). Event handling (state- and time-events) is supported. If you don't want events to be handled, you can disable event-handling for the NeuralFMU nfmu with the attribute eventHandling = false.\n\nOptional, additional FMU-values can be set via keyword arguments setValueReferences and setValues. Optional, additional FMU-values can be retrieved by keyword argument getValueReferences.\n\nFunction takes the current system state array (\"x\") and returns an array with state derivatives (\"x dot\") and optionally the FMU-values for getValueReferences. Setting the FMU time via argument t is optional, if not set, the current time of the ODE solver around the NeuralFMU is used.\n\n\n\n\n\n","category":"function"},{"location":"library/#FMIFlux.fmi2InputDoStepCSOutput","page":"Library Functions","title":"FMIFlux.fmi2InputDoStepCSOutput","text":"DEPRECATED:\n\nfmi2InputDoStepCSOutput(comp::FMU2Component, \n                        dt::Real, \n                        u::Array{<:Real})\n\nSets all FMU inputs to u, performs a Â´Â´Â´fmi2DoStepÂ´Â´Â´ and returns all FMU outputs.\n\n\n\n\n\n","category":"function"},{"location":"library/#FMI-version-independent-functions","page":"Library Functions","title":"FMI version independent functions","text":"","category":"section"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"fmiEvaluateME\nfmiInputDoStepCSOutput","category":"page"},{"location":"library/#FMIFlux.fmiEvaluateME","page":"Library Functions","title":"FMIFlux.fmiEvaluateME","text":"DEPRECATED:\n\nWrapper. Call fmi2EvaluateME for more information.\n\n\n\n\n\n","category":"function"},{"location":"library/#FMIFlux.fmiInputDoStepCSOutput","page":"Library Functions","title":"FMIFlux.fmiInputDoStepCSOutput","text":"DEPRECATED:\n\nWrapper. Call fmi2InputDoStepCSOutput for more information.\n\n\n\n\n\n","category":"function"},{"location":"library/#Additional-functions","page":"Library Functions","title":"Additional functions","text":"","category":"section"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"mse_interpolate","category":"page"},{"location":"library/#FMIFlux.mse_interpolate","page":"Library Functions","title":"FMIFlux.mse_interpolate","text":"Compares non-equidistant (or equidistant) datapoints by linear interpolating and comparing at given interpolation points t_comp.  (Zygote-friendly: Zygote can differentiate through via AD.)\n\n\n\n\n\n","category":"function"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"transferParams!","category":"page"},{"location":"library/#TODO:-Sort-docs","page":"Library Functions","title":"TODO: Sort docs","text":"","category":"section"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"LossAccumulationScheduler\nFMIFlux.transferFlatParams!\nFMIFlux.WorstElementScheduler\nFMIFlux.FMUParameterRegistrator\nFMIFlux.SimultaniousZeroCrossing\nFMIFlux.ParameterRegistrator\nFMIFlux.ScaleShift\nFMIFlux.WorstGrowScheduler\nFMIFlux.SequentialScheduler\nFMIFlux.FMUTimeLayer\nFMIFlux.ShiftScale\nFMIFlux.RandomScheduler","category":"page"},{"location":"library/#FMIFlux.LossAccumulationScheduler","page":"Library Functions","title":"FMIFlux.LossAccumulationScheduler","text":"Computes all batch element losses. Picks the batch element with the greatest accumulated loss as next training element. If picked, accumulated loss is resetted.\n(Prevents starvation of batch elements with little loss)\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.transferFlatParams!","page":"Library Functions","title":"FMIFlux.transferFlatParams!","text":"Writes/Copies flatted (Flux.destructure) training parameters p_net to non-flat model net with data offset c.\n\n\n\n\n\n","category":"function"},{"location":"library/#FMIFlux.WorstElementScheduler","page":"Library Functions","title":"FMIFlux.WorstElementScheduler","text":"Computes all batch element losses. Picks the batch element with the greatest loss as next training element.\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.FMUParameterRegistrator","page":"Library Functions","title":"FMIFlux.FMUParameterRegistrator","text":"ToDo.\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.SimultaniousZeroCrossing","page":"Library Functions","title":"FMIFlux.SimultaniousZeroCrossing","text":"Forces a simultaniuos zero crossing together with a given value by function.\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.ParameterRegistrator","page":"Library Functions","title":"FMIFlux.ParameterRegistrator","text":"ToDo.\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.ScaleShift","page":"Library Functions","title":"FMIFlux.ScaleShift","text":"ToDo.\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.WorstGrowScheduler","page":"Library Functions","title":"FMIFlux.WorstGrowScheduler","text":"Computes all batch element losses. Picks the batch element with the greatest grow in loss (derivative) as next training element.\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.SequentialScheduler","page":"Library Functions","title":"FMIFlux.SequentialScheduler","text":"Sequentially runs over all elements.\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.FMUTimeLayer","page":"Library Functions","title":"FMIFlux.FMUTimeLayer","text":"A neutral layer that calls a function fct with current FMU time as input.\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.ShiftScale","page":"Library Functions","title":"FMIFlux.ShiftScale","text":"ToDo.\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.RandomScheduler","page":"Library Functions","title":"FMIFlux.RandomScheduler","text":"Picks a random batch element as next training element.\n\n\n\n\n\n","category":"type"},{"location":"related/#Related-Publications","page":"Related Publication","title":"Related Publications","text":"","category":"section"},{"location":"related/","page":"Related Publication","title":"Related Publication","text":"Thummerer T, Kircher J and Mikelsons L: Neural FMU: Towards structual integration of FMUs into neural networks (Preprint, accepted 14th International Modelica Conference) pdf|DOI","category":"page"},{"location":"related/","page":"Related Publication","title":"Related Publication","text":"Thummerer T, Tintenherr J, Mikelsons L: Hybrid modeling of the human cardiovascular system using NeuralFMUs (Preprint, accepted 10th International Conference on Mathematical Modeling in Physical Sciences) pdf|DOI","category":"page"},{"location":"examples/overview/#Examples-Overview","page":"Overview","title":"Examples - Overview","text":"","category":"section"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"This section discusses the included examples of the FMIFlux.jl library. You can execute them on your machine and get detailed information about all of the steps.  If you require further information about the function calls, see library functions section.  For more information related to the setup and simulation of an FMU see FMI.jl library.","category":"page"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"The examples are intended for users who work in the field of first principle and/or data driven modeling and are further interested in hybrid model building.  The examples show how to combine FMUs with machine learning (\"NeuralFMU\") and illustrates the advantages of this approach.","category":"page"},{"location":"examples/overview/#Examples","page":"Overview","title":"Examples","text":"","category":"section"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"Simple CS-NeuralFMU: Showing how to train a NeuralFMU in Co-Simulation-Mode.\nSimple ME-NeuralFMU: Showing how to train a NeuralFMU in Model-Exchange-Mode.","category":"page"},{"location":"examples/overview/#Advanced-examples:-Demo-applications","page":"Overview","title":"Advanced examples: Demo applications","text":"","category":"section"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"JuliaCon 2023: Using NeuralODEs in real life applications: An example for a NeuralODE in a real world engineering scenario.\nModelica Conference 2021: NeuralFMUs: Showing basics on how to train a NeuralFMU (Contribution for the Modelica Conference 2021).","category":"page"},{"location":"examples/overview/#Workshops","page":"Overview","title":"Workshops","text":"","category":"section"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"Pluto workshops: Pluto based notebooks, that can easily be executed on your own Pluto-Setup.","category":"page"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"Scientific Machine Learning using Functional Mock-up Units: Workshop at JuliaCon 2024 (Eindhoven University, Netherlands)","category":"page"},{"location":"examples/overview/#Archived","page":"Overview","title":"Archived","text":"","category":"section"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"MDPI 2022: Physics-enhanced NeuralODEs in real-world applications: An example for a NeuralODE in a real world modeling scenario (Contribution in MDPI Electronics 2022).\nGrowing Horizon ME-NeuralFMU: Growing horizon training technique for a ME-NeuralFMU.\nHands-on: Hybrid Modeling using FMI: Workshop at MODPROD 2024 (LinkÃ¶ping University, Sweden)","category":"page"},{"location":"examples/simple_hybrid_ME/#Neural-FMUs-in-model-exchange-(ME)-mode","page":"Simple ME-NeuralFMU","title":"Neural FMUs in model exchange (ME) mode","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Tutorial by Tobias Thummerer","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Last edit: 03.09.2024","category":"page"},{"location":"examples/simple_hybrid_ME/#License","page":"Simple ME-NeuralFMU","title":"License","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons\n# Licensed under the MIT license. \n# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details.","category":"page"},{"location":"examples/simple_hybrid_ME/#Introduction","page":"Simple ME-NeuralFMU","title":"Introduction","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Functional mock-up units (FMUs) can easily be seen as containers for simulation models. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"This example shows how to build a very easy neural FMU by combining a model exchange (ME) FMU and an artificial neural network (ANN). The goal is, to train the hybrid model based on a very simple simulation model.","category":"page"},{"location":"examples/simple_hybrid_ME/#Packages","page":"Simple ME-NeuralFMU","title":"Packages","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"First, import the packages needed:","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# imports\nusing FMI                       # for importing and simulating FMUs\nusing FMIFlux                   # for building neural FMUs\nusing FMIFlux.Flux              # the default machine learning library in Julia\nusing FMIZoo                    # a collection of demo FMUs\nusing DifferentialEquations     # the (O)DE solver suite in Julia\nusing Plots                     # for plotting some results\n\nimport Random                   # for random variables (and random initialization)\nRandom.seed!(1234)              # makes our program deterministic","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Random.TaskLocalRNG()","category":"page"},{"location":"examples/simple_hybrid_ME/#Code","page":"Simple ME-NeuralFMU","title":"Code","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Next, start and stop time are set for the simulation, as well as some intermediate time points tSave to record simulation results.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"tStart = 0.0\ntStep = 0.01\ntStop = 5.0\ntSave = collect(tStart:tStep:tStop)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"501-element Vector{Float64}:\n 0.0\n 0.01\n 0.02\n 0.03\n 0.04\n 0.05\n 0.06\n 0.07\n 0.08\n 0.09\n 0.1\n 0.11\n 0.12\n â‹®\n 4.89\n 4.9\n 4.91\n 4.92\n 4.93\n 4.94\n 4.95\n 4.96\n 4.97\n 4.98\n 4.99\n 5.0","category":"page"},{"location":"examples/simple_hybrid_ME/#Complex-FMU-(ground-truth-training-data)","page":"Simple ME-NeuralFMU","title":"Complex FMU (ground truth training data)","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"First, let's load a model from the FMIZoo.jl, an easy pendulum including some friction. We will use that to generate training data.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# let's load the FMU in ME-mode (some FMUs support multiple simulation modes)\nfmu_gt = loadFMU(\"SpringFrictionPendulum1D\", \"Dymola\", \"2022x\"; type=:ME)  \n\n# and print some info\ninfo(fmu_gt)   ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringFrictionPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{2e178ad3-5e9b-48ec-a7b2-baa5669efc0c}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:12Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t24\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\n\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\", \"mass.v_relfric\"]\n\tParameters:\t\t\t12\n\t\t16777216 [\"fricScale\"]\n\t\t16777217 [\"s0\"]\n\t\t16777218 [\"v0\"]\n\t\t16777219 [\"fixed.s0\"]\n\t\t...\n\t\t16777223 [\"mass.smin\"]\n\t\t16777224 [\"mass.v_small\"]\n\t\t16777225 [\"mass.L\"]\n\t\t16777226 [\"mass.m\"]\n\t\t16777227 [\"mass.fexp\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Next, the start state x0 is defined, together with some variables to be recorded vrs (they are identified by the names that where used during export of the FMU). The FMU is simulated and the results are plotted.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# the initial state we start our simulation with, position (0.5 m) and velocity (0.0 m/s) of the pendulum\nx0 = [0.5, 0.0] \n\n# some variables we are interested in, so let's record them: position, velocity and acceleration\nvrs = [\"mass.s\", \"mass.v\", \"mass.a\"]  \n\n# simulate the FMU ...\nsol_gt = simulate(fmu_gt, (tStart, tStop); recordValues=vrs, saveat=tSave, x0=x0)    \n\n# ... and plot it! (but only the recorded values, not the states)\nplot(sol_gt; states=false)                                                                    ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"\u001b[34mSimulating ME-FMU ...   0%|â–ˆ                             |  ETA: N/A\u001b[39m\n\n\u001b[34mSimulating ME-FMU ... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:16\u001b[39m","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"After the simulation, specific variables can be extracted. We will use them for the later training - as training data!","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"pos_gt = getValue(sol_gt, \"mass.s\")","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"501-element Vector{Float64}:\n 0.5\n 0.5002131418271644\n 0.500854887495059\n 0.5019281657516876\n 0.5034351795370763\n 0.50537742474533\n 0.5077556973743648\n 0.5105701110158936\n 0.5138201163230011\n 0.5175045276221266\n 0.5216215241870015\n 0.5261686593877334\n 0.5311429006829193\n â‹®\n 1.0616593561654388\n 1.0627701713285898\n 1.0637521434353139\n 1.0646032889175199\n 1.0653217119141543\n 1.0659056034549985\n 1.0663532416435237\n 1.0666629937790932\n 1.0668333163759727\n 1.0668685641881956\n 1.0668685641871958\n 1.0668685641861957","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Now, we can release the FMU again - we don't need it anymore.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"unloadFMU(fmu_gt)","category":"page"},{"location":"examples/simple_hybrid_ME/#Simple-FMU","page":"Simple ME-NeuralFMU","title":"Simple FMU","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Now, we load an even more simple system, that we use as core for our neural FMU: A pendulum without friction. Again, we load, simulate and plot the FMU and its results.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"fmu = loadFMU(\"SpringPendulum1D\", \"Dymola\", \"2022x\"; type=:ME)\ninfo(fmu)\n\nsol_fmu = simulate(fmu, (tStart, tStop); recordValues=vrs, saveat=tSave)\nplot(sol_fmu)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{fc15d8c4-758b-48e6-b00e-5bf47b8b14e5}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:23Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t0\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\"]\n\tParameters:\t\t\t7\n\t\t16777216 [\"mass_s0\"]\n\t\t16777217 [\"mass_v0\"]\n\t\t16777218 [\"fixed.s0\"]\n\t\t16777219 [\"spring.c\"]\n\t\t16777220 [\"spring.s_rel0\"]\n\t\t16777221 [\"mass.m\"]\n\t\t16777222 [\"mass.L\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/simple_hybrid_ME/#Neural-FMU","page":"Simple ME-NeuralFMU","title":"Neural FMU","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Now the fun begins, let's combine the loaded FMU and the ANN! ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# get number of states\nnumStates = getNumberOfStates(fmu)\n\nnet = Chain(x -> fmu(x=x, dx_refs=:all),    # we can use the FMU just like any other neural network layer!\n            Dense(numStates, 16, tanh),     # some additional dense layers ...\n            Dense(16, 16, tanh),\n            Dense(16, numStates))\n\n# the neural FMU is constructed by providing the FMU, the net topology, start and stop time and a solver (here: Tsit5)\nneuralFMU = ME_NeuralFMU(fmu, net, (tStart, tStop), Tsit5(); saveat=tSave);","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Now, we can check how the neural FMU performs before the actual training!","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"solutionBefore = neuralFMU(x0)\nplot(solutionBefore)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Not that ideal... let's add our ground truth data to compare!","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"plot!(sol_gt; values=false)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Ufff... only the starting state for position and velocity is correct. Training seems a good idea here!","category":"page"},{"location":"examples/simple_hybrid_ME/#Loss-function","page":"Simple ME-NeuralFMU","title":"Loss function","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Before we can train the neural FMU, we need to define a loss function. We use the common mean-squared-error (MSE) here.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"function loss(p)\n    # simulate the neural FMU by calling it\n    sol_nfmu = neuralFMU(x0; p=p)\n\n    # we use the first state, because we know that's the position\n    pos_nfmu = getState(sol_nfmu, 1; isIndex=true)\n\n    # we could also identify the position state by its name\n    #pos_nfmu = getState(solution, \"mass.s\")\n    \n    FMIFlux.Losses.mse(pos_gt, pos_nfmu) \nend","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"loss (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_ME/#Callback","page":"Simple ME-NeuralFMU","title":"Callback","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Further, we define a simple logging function for our training.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"global counter = 0\nfunction callback(p)\n    global counter += 1\n    if counter % 20 == 1\n        lossVal = loss(p[1])\n        @info \"Loss [$(counter)]: $(round(lossVal, digits=6))\"\n    end\nend","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"callback (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_ME/#Training","page":"Simple ME-NeuralFMU","title":"Training","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"For training, we only need to extract the parameters to optimize and pass it to a pre-build train command FMIFlux.train!.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"optim = Adam()\n\np = FMIFlux.params(neuralFMU)\n\nFMIFlux.train!(\n    loss, \n    neuralFMU,\n    Iterators.repeated((), 500), \n    optim; \n    cb=()->callback(p)\n) ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1]: 0.061175\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [21]: 0.040784\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [41]: 0.040451\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [61]: 0.039743\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [81]: 0.039087\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [101]: 0.03815\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [121]: 0.035558\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [141]: 0.021058\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [161]: 0.006635\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [181]: 0.004409\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [201]: 0.003957\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [221]: 0.003682\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [241]: 0.003449\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [261]: 0.00321\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [281]: 0.002995\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [301]: 0.002806\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [321]: 0.002578\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [341]: 0.002362\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [361]: 0.002152\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [381]: 0.001956\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [401]: 0.001789\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [421]: 0.001617\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [441]: 0.001453\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [461]: 0.001301\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [481]: 0.00116","category":"page"},{"location":"examples/simple_hybrid_ME/#Results","page":"Simple ME-NeuralFMU","title":"Results","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Finally, we can compare the results before and after training, as well as the ground truth data:","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"solutionAfter = neuralFMU(x0)\n\nfig = plot(solutionBefore; stateIndices=1:1, label=\"Neural FMU (before)\", ylabel=\"position [m]\")\nplot!(fig, solutionAfter; stateIndices=1:1, label=\"Neural FMU (after)\")\nplot!(fig, tSave, pos_gt; label=\"ground truth\")\nfig","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Finally, the FMU is unloaded and memory released.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"unloadFMU(fmu)","category":"page"},{"location":"examples/simple_hybrid_ME/#Source","page":"Simple ME-NeuralFMU","title":"Source","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"[1] Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. NeuralFMU: towards structural integration of FMUs into neural networks. Martin SjÃ¶lund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, LinkÃ¶ping, Sweden, September 20-24, 2021. LinkÃ¶ping University Electronic Press, LinkÃ¶ping (LinkÃ¶ping Electronic Conference Proceedings ; 181), 297-306. DOI: 10.3384/ecp21181297","category":"page"},{"location":"examples/simple_hybrid_ME/#Build-information","page":"Simple ME-NeuralFMU","title":"Build information","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# check package build information for reproducibility\nimport Pkg; Pkg.status()","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `D:\\a\\FMIFlux.jl\\FMIFlux.jl\\examples\\Project.toml`\n  \u001b[90m[0c46a032] \u001b[39mDifferentialEquations v7.14.0\n  \u001b[90m[14a09403] \u001b[39mFMI v0.14.1\n  \u001b[90m[fabad875] \u001b[39mFMIFlux v0.13.0 `D:\\a\\FMIFlux.jl\\FMIFlux.jl`\n  \u001b[90m[9fcbc62e] \u001b[39mFMIImport v1.0.7\n  \u001b[90m[724179cf] \u001b[39mFMIZoo v1.1.0\n  \u001b[90m[587475ba] \u001b[39mFlux v0.14.19\n  \u001b[90m[7073ff75] \u001b[39mIJulia v1.25.0\n\u001b[32mâŒƒ\u001b[39m \u001b[90m[033835bb] \u001b[39mJLD2 v0.4.53\n  \u001b[90m[b964fa9f] \u001b[39mLaTeXStrings v1.3.1\n  \u001b[90m[f0f68f2c] \u001b[39mPlotlyJS v0.18.14\n  \u001b[90m[91a5bcdd] \u001b[39mPlots v1.40.8\n  \u001b[90m[9a3f8284] \u001b[39mRandom\n\u001b[36m\u001b[1mInfo\u001b[22m\u001b[39m Packages marked with \u001b[32mâŒƒ\u001b[39m have new versions available and may be upgradable.","category":"page"},{"location":"faq/#FAQ","page":"FAQ","title":"FAQ","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"This list some common - often numerical - errors, that can be fixed by better understanding the ODE-Problem inside your FMU.","category":"page"},{"location":"faq/#Double-callback-crossing","page":"FAQ","title":"Double callback crossing","text":"","category":"section"},{"location":"faq/#Description","page":"FAQ","title":"Description","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Error message, a double zero-crossing happened, often during training a NeuralFMU.","category":"page"},{"location":"faq/#Example","page":"FAQ","title":"Example","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Double callback crossing floating pointer reducer errored. Report this issue.","category":"page"},{"location":"faq/#Reason","page":"FAQ","title":"Reason","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"This could be, because the event inside of a NeuralFMU can't be located (often when using Zygote). ","category":"page"},{"location":"faq/#Fix","page":"FAQ","title":"Fix","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Try to increase the root search interpolation points, this is computational expensive for FMUs with many events- and event-indicators. This can be done using fmu.executionConfig.rootSearchInterpolationPoints = 100 (default value is 10).","category":"page"},{"location":"examples/simple_hybrid_CS/#Neural-FMUs-in-co-simulation-(CS)-mode","page":"Simple CS-NeuralFMU","title":"Neural FMUs in co simulation (CS) mode","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Tutorial by Tobias Thummerer","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Last edit: 03.09.2024","category":"page"},{"location":"examples/simple_hybrid_CS/#License","page":"Simple CS-NeuralFMU","title":"License","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons\n# Licensed under the MIT license. \n# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details.","category":"page"},{"location":"examples/simple_hybrid_CS/#Introduction","page":"Simple CS-NeuralFMU","title":"Introduction","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Functional mock-up units (FMUs) can easily be seen as containers for simulation models. ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"This example shows how to build a very easy neural FMU by combining a co simulation (CS) FMU and an artificial neural network (ANN). The goal is, to train the hybrid model based on a very simple simulation model.","category":"page"},{"location":"examples/simple_hybrid_CS/#Packages","page":"Simple CS-NeuralFMU","title":"Packages","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"First, import the packages needed:","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# imports\nusing FMI                       # for importing and simulating FMUs\nusing FMIFlux                   # for building neural FMUs\nusing FMIFlux.Flux              # the default machine learning library in Julia\nusing FMIZoo                    # a collection of demo FMUs\nusing Plots                     # for plotting some results\n\nimport Random                   # for random variables (and random initialization)\nRandom.seed!(1234)              # makes our program deterministic","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Random.TaskLocalRNG()","category":"page"},{"location":"examples/simple_hybrid_CS/#Code","page":"Simple CS-NeuralFMU","title":"Code","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Next, start and stop time are set for the simulation, as well as some intermediate time points tSave to record simulation results.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"tStart = 0.0\ntStep = 0.01\ntStop = 5.0\ntSave = collect(tStart:tStep:tStop)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"501-element Vector{Float64}:\n 0.0\n 0.01\n 0.02\n 0.03\n 0.04\n 0.05\n 0.06\n 0.07\n 0.08\n 0.09\n 0.1\n 0.11\n 0.12\n â‹®\n 4.89\n 4.9\n 4.91\n 4.92\n 4.93\n 4.94\n 4.95\n 4.96\n 4.97\n 4.98\n 4.99\n 5.0","category":"page"},{"location":"examples/simple_hybrid_CS/#Complex-FMU-(ground-truth-training-data)","page":"Simple CS-NeuralFMU","title":"Complex FMU (ground truth training data)","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"First, let's load a model from the FMIZoo.jl, an easy pendulum including some friction. We will use that to generate training data.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# let's load the FMU in CS-mode (some FMUs support multiple simulation modes)\nfmu_gt = loadFMU(\"SpringPendulum1D\", \"Dymola\", \"2022x\"; type=:CS)  \n\n# and print some info\ninfo(fmu_gt)   ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{fc15d8c4-758b-48e6-b00e-5bf47b8b14e5}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:23Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t0\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\n\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\"]\n\tParameters:\t\t\t7\n\t\t16777216 [\"mass_s0\"]\n\t\t16777217 [\"mass_v0\"]\n\t\t16777218 [\"fixed.s0\"]\n\t\t16777219 [\"spring.c\"]\n\t\t16777220 [\"spring.s_rel0\"]\n\t\t16777221 [\"mass.m\"]\n\t\t16777222 [\"mass.L\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Next, some variables to be recorded vrs are defined (they are identified by the names that where used during export of the FMU). The FMU is simulated and the results are plotted.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# the initial state we start our simulation with, position (0.5 m) and velocity (0.0 m/s) of the pendulum\nx0 = [0.5, 0.0] \n\n# some variables we are interested in, so let's record them: position, velocity and acceleration\nvrs = [\"mass.s\", \"mass.v\", \"mass.a\"]  \n\n# set the start state via parameters \nparameters = Dict(\"mass_s0\" => x0[1], \"mass_v0\" => x0[2]) \n\n# simulate the FMU ...\nsol_gt = simulate(fmu_gt, (tStart, tStop); recordValues=vrs, saveat=tSave, parameters=parameters)    \n\n# ... and plot it!\nplot(sol_gt)                                                                    ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"After the simulation, specific variables can be extracted. We will use them for the later training - as training data!","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"vel_gt = getValue(sol_gt, \"mass.v\")\nacc_gt = getValue(sol_gt, \"mass.a\")","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"501-element Vector{Float64}:\n  6.0\n  5.996872980925033\n  5.987824566254761\n  5.9728274953129645\n  5.95187583433241\n  5.9249872805026715\n  5.892169834645022\n  5.853465119227542\n  5.808892969264781\n  5.75851573503067\n  5.702370188387734\n  5.640527685538739\n  5.573049035471661\n  â‹®\n -5.842615646003006\n -5.884869953422783\n -5.921224800662572\n -5.9516502108284985\n -5.976144547672481\n -5.994659284032171\n -6.007174453690571\n -6.013675684067705\n -6.014154196220591\n -6.008606804843264\n -5.997055285530499\n -5.979508813705998","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Now, we can release the FMU again - we don't need it anymore.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"unloadFMU(fmu_gt)","category":"page"},{"location":"examples/simple_hybrid_CS/#Simple-FMU","page":"Simple CS-NeuralFMU","title":"Simple FMU","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Now, we load an even more simple system, that we use as core for our neural FMU: A pendulum without friction. Again, we load, simulate and plot the FMU and its results.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"fmu = loadFMU(\"SpringPendulumExtForce1D\", \"Dymola\", \"2022x\"; type=:CS)\ninfo(fmu)\n\n# set the start state via parameters \nparameters = Dict(\"mass_s0\" => x0[1], \"mass.v\" => x0[2])\n\nsol_fmu = simulate(fmu, (tStart, tStop); recordValues=vrs, saveat=tSave, parameters=parameters)\nplot(sol_fmu)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringPendulumExtForce1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{df5ebe46-3c86-42a5-a68a-7d008395a7a3}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:33Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t0\n\tInputs:\t\t\t\t1\n\t\t352321536 [\"extForce\"]\n\tOutputs:\t\t\t2\n\t\t335544320 [\"accSensor.v\", \"der(accSensor.flange.s)\", \"v\", \"der(speedSensor.flange.s)\", \"speedSensor.v\"]\n\t\t335544321 [\"der(accSensor.v)\", \"a\", \"accSensor.a\"]\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\"]\n\tParameters:\t\t\t6\n\t\t16777216 [\"mass_s0\"]\n\t\t16777217 [\"fixed.s0\"]\n\t\t16777218 [\"spring.c\"]\n\t\t16777219 [\"spring.s_rel0\"]\n\t\t16777220 [\"mass.m\"]\n\t\t16777221 [\"mass.L\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringPendulumExtForce1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringPendulumExtForce1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/simple_hybrid_CS/#Neural-FMU","page":"Simple CS-NeuralFMU","title":"Neural FMU","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"First, let's check the inputs and outputs of our CS FMU.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# outputs\nprintln(\"Outputs:\")\ny_refs = fmu.modelDescription.outputValueReferences \nnumOutputs = length(y_refs)\nfor y_ref in y_refs \n    name = valueReferenceToString(fmu, y_ref)\n    println(\"$(y_ref) -> $(name)\")\nend\n\n# inputs\nprintln(\"\\nInputs:\")\nu_refs = fmu.modelDescription.inputValueReferences \nnumInputs = length(u_refs)\nfor u_ref in u_refs \n    name = valueReferenceToString(fmu, u_ref)\n    println(\"$(u_ref) -> $(name)\")\nend","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Outputs:\n335544320 -> [\"accSensor.v\", \"der(accSensor.flange.s)\", \"v\", \"der(speedSensor.flange.s)\", \"speedSensor.v\"]\n335544321 -> [\"der(accSensor.v)\", \"a\", \"accSensor.a\"]\n\nInputs:\n352321536 -> [\"extForce\"]","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Now the fun begins, let's combine the loaded FMU and the ANN! ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"net = Chain(u -> fmu(;u_refs=u_refs, u=u, y_refs=y_refs),   # we can use the FMU just like any other neural network layer!\n            Dense(numOutputs, 16, tanh),                    # some additional dense layers ...\n            Dense(16, 16, tanh),\n            Dense(16, numOutputs))\n\n# the neural FMU is constructed by providing the FMU, the net topology, start and stop time\nneuralFMU = CS_NeuralFMU(fmu, net, (tStart, tStop));","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Before we can check that neural FMU, we need to define a input function, because the neural FMU - as well as the original FMU - has inputs.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"function extForce(t)\n    return [0.0]\nend ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"extForce (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Now, we can check how the neural FMU performs before the actual training!","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"solutionBefore = neuralFMU(extForce, tStep, (tStart, tStop); parameters=parameters)\nplot(solutionBefore)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Not that ideal... let's add our ground truth data to compare!","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"plot!(sol_gt)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Ufff... training seems a good idea here!","category":"page"},{"location":"examples/simple_hybrid_CS/#Loss-function","page":"Simple CS-NeuralFMU","title":"Loss function","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Before we can train the neural FMU, we need to define a loss function. We use the common mean-squared-error (MSE) here.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"function loss(p)\n    # simulate the neural FMU by calling it\n    sol_nfmu = neuralFMU(extForce, tStep, (tStart, tStop); parameters=parameters, p=p)\n\n    # we use the second value, because we know that's the acceleration\n    acc_nfmu = getValue(sol_nfmu, 2; isIndex=true)\n    \n    # we could also identify the position state by its name\n    #acc_nfmu = getValue(sol_nfmu, \"mass.a\")\n    \n    FMIFlux.Losses.mse(acc_gt, acc_nfmu) \nend","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"loss (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_CS/#Callback","page":"Simple CS-NeuralFMU","title":"Callback","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Further, we define a simple logging function for our training.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"global counter = 0\nfunction callback(p)\n    global counter += 1\n    if counter % 20 == 1\n        lossVal = loss(p[1])\n        @info \"Loss [$(counter)]: $(round(lossVal, digits=6))\"\n    end\nend","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"callback (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_CS/#Training","page":"Simple CS-NeuralFMU","title":"Training","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"For training, we only need to extract the parameters to optimize and pass it to a pre-build train command FMIFlux.train!.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"optim = Adam()\n\np = FMIFlux.params(neuralFMU)\n\nFMIFlux.train!(\n    loss, \n    neuralFMU,\n    Iterators.repeated((), 500), \n    optim; \n    cb=()->callback(p)\n) ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1]: 16.874727\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [21]: 10.452957\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [41]: 6.017093\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [61]: 3.327601\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [81]: 1.87555\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [101]: 1.162226\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [121]: 0.818483\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [141]: 0.625927\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [161]: 0.487464\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [181]: 0.373996\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [201]: 0.28081\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [221]: 0.207289\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [241]: 0.151647\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [261]: 0.110905\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [281]: 0.081792\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [301]: 0.061356\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [321]: 0.047178\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [341]: 0.037386\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [361]: 0.030586\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [381]: 0.025778\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [401]: 0.02227\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [421]: 0.019598\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [441]: 0.017464\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [461]: 0.015685\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [481]: 0.014149","category":"page"},{"location":"examples/simple_hybrid_CS/#Results","page":"Simple CS-NeuralFMU","title":"Results","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Finally, we can compare the results before and after training, as well as the ground truth data:","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"solutionAfter = neuralFMU(extForce, tStep, (tStart, tStop); parameters=parameters)\n\nfig = plot(solutionBefore; valueIndices=2:2, label=\"Neural FMU (before)\", ylabel=\"acceleration [m/s^2]\")\nplot!(fig, solutionAfter; valueIndices=2:2, label=\"Neural FMU (after)\")\nplot!(fig, tSave, acc_gt; label=\"ground truth\")\nfig","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Finally, the FMU is unloaded and memory released.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"unloadFMU(fmu)","category":"page"},{"location":"examples/simple_hybrid_CS/#Source","page":"Simple CS-NeuralFMU","title":"Source","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"[1] Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. NeuralFMU: towards structural integration of FMUs into neural networks. Martin SjÃ¶lund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, LinkÃ¶ping, Sweden, September 20-24, 2021. LinkÃ¶ping University Electronic Press, LinkÃ¶ping (LinkÃ¶ping Electronic Conference Proceedings ; 181), 297-306. DOI: 10.3384/ecp21181297","category":"page"},{"location":"examples/simple_hybrid_CS/#Build-information","page":"Simple CS-NeuralFMU","title":"Build information","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# check package build information for reproducibility\nimport Pkg; Pkg.status()","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `D:\\a\\FMIFlux.jl\\FMIFlux.jl\\examples\\Project.toml`\n  \u001b[90m[0c46a032] \u001b[39mDifferentialEquations v7.14.0\n  \u001b[90m[14a09403] \u001b[39mFMI v0.14.1\n  \u001b[90m[fabad875] \u001b[39mFMIFlux v0.13.0 `D:\\a\\FMIFlux.jl\\FMIFlux.jl`\n  \u001b[90m[9fcbc62e] \u001b[39mFMIImport v1.0.7\n  \u001b[90m[724179cf] \u001b[39mFMIZoo v1.1.0\n  \u001b[90m[587475ba] \u001b[39mFlux v0.14.19\n  \u001b[90m[7073ff75] \u001b[39mIJulia v1.25.0\n\u001b[32mâŒƒ\u001b[39m \u001b[90m[033835bb] \u001b[39mJLD2 v0.4.53\n  \u001b[90m[b964fa9f] \u001b[39mLaTeXStrings v1.3.1\n  \u001b[90m[f0f68f2c] \u001b[39mPlotlyJS v0.18.14\n  \u001b[90m[91a5bcdd] \u001b[39mPlots v1.40.8\n  \u001b[90m[9a3f8284] \u001b[39mRandom\n\u001b[36m\u001b[1mInfo\u001b[22m\u001b[39m Packages marked with \u001b[32mâŒƒ\u001b[39m have new versions available and may be upgradable.","category":"page"},{"location":"examples/modelica_conference_2021/#ME-NeuralFMU-from-the-Modelica-Conference-2021","page":"Modelica Conference 2021","title":"ME-NeuralFMU from the Modelica Conference 2021","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Tutorial by Johannes Stoljar, Tobias Thummerer","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"ðŸ“šðŸ“šðŸ“š This tutorial is achieved (so keeping it runnable is low priority). This tutorial further needs heavy refactoring. ðŸ“šðŸ“šðŸ“š","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Last edit: 29.03.2023","category":"page"},{"location":"examples/modelica_conference_2021/#License","page":"Modelica Conference 2021","title":"License","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons, Johannes Stoljar\n# Licensed under the MIT license. \n# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details.","category":"page"},{"location":"examples/modelica_conference_2021/#Motivation","page":"Modelica Conference 2021","title":"Motivation","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The Julia Package FMIFlux.jl is motivated by the application of hybrid modeling. This package enables the user to integrate his simulation model between neural networks (NeuralFMU). For this, the simulation model must be exported as FMU (functional mock-up unit), which corresponds to a widely used standard. The big advantage of hybrid modeling with artificial neural networks is, that the effects that are difficult to model (because they might be unknown) can be easily learned by the neural networks. For this purpose, the NeuralFMU is trained with measurement data containing the not modeled physical effect. The final product is a simulation model including the originally not modeled effects. Another big advantage of the NeuralFMU is that it works with little data, because the FMU already contains the characteristic functionality of the simulation and only the missing effects are added.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"NeuralFMUs do not need to be as easy as in this example. Basically a NeuralFMU can combine different ANN topologies that manipulate any FMU-input (system state, system inputs, time) and any FMU-output (system state derivative, system outputs, other system variables). However, for this example a NeuralFMU topology as shown in the following picture is used.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: NeuralFMU.svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"NeuralFMU (ME) from [1].","category":"page"},{"location":"examples/modelica_conference_2021/#Introduction-to-the-example","page":"Modelica Conference 2021","title":"Introduction to the example","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In this example, simplified modeling of a one-dimensional spring pendulum (without friction) is compared to a model of the same system that includes a nonlinear friction model. The FMU with the simplified model will be named simpleFMU in the following and the model with the friction will be named realFMU. At the beginning, the actual state of both simulations is shown, whereby clear deviations can be seen in the graphs. In addition, the initial states are changed for both models and these graphs are also contrasted, and the differences can again be clearly seen. The realFMU serves as a reference graph. The simpleFMU is then integrated into a NeuralFMU architecture and a training of the entire network is performed. After the training the final state is compared again to the realFMU. It can be clearly seen that by using the NeuralFMU, learning of the friction process has taken place.  ","category":"page"},{"location":"examples/modelica_conference_2021/#Target-group","page":"Modelica Conference 2021","title":"Target group","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The example is primarily intended for users who work in the field of first principle and/or hybrid modeling and are further interested in hybrid model building. The example wants to show how simple it is to combine FMUs with machine learning and to illustrate the advantages of this approach.","category":"page"},{"location":"examples/modelica_conference_2021/#Other-formats","page":"Modelica Conference 2021","title":"Other formats","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Besides, this Jupyter Notebook there is also a Julia file with the same name, which contains only the code cells. For the documentation there is a Markdown file corresponding to the notebook.  ","category":"page"},{"location":"examples/modelica_conference_2021/#Getting-started","page":"Modelica Conference 2021","title":"Getting started","text":"","category":"section"},{"location":"examples/modelica_conference_2021/#Installation-prerequisites","page":"Modelica Conference 2021","title":"Installation prerequisites","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":" Description Command\n1. Enter Package Manager via ]\n2. Install FMI via add FMI\n3. Install FMIFlux via add FMIFlux\n4. Install FMIZoo via add FMIZoo\n5. Install DifferentialEquations via add DifferentialEquations\n6. Install Plots via add Plots\n7. Install Random via add Random","category":"page"},{"location":"examples/modelica_conference_2021/#Code-section","page":"Modelica Conference 2021","title":"Code section","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"To run the example, the previously installed packages must be included. ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# imports\nusing FMI\nusing FMIFlux\nusing FMIFlux.Flux\nusing FMIZoo\nusing DifferentialEquations: Tsit5\nusing Plots\n\n# set seed\nimport Random\nRandom.seed!(1234);","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"After importing the packages, the path to the Functional Mock-up Units (FMUs) is set. The exported FMU is a model meeting the Functional Mock-up Interface (FMI) Standard. The FMI is a free standard (fmi-standard.org) that defines a container and an interface to exchange dynamic models using a combination of XML files, binaries and C code zipped into a single file. ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The object-orientated structure of the SpringPendulum1D (simpleFMU) can be seen in the following graphic and corresponds to a simple modeling.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In contrast, the model SpringFrictionPendulum1D (realFMU) is somewhat more accurate, because it includes a friction component. ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Next, the start time and end time of the simulation are set. Finally, a step size is specified to store the results of the simulation at these time steps.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"tStart = 0.0\ntStep = 0.01\ntStop = 4.0\ntSave = collect(tStart:tStep:tStop)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"401-element Vector{Float64}:\n 0.0\n 0.01\n 0.02\n 0.03\n 0.04\n 0.05\n 0.06\n 0.07\n 0.08\n 0.09\n 0.1\n 0.11\n 0.12\n â‹®\n 3.89\n 3.9\n 3.91\n 3.92\n 3.93\n 3.94\n 3.95\n 3.96\n 3.97\n 3.98\n 3.99\n 4.0","category":"page"},{"location":"examples/modelica_conference_2021/#RealFMU","page":"Modelica Conference 2021","title":"RealFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the next lines of code the FMU of the realFMU model from FMIZoo.jl is loaded and the information about the FMU is shown.  ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"realFMU = loadFMU(\"SpringFrictionPendulum1D\", \"Dymola\", \"2022x\"; type=:ME)\ninfo(realFMU)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringFrictionPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{2e178ad3-5e9b-48ec-a7b2-baa5669efc0c}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:12Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t24\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\", \"mass.v_relfric\"]\n\tParameters:\t\t\t12\n\t\t16777216 [\"fricScale\"]\n\t\t16777217 [\"s0\"]\n\t\t16777218 [\"v0\"]\n\t\t16777219 [\"fixed.s0\"]\n\t\t...\n\t\t16777223 [\"mass.smin\"]\n\t\t16777224 [\"mass.v_small\"]\n\n\n\t\t16777225 [\"mass.L\"]\n\t\t16777226 [\"mass.m\"]\n\t\t16777227 [\"mass.fexp\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the following two subsections, the realFMU is simulated twice with different initial states to show what effect the choice of initial states has.","category":"page"},{"location":"examples/modelica_conference_2021/#Default-initial-states","page":"Modelica Conference 2021","title":"Default initial states","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the next steps the parameters are defined. The first parameter is the initial position of the mass, which is initialized with 05m, the second parameter is the initial velocity, which is initialized with 0fracms. In the function fmiSimulate() the realFMU is simulated, still specifying the start and end time, the parameters and which variables are recorded. After the simulation is finished the result of the realFMU can be plotted. This plot also serves as a reference for the other model (simpleFMU). The extracted data will still be needed later on.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"initStates = [\"s0\", \"v0\"]\nxâ‚€ = [0.5, 0.0]\nparams = Dict(zip(initStates, xâ‚€))\nvrs = [\"mass.s\", \"mass.v\", \"mass.a\", \"mass.f\"]\n\nrealSimData = simulate(realFMU, (tStart, tStop); parameters=params, recordValues=vrs, saveat=tSave)\nposReal = getValue(realSimData, \"mass.s\")\nvelReal = getValue(realSimData, \"mass.v\")\nplot(realSimData)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"\u001b[34mSimulating ME-FMU ...   0%|â–ˆ                             |  ETA: N/A\u001b[39m\n\n\u001b[34mSimulating ME-FMU ... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:15\u001b[39m","category":"page"},{"location":"examples/modelica_conference_2021/#Define-functions","page":"Modelica Conference 2021","title":"Define functions","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Also, a function to extract the position and velocity from the simulation data is created.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function extractPosVel(simData)\n    if simData.states === nothing\n        posData = getValue(simData, \"mass.s\")\n        velData = getValue(simData, \"mass.v\")\n    else\n        posData = getState(simData, 1; isIndex=true)\n        velData = getState(simData, 2; isIndex=true)\n    end\n\n    return posData, velData\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"extractPosVel (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/#Modified-initial-states","page":"Modelica Conference 2021","title":"Modified initial states","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In contrast to the previous section, other initial states are selected. The position of the mass is initialized with 10m and the velocity is initialized with -15fracms. With the modified initial states the realFMU is simulated and a graph is generated.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"xModâ‚€ = [1.0, -1.5]\nrealSimDataMod = simulate(realFMU, (tStart, tStop); parameters=Dict(zip(initStates, xModâ‚€)), recordValues=vrs, saveat=tSave)\nplot(realSimDataMod)","category":"page"},{"location":"examples/modelica_conference_2021/#SimpleFMU","page":"Modelica Conference 2021","title":"SimpleFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The following lines load the simpleFMU from FMIZoo.jl. ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"simpleFMU = loadFMU(\"SpringPendulum1D\", \"Dymola\", \"2022x\"; type=:ME)\ninfo(simpleFMU)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{fc15d8c4-758b-48e6-b00e-5bf47b8b14e5}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:23Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t0\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\"]\n\tParameters:\t\t\t7\n\t\t16777216 [\"mass_s0\"]\n\t\t16777217 [\"mass_v0\"]\n\t\t16777218 [\"fixed.s0\"]\n\t\t16777219 [\"spring.c\"]\n\t\t16777220 [\"spring.s_rel0\"]\n\t\t16777221 [\"mass.m\"]\n\t\t16777222 [\"mass.L\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The differences between both systems can be clearly seen from the plots in the subchapters. In the plot for the realFMU it can be seen that the oscillation continues to decrease due to the effect of the friction. If you simulate long enough, the oscillation would come to a standstill in a certain time. The oscillation in the simpleFMU behaves differently, since the friction was not taken into account here. The oscillation in this model would continue to infinity with the same oscillation amplitude. From this observation the desire of an improvement of this model arises.     ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the following two subsections, the simpleFMU is simulated twice with different initial states to show what effect the choice of initial states has.","category":"page"},{"location":"examples/modelica_conference_2021/#Default-initial-states-2","page":"Modelica Conference 2021","title":"Default initial states","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Similar to the simulation of the realFMU, the simpleFMU is also simulated with the default values for the position and velocity of the mass and then plotted. There is one difference, however, as another state representing a fixed displacement is set. In addition, the last variable is also removed from the variables to be plotted.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"initStates = [\"mass_s0\", \"mass_v0\", \"fixed.s0\"]\ndisplacement = 0.1\nxSimpleâ‚€ = vcat(xâ‚€, displacement)\nvrs = vrs[1:end-1]\n\nsimpleSimData = simulate(simpleFMU, (tStart, tStop); parameters=Dict(zip(initStates, xSimpleâ‚€)), recordValues=vrs, saveat=tSave)\nplot(simpleSimData)","category":"page"},{"location":"examples/modelica_conference_2021/#Modified-initial-states-2","page":"Modelica Conference 2021","title":"Modified initial states","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The same values for the initial states are used for this simulation as for the simulation from the realFMU with the modified initial states.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"xSimpleModâ‚€ = vcat(xModâ‚€, displacement)\n\nsimpleSimDataMod = simulate(simpleFMU, (tStart, tStop); parameters=Dict(zip(initStates, xSimpleModâ‚€)), recordValues=vrs, saveat=tSave)\nplot(simpleSimDataMod)","category":"page"},{"location":"examples/modelica_conference_2021/#NeuralFMU","page":"Modelica Conference 2021","title":"NeuralFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/#Loss-function","page":"Modelica Conference 2021","title":"Loss function","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In order to train our model, a loss function must be implemented. The solver of the NeuralFMU can calculate the gradient of the loss function. The gradient descent is needed to adjust the weights in the neural network so that the sum of the error is reduced and the model becomes more accurate.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The error function in this implementation consists of the mean of the mean squared errors. The first part of the addition is the deviation of the position and the second part is the deviation of the velocity. The mean squared error (mse) for the position consists from the real position of the realFMU simulation (posReal) and the position data of the network (posNet). The mean squared error for the velocity consists of the real velocity of the realFMU simulation (velReal) and the velocity data of the network (velNet). $ e{loss} = \\frac{1}{2} \\Bigl[ \\frac{1}{n} \\sum\\limits{i=0}^n (posReal[i] - posNet[i])^2 + \\frac{1}{n} \\sum\\limits_{i=0}^n (velReal[i] - velNet[i])^2 \\Bigr]$","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# loss function for training\nfunction lossSum(p)\n    global xâ‚€\n    solution = neuralFMU(xâ‚€; p=p)\n\n    posNet, velNet = extractPosVel(solution)\n\n    (FMIFlux.Losses.mse(posReal, posNet) + FMIFlux.Losses.mse(velReal, velNet)) / 2.0\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"lossSum (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/#Callback","page":"Modelica Conference 2021","title":"Callback","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"To output the loss in certain time intervals, a callback is implemented as a function in the following. Here a counter is incremented, every fiftieth pass the loss function is called and the average error is printed out. Also, the parameters for the velocity in the first layer are kept to a fixed value.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# callback function for training\nglobal counter = 0\nfunction callb(p)\n    global counter\n    counter += 1\n\n    # freeze first layer parameters (2,4,6) for velocity -> (static) direct feed trough for velocity\n    # parameters for position (1,3,5) are learned\n    p[1][2] = 0.0\n    p[1][4] = 1.0\n    p[1][6] = 0.0\n\n    if counter % 50 == 1\n        avgLoss = lossSum(p[1])\n        @info \"  Loss [$counter]: $(round(avgLoss, digits=5))\n        Avg displacement in data: $(round(sqrt(avgLoss), digits=5))\n        Weight/Scale: $(paramsNet[1][1])   Bias/Offset: $(paramsNet[1][5])\"\n    end\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"callb (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/#Functions-for-plotting","page":"Modelica Conference 2021","title":"Functions for plotting","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In this section some important functions for plotting are defined. The function generate_figure() creates a new figure object and sets some attributes.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function generate_figure(title, xLabel, yLabel, xlim=:auto)\n    plot(\n        title=title, xlabel=xLabel, ylabel=yLabel, linewidth=2,\n        xtickfontsize=12, ytickfontsize=12, xguidefontsize=12, yguidefontsize=12,\n        legendfontsize=12, legend=:topright, xlim=xlim)\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"generate_figure (generic function with 2 methods)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the following function, the data of the realFMU, simpleFMU and neuralFMU are summarized and displayed in a graph.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function plot_results(title, xLabel, yLabel, interval, realData, simpleData, neuralData)\n    linestyles = [:dot, :solid]\n    \n    fig = generate_figure(title, xLabel, yLabel)\n    plot!(fig, interval, simpleData, label=\"SimpleFMU\", linewidth=2)\n    plot!(fig, interval, realData, label=\"Reference\", linewidth=2)\n    for i in 1:length(neuralData)\n        plot!(fig, neuralData[i][1], neuralData[i][2], label=\"NeuralFMU ($(i*2500))\", \n                    linewidth=2, linestyle=linestyles[i], linecolor=:green)\n    end\n    display(fig)\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"plot_results (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"This is the superordinate function, which at the beginning extracts the position and velocity from the simulation data (realSimData, realSimDataMod, simpleSimData,..., solutionAfterMod). Four graphs are then generated, each comparing the corresponding data from the realFMU, simpleFMU, and neuralFMU. The comparison is made with the simulation data from the simulation with the default and modified initial states. According to the data, the designation of the title and the naming of the axes is adapted.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function plot_all_results(realSimData, realSimDataMod, simpleSimData, \n        simpleSimDataMod, solutionAfter, solutionAfterMod)    \n    # collect all data\n    posReal, velReal = extractPosVel(realSimData)\n    posRealMod, velRealMod = extractPosVel(realSimDataMod)\n    posSimple, velSimple = extractPosVel(simpleSimData)\n    posSimpleMod, velSimpleMod = extractPosVel(simpleSimDataMod)\n    \n    run = length(solutionAfter)\n    \n    posNeural, velNeural = [], []\n    posNeuralMod, velNeuralMod = [], []\n    for i in 1:run\n        dataNeural = extractPosVel(solutionAfter[i])\n        time = getTime(solutionAfter[i])\n\n        push!(posNeural, (time, dataNeural[1]))\n        push!(velNeural, (time, dataNeural[2]))\n        \n        dataNeuralMod = extractPosVel(solutionAfterMod[i])\n        time = getTime(solutionAfterMod[i])\n        push!(posNeuralMod, (time, dataNeuralMod[1]))\n        push!(velNeuralMod, (time, dataNeuralMod[2]))\n    end\n         \n    # plot results s (default initial states)\n    xLabel=\"t [s]\"\n    yLabel=\"mass position [m]\"\n    title = \"Default: Mass position after Run: $(run)\"\n    plot_results(title, xLabel, yLabel, tSave, posReal, posSimple, posNeural)\n\n    # plot results s (modified initial states)\n    title = \"Modified: Mass position after Run: $(run)\"\n    plot_results(title, xLabel, yLabel, tSave, posRealMod, posSimpleMod, posNeuralMod)\n\n    # plot results v (default initial states)\n    yLabel=\"mass velocity [m/s]\"\n    title = \"Default: Mass velocity after Run: $(run)\"\n    plot_results(title, xLabel, yLabel, tSave, velReal, velSimple, velNeural)\n\n    # plot results v (modified initial states)    \n    title = \"Modified: Mass velocity after Run: $(run)\"\n    plot_results(title, xLabel, yLabel, tSave, velRealMod, velSimpleMod, velNeuralMod)\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"plot_all_results (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The function plot_friction_model() compares the friction model of the realFMU, simpleFMU and neuralFMU. For this, the velocity and force from the simulation data of the realFMU is needed. The force data is calculated with the extracted last layer of the neuralFMU to the real velocity in line 9 by iterating over the vector velReal. In the next rows, the velocity and force data (if available) for each of the three FMUs are combined into a matrix. The first row of the matrix corresponds to the later x-axis and here the velocity is plotted. The second row corresponds to the y-axis and here the force is plotted. This matrix is sorted and plotted by the first entries (velocity) with the function sortperm(). The graph with at least three graphs is plotted in line 33. As output this function has the forces of the neuralFMU.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function plot_friction_model!(realSimData, netBottom, forces)    \n    linestyles = [:dot, :solid]\n    \n    velReal = getValue(realSimData, \"mass.v\")\n    forceReal = getValue(realSimData, \"mass.f\")\n\n    push!(forces, zeros(length(velReal)))\n    for i in 1:length(velReal)\n        forces[end][i] = -netBottom([velReal[i], 0.0])[2]\n    end\n\n    run = length(forces) \n    \n    fig = generate_figure(\"Friction model $(run)\", \"v [m/s]\", \"friction force [N]\", (-1.25, 1.25))\n\n    fricSimple = hcat(velReal, zeros(length(velReal)))\n    fricSimple[sortperm(fricSimple[:, 1]), :]\n    Plots.plot!(fig, fricSimple[:,1], fricSimple[:,2], label=\"SimpleFMU\", linewidth=2)\n\n    fricReal = hcat(velReal, forceReal)\n    fricReal[sortperm(fricReal[:, 1]), :]\n    plot!(fig, fricReal[:,1], fricReal[:,2], label=\"reference\", linewidth=2)\n\n    for i in 1:run\n        fricNeural = hcat(velReal, forces[i])\n        fricNeural[sortperm(fricNeural[:, 1]), :]\n        plot!(fig, fricNeural[:,1], fricNeural[:,2], label=\"NeuralFMU ($(i*2500))\", \n                    linewidth=2, linestyle=linestyles[i], linecolor=:green)\n        @info \"Friction model $i mse: $(FMIFlux.Losses.mse(fricNeural[:,2], fricReal[:,2]))\"\n    end\n    flush(stderr)\n\n    display(fig)\n    \n    return nothing\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"plot_friction_model! (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The following function is used to display the different displacement modells of the realFMU, simpleFMU and neuralFMU. The displacement of the realFMU and simpleFMU is very trivial and is only a constant. The position data of the realFMU is needed to calculate the displacement. The displacement for the neuralFMU is calculated using the first extracted layer of the neural network, subtracting the real position and the displacement of the simpleFMU. Also in this function, the graphs of the three FMUs are compared in a plot.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function plot_displacement_model!(realSimData, netTop, displacements, tSave, displacement)\n    linestyles = [:dot, :solid]\n    \n    posReal = getValue(realSimData, \"mass.s\")\n    \n    push!(displacements, zeros(length(posReal)))\n    for i in 1:length(posReal)\n        displacements[end][i] = netTop([posReal[i], 0.0])[1] - posReal[i] - displacement\n    end\n\n    run = length(displacements)\n    fig = generate_figure(\"Displacement model $(run)\", \"t [s]\", \"displacement [m]\")\n    plot!(fig, [tSave[1], tSave[end]], [displacement, displacement], label=\"simpleFMU\", linewidth=2)\n    plot!(fig, [tSave[1], tSave[end]], [0.0, 0.0], label=\"reference\", linewidth=2)\n    for i in 1:run\n        plot!(fig, tSave, displacements[i], label=\"NeuralFMU ($(i*2500))\", \n                    linewidth=2, linestyle=linestyles[i], linecolor=:green)\n    end\n\n    display(fig)\n    \n    return nothing\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"plot_displacement_model! (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/#Structure-of-the-NeuralFMU","page":"Modelica Conference 2021","title":"Structure of the NeuralFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the following, the topology of the NeuralFMU is constructed. It consists of a dense layer that has exactly as many inputs and outputs as the model has states numStates (and therefore state derivatives). It also sets the initial weights and offsets for the first dense layer, as well as the activation function, which consists of the identity. An input layer follows, which then leads into the simpleFMU model. The ME-FMU computes the state derivatives for a given system state. Following the simpleFMU is a dense layer that has numStates states. The output of this layer consists of 8 output nodes and a identity activation function. The next layer has 8 input and output nodes with a tanh activation function. The last layer is again a dense layer with 8 input nodes and the number of states as outputs. Here, it is important that no tanh-activation function follows, because otherwise the pendulums state values would be limited to the interval -11.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# NeuralFMU setup\nnumStates = getNumberOfStates(simpleFMU)\n\n# diagonal matrix \ninitW = zeros(numStates, numStates)\nfor i in 1:numStates\n    initW[i,i] = 1\nend\n\nnet = Chain(Dense(numStates, numStates,  identity),\n            x -> simpleFMU(x=x, dx_refs=:all),\n            Dense(numStates, 8, identity),\n            Dense(8, 8, tanh),\n            Dense(8, numStates))","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Chain(\n  Dense(2 => 2),                        \u001b[90m# 6 parameters\u001b[39m\n  var\"#1#2\"(),\n  Dense(2 => 8),                        \u001b[90m# 24 parameters\u001b[39m\n  Dense(8 => 8, tanh),                  \u001b[90m# 72 parameters\u001b[39m\n  Dense(8 => 2),                        \u001b[90m# 18 parameters\u001b[39m\n) \u001b[90m                  # Total: 8 arrays, \u001b[39m120 parameters, 992 bytes.","category":"page"},{"location":"examples/modelica_conference_2021/#Definition-of-the-NeuralFMU","page":"Modelica Conference 2021","title":"Definition of the NeuralFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The instantiation of the ME-NeuralFMU is done as a one-liner. The FMU (simpleFMU), the structure of the network net, start tStart and end time tStop, the numerical solver Tsit5() and the time steps tSave for saving are specified.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"neuralFMU = ME_NeuralFMU(simpleFMU, net, (tStart, tStop), Tsit5(); saveat=tSave);","category":"page"},{"location":"examples/modelica_conference_2021/#Plot-before-training","page":"Modelica Conference 2021","title":"Plot before training","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Here the state trajectory of the simpleFMU is recorded. Doesn't really look like a pendulum yet, but the system is random initialized by default. In the plots later on, the effect of learning can be seen.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"solutionBefore = neuralFMU(xâ‚€)\nplot(solutionBefore)","category":"page"},{"location":"examples/modelica_conference_2021/#Training-of-the-NeuralFMU","page":"Modelica Conference 2021","title":"Training of the NeuralFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"For the training of the NeuralFMU the parameters are extracted. All parameters of the first layer are set to the absolute value.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# train\nparamsNet = FMIFlux.params(neuralFMU)\n\nfor i in 1:length(paramsNet[1])\n    if paramsNet[1][i] < 0.0 \n        paramsNet[1][i] = -paramsNet[1][i]\n    end\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The well-known Adam optimizer for minimizing the gradient descent is used as further passing parameters. Additionally, the previously defined loss and callback function as well as a one for the number of epochs are passed. Only one epoch is trained so that the NeuralFMU is precompiled.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"optim = Adam()\nFMIFlux.train!(lossSum, neuralFMU, Iterators.repeated((), 1), optim; cb=()->callb(paramsNet)) ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1]: 0.63854\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.79909\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.5550727972914904   Bias/Offset: 0.0009999999899930306","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Some vectors for collecting data are initialized and the number of runs, epochs and iterations are set.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"solutionAfter = []\nsolutionAfterMod = []\nforces = []\ndisplacements = []\n\nnumRuns = 2\nnumEpochs= 5\nnumIterations = 500;","category":"page"},{"location":"examples/modelica_conference_2021/#Training-loop","page":"Modelica Conference 2021","title":"Training loop","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The code section shown here represents the training loop. The loop is structured so that it has numRuns runs, where each run has numEpochs epochs, and the training is performed at each epoch with numIterations iterations. In lines 9 and 10, the data for the neuralFMU for the default and modified initial states are appended to the corresponding vectors. The plots for the opposition of position and velocity is done in line 13 by calling the function plot_all_results. In the following lines the last layers are extracted from the neuralFMU and formed into an independent network netBottom. The parameters for the netBottom network come from the original architecture and are shared. In line 20, the new network is used to represent the friction model in a graph. An analogous construction of the next part of the training loop, where here the first layer is taken from the neuralFMU and converted to its own network netTop. This network is used to record the displacement model. The different graphs are generated for each run and can thus be compared. ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"for run in 1:numRuns\n\n    global forces, displacements\n    \n    optim = Adam(10.0^(-3+1-run)) # going from 1e-3 to 1e-4\n\n    @time for epoch in 1:numEpochs\n        @info \"Run: $(run)/$(numRuns)  Epoch: $(epoch)/$(numEpochs)\"\n        FMIFlux.train!(lossSum, neuralFMU, Iterators.repeated((), numIterations), optim; cb=()->callb(paramsNet))\n    end\n    flush(stderr)\n    flush(stdout)\n    \n    push!(solutionAfter, neuralFMU(xâ‚€))\n    push!(solutionAfterMod, neuralFMU(xModâ‚€))\n\n    # generate all plots for the position and velocity\n    plot_all_results(realSimData, realSimDataMod, simpleSimData, simpleSimDataMod, solutionAfter, solutionAfterMod)\n    \n    # friction model extraction\n    layersBottom = neuralFMU.model.layers[3:5]\n    netBottom = Chain(layersBottom...)\n    transferFlatParams!(netBottom, paramsNet, 7)\n    \n    plot_friction_model!(realSimData, netBottom, forces) \n    \n    # displacement model extraction\n    layersTop = neuralFMU.model.layers[1:1]\n    netTop = Chain(layersTop...)\n    transferFlatParams!(netTop, paramsNet, 1)\n\n    plot_displacement_model!(realSimData, netTop, displacements, tSave, displacement)\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 1/2  Epoch: 1/5\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [51]: 0.45217\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.67244\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.6029313727409417   Bias/Offset: 0.04838982792298539\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [101]: 0.38871\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.62346\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.6410513958850733   Bias/Offset: 0.08756850912808462\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [151]: 0.35475\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.59561\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.6706310161016641   Bias/Offset: 0.1194583853018859\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [201]: 0.3351\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.57887\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.6941713002366973   Bias/Offset: 0.14552377657493937\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [251]: 0.323\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.56834\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7130400884743852   Bias/Offset: 0.1666381199317015\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [301]: 0.31495\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.5612\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7281354038982668   Bias/Offset: 0.18339234053778794\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [351]: 0.30855\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.55547\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7400848576770966   Bias/Offset: 0.19618836771630763\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [401]: 0.29993\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.54766\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7494160703081445   Bias/Offset: 0.20518935235560415\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [451]: 0.283\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.53198\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7569472375897621   Bias/Offset: 0.21018863953659989\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [501]: 0.2292\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.47875\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.763209453810433   Bias/Offset: 0.20972727851143513\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 1/2  Epoch: 2/5\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [551]: 0.15297\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.39111\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7716294020933754   Bias/Offset: 0.21500804696457382\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [601]: 0.03121\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.17666\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.787650243323763   Bias/Offset: 0.23930263953061687\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [651]: 0.02377\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.15419\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7828851053398479   Bias/Offset: 0.23011146927498835\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [701]: 0.02011\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.14183\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7798450590951862   Bias/Offset: 0.22482265492637088\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [751]: 0.01798\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.13409\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7772658793823928   Bias/Offset: 0.2208114990088981\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [801]: 0.01718\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.13105\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7750933517617076   Bias/Offset: 0.21795103458471568\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [851]: 0.01598\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.12642\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7730325041518178   Bias/Offset: 0.21568935476199486\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [901]: 0.01554\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.12465\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7715978702919699   Bias/Offset: 0.21431545688955456\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [951]: 0.01526\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.12355\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7702666841258349   Bias/Offset: 0.21303130050779182\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1001]: 0.01483\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.12177\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7684255238986611   Bias/Offset: 0.21121321082939043\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 1/2  Epoch: 3/5\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1051]: 0.0142\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.11915\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7668961621637944   Bias/Offset: 0.2100001457035587\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1101]: 0.01399\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.11828\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7653014470322085   Bias/Offset: 0.20898426677677534\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1151]: 0.01359\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.11658\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7636902062254607   Bias/Offset: 0.2078315731260719\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1201]: 0.01368\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.11695\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7618945596000443   Bias/Offset: 0.2062826683387349\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1251]: 0.01288\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.11348\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7602320129169557   Bias/Offset: 0.20484587888704264\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1301]: 0.0128\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.11312\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7584852446811282   Bias/Offset: 0.20333738756961667\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1351]: 0.01233\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.11104\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.756805477769466   Bias/Offset: 0.20193445972145055\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1401]: 0.01212\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.11008\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7551823522843474   Bias/Offset: 0.2008023490657473\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1451]: 0.01184\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.10881\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7535919652320717   Bias/Offset: 0.19983767373972636\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1501]: 0.01176\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.10843\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7521206937747862   Bias/Offset: 0.1989686681528405\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 1/2  Epoch: 4/5\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1551]: 0.01135\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.10653\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7506097264801087   Bias/Offset: 0.19789621918008185\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1601]: 0.01147\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.10708\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7490762274238789   Bias/Offset: 0.19679825504096937\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1651]: 0.01135\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.10655\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7479131226007704   Bias/Offset: 0.19583276534128222\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1701]: 0.01049\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.10241\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7464845792271897   Bias/Offset: 0.19458437809896817\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1751]: 0.01043\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.10214\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7450419476954268   Bias/Offset: 0.19313117283238865\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1801]: 0.01035\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.10175\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7434982725757668   Bias/Offset: 0.19176644882018015\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1851]: 0.00998\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.09991\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7424112848046222   Bias/Offset: 0.19088389470922154\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1901]: 0.01006\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.10029\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7408925985826832   Bias/Offset: 0.18942704817573972\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1951]: 0.00939\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.09692\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7394017503105694   Bias/Offset: 0.1880006742329454\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2001]: 0.00899\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.09481\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7379782021500545   Bias/Offset: 0.18645999496249335\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 1/2  Epoch: 5/5\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2051]: 0.00847\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.09201\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7365607177262747   Bias/Offset: 0.18511411682205303\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2101]: 0.00776\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.08812\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7356629818063877   Bias/Offset: 0.18398681068840644\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2151]: 0.00682\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.08258\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7351706437693412   Bias/Offset: 0.1829903640856176\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2201]: 0.00586\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.07655\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7353706389879586   Bias/Offset: 0.18234241887698246\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2251]: 0.00489\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.06991\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7367753264087095   Bias/Offset: 0.18275195104096703\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2301]: 0.00412\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.06419\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7389656946343818   Bias/Offset: 0.18426555560023747\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2351]: 0.00373\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.06108\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7408731376166495   Bias/Offset: 0.18601965833172573\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2401]: 0.00345\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.0587\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7421882203300983   Bias/Offset: 0.187523764283474\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2451]: 0.00315\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.05611\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7431584207431337   Bias/Offset: 0.18889845772789696\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2501]: 0.00291\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.05398\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7438872351944437   Bias/Offset: 0.19014429963747764\n\n\n 95.874149 seconds (1.32 G allocations: 59.333 GiB, 8.50% gc time, 0.09% compilation time)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFriction model 1 mse: 16.30873694544497\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 2/2  Epoch: 1/5\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2551]: 0.00286\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.05344\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7440471016905091   Bias/Offset: 0.19051256263468003\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2601]: 0.00281\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.05304\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7441520323167196   Bias/Offset: 0.19100931281544642\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2651]: 0.00278\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.05269\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7441802974794633   Bias/Offset: 0.1915679209490836\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2701]: 0.00262\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.0512\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7441452629247564   Bias/Offset: 0.19217317966556552\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2751]: 0.0026\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.05095\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7440690291135971   Bias/Offset: 0.19282255883094956\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2801]: 0.00254\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.05035\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7439840708085347   Bias/Offset: 0.19352858466455405\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2851]: 0.00241\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.04909\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7439098114024602   Bias/Offset: 0.19429651151628144\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2901]: 0.00232\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.04817\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.743861525347209   Bias/Offset: 0.19513204194545583\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2951]: 0.00225\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.04747\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7438426796785472   Bias/Offset: 0.1960372112400526\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3001]: 0.00218\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.04673\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7438315491972639   Bias/Offset: 0.19698127821198744\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 2/2  Epoch: 2/5\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3051]: 0.0021\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.04584\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7438199538351697   Bias/Offset: 0.19793962190968858\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3101]: 0.00203\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.04504\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.743812387659078   Bias/Offset: 0.1989016530011808\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3151]: 0.00195\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.04421\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7438159421376663   Bias/Offset: 0.19986438458439829\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3201]: 0.00186\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.04317\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7438336302851711   Bias/Offset: 0.2008270242430251\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3251]: 0.00175\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.04188\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.743866110866574   Bias/Offset: 0.20179263065385966\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3301]: 0.00168\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.04102\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7439138992407596   Bias/Offset: 0.20276479630834549\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3351]: 0.00159\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.03991\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7439743154761158   Bias/Offset: 0.20374272681713113\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3401]: 0.00149\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.03857\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7440415361146039   Bias/Offset: 0.20472150692564062\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3451]: 0.00174\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.04167\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7441084625478972   Bias/Offset: 0.2056934574533521\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3501]: 0.00136\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.03688\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7441695114493807   Bias/Offset: 0.20665220126400813\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 2/2  Epoch: 3/5\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3551]: 0.0013\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.03608\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7442249966603137   Bias/Offset: 0.20760125403750768\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3601]: 0.00124\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.03523\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7442572308006917   Bias/Offset: 0.20852557164606914\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3651]: 0.00121\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.03479\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7442878448172773   Bias/Offset: 0.2094553315039913\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3701]: 0.00114\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.03371\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7443301832225057   Bias/Offset: 0.21042460022082887\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3751]: 0.00105\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.03236\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7443831241556889   Bias/Offset: 0.21145248481423115\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3801]: 0.001\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.03168\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7444058764263503   Bias/Offset: 0.21250696589685578\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3851]: 0.00099\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.03139\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.744435715605685   Bias/Offset: 0.21360601813775762\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3901]: 0.00092\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.03033\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7442496932936764   Bias/Offset: 0.21453399349411345\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3951]: 0.00088\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02972\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7439698954615857   Bias/Offset: 0.21527045751233106\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4001]: 0.00085\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02911\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7436711003148889   Bias/Offset: 0.2158836769905478\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 2/2  Epoch: 4/5\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4051]: 0.00081\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02852\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7433670891138677   Bias/Offset: 0.21640001472227027\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4101]: 0.00081\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02848\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7430599540703008   Bias/Offset: 0.2168299592387007\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4151]: 0.00077\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02779\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7427314960466987   Bias/Offset: 0.21723291101615616\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4201]: 0.00075\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02741\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7423906914442373   Bias/Offset: 0.21761172226154463\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4251]: 0.00073\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02693\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7420450188228398   Bias/Offset: 0.21797091893116027\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4301]: 0.0007\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02647\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7416952691321793   Bias/Offset: 0.218314649292919\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4351]: 0.00068\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.026\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7413485860267984   Bias/Offset: 0.21863281160310336\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4401]: 0.00066\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.0256\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7409902752048756   Bias/Offset: 0.21892503352896034\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4451]: 0.00063\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.0252\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7406235373324925   Bias/Offset: 0.2192209052948436\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4501]: 0.00061\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.0248\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7402581611875044   Bias/Offset: 0.21952494458366242\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 2/2  Epoch: 5/5\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4551]: 0.0006\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.0244\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7398924330632394   Bias/Offset: 0.2198360859839917\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4601]: 0.00058\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02401\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7395334720229155   Bias/Offset: 0.2201453399443113\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4651]: 0.00056\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02367\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.739172457763217   Bias/Offset: 0.2204601029954657\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4701]: 0.00054\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02333\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7388100703474585   Bias/Offset: 0.22079544229570278\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4751]: 0.00053\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02302\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7384450540513796   Bias/Offset: 0.22113678580854923\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4801]: 0.00052\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02287\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.738095856116457   Bias/Offset: 0.22148179218930744\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4851]: 0.00051\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02266\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7377464133987138   Bias/Offset: 0.2218581012375526\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4901]: 0.00051\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.0225\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7373922883985439   Bias/Offset: 0.22225542461472753\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4951]: 0.00052\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02273\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7370386383077695   Bias/Offset: 0.22267329629733626\n\n\n\u001b[36m\u001b[1mâ”Œ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [5001]: 0.0005\n\u001b[36m\u001b[1mâ”‚ \u001b[22m\u001b[39m        Avg displacement in data: 0.02233\n\u001b[36m\u001b[1mâ”” \u001b[22m\u001b[39m        Weight/Scale: 0.7366671763752564   Bias/Offset: 0.22303477489954107\n\n\n 85.740204 seconds (1.19 G allocations: 53.583 GiB, 7.94% gc time)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFriction model 1 mse: 16.30873694544497\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFriction model 2 mse: 18.472186845588634","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Finally, the FMUs are cleaned-up.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"unloadFMU(simpleFMU)\nunloadFMU(realFMU)","category":"page"},{"location":"examples/modelica_conference_2021/#Summary","page":"Modelica Conference 2021","title":"Summary","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Based on the plots, it can be seen that the curves of the realFMU and the neuralFMU are very close. The neuralFMU is able to learn the friction and displacement model.","category":"page"},{"location":"examples/modelica_conference_2021/#Source","page":"Modelica Conference 2021","title":"Source","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"[1] Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. NeuralFMU: towards structural integration of FMUs into neural networks. Martin SjÃ¶lund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, LinkÃ¶ping, Sweden, September 20-24, 2021. LinkÃ¶ping University Electronic Press, LinkÃ¶ping (LinkÃ¶ping Electronic Conference Proceedings ; 181), 297-306. DOI: 10.3384/ecp21181297","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: FMIFlux.jl Logo)","category":"page"},{"location":"#FMIFlux.jl","page":"Introduction","title":"FMIFlux.jl","text":"","category":"section"},{"location":"#What-is-FMIFlux.jl?","page":"Introduction","title":"What is FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"FMIFlux.jl is a free-to-use software library for the Julia programming language, which offers the ability to simply place your FMU (fmi-standard.org) everywhere inside of your ML topologies and still keep the resulting models trainable with a standard (or custom) FluxML training process. This includes for example:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"NeuralODEs including FMUs, so called Neural Functional Mock-up Units (NeuralFMUs): ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"You can place FMUs inside of your ML topology.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"PINNs including FMUs, so called Functional Mock-Up Unit informed Neural Networks (FMUINNs): ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"You can evaluate FMUs inside of your loss function. ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: Dev Docs)  (Image: Test (latest)) (Image: Test (LTS)) (Image: Examples) (Image: Build Docs) (Image: Run PkgEval) (Image: Coverage) (Image: ColPrac: Contributor's Guide on Collaborative Practices for Community Packages) (Image: SciML Code Style)","category":"page"},{"location":"#How-can-I-use-FMIFlux.jl?","page":"Introduction","title":"How can I use FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"1. Open a Julia-REPL, switch to package mode using ], activate your preferred environment.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"2. Install  FMIFlux.jl:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(@v1) pkg> add FMIFlux","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"3. If you want to check that everything works correctly, you can run the tests bundled with FMIFlux.jl:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(@v1) pkg> test FMIFlux","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"4. Have a look inside the examples folder in the examples branch or the examples section of the documentation. All examples are available as Julia-Script (.jl), Jupyter-Notebook (.ipynb) and Markdown (.md).","category":"page"},{"location":"#What-is-currently-supported-in-FMIFlux.jl?","page":"Introduction","title":"What is currently supported in FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"building and training ME-NeuralFMUs (NeuralODEs) with support for event-handling (DiffEqCallbacks.jl) and discontinuous sensitivity analysis (SciMLSensitivity.jl)\nbuilding and training CS-NeuralFMUs \nbuilding and training NeuralFMUs consisting of multiple FMUs\nbuilding and training FMUINNs (PINNs)\ndifferent AD-frameworks: ForwardDiff.jl (CI-tested), ReverseDiff.jl (CI-tested, default setting), FiniteDiff.jl (not CI-tested) and Zygote.jl (not CI-tested)\nuse Flux.jl optimizers as well as the ones from Optim.jl\nusing the entire DifferentialEquations.jl solver suite (autodiff=false for implicit solvers, not all are tested, see following section)\n...","category":"page"},{"location":"#(Current)-Limitations","page":"Introduction","title":"(Current) Limitations","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Not all implicit solvers work for challenging, hybrid models (stiff FMUs with events), currently tested are: Rosenbrock23(autodiff=false).\nImplicit solvers using autodiff=true is not supported (now), but you can use implicit solvers with autodiff=false.\nSensitivity information over state change by event partial x^+  partial x^- can't be accessed in FMI. ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"These sensitivities are sampled if the FMU supports fmiXGet/SetState. If this feature is not available, wrong sensitivities are computed, which my influence your optimization (dependent on the use case). This issue is also part of the OpenScaling research project.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"If continuous adjoints instead of automatic differentiation through the ODE solver (discrete adjoint) are applied, this might lead to issues, because FMUs are by design not capable of being simulated backwards in time. ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"On the other hand, many FMUs are capable of doing so. This issue is also part of the OpenScaling research project.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"For now, only FMI version 2.0 is supported, but FMI 3.0 support is coming with the OpenScaling research project.","category":"page"},{"location":"#What-is-under-development-in-FMIFlux.jl?","page":"Introduction","title":"What is under development in FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"performance optimizations\nmulti threaded CPU training\nimproved documentation\nmore examples\nFMI3 integration\n...","category":"page"},{"location":"#What-Platforms-are-supported?","page":"Introduction","title":"What Platforms are supported?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"FMIFlux.jl is tested (and testing) under Julia versions v1.6 (LTS) and v1 (latest) on Windows (latest) and Ubuntu (latest). MacOS should work, but untested. All shipped examples are automatically tested under Julia version v1 (latest) on Windows (latest).","category":"page"},{"location":"#What-FMI.jl-Library-should-I-use?","page":"Introduction","title":"What FMI.jl-Library should I use?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: FMI.jl Family) To keep dependencies nice and clean, the original package FMI.jl had been split into new packages:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"FMI.jl: High level loading, manipulating, saving or building entire FMUs from scratch\nFMIImport.jl: Importing FMUs into Julia\nFMIExport.jl: Exporting stand-alone FMUs from Julia Code\nFMIBase.jl: Common concepts for import and export of FMUs\nFMICore.jl: C-code wrapper for the FMI-standard\nFMISensitivity.jl: Static and dynamic sensitivities over FMUs\nFMIBuild.jl: Compiler/Compilation dependencies for FMIExport.jl\nFMIFlux.jl: Machine Learning with FMUs\nFMIZoo.jl: A collection of testing and example FMUs","category":"page"},{"location":"#Video-Workshops","page":"Introduction","title":"Video-Workshops","text":"","category":"section"},{"location":"#JuliaCon-2024-(Eindhoven-University-of-Technology,-Netherlands)","page":"Introduction","title":"JuliaCon 2024 (Eindhoven University of Technology, Netherlands)","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: YouTube Video of Workshop)","category":"page"},{"location":"#JuliaCon-2023-(Massachusetts-Institute-of-Technology,-United-States)","page":"Introduction","title":"JuliaCon 2023 (Massachusetts Institute of Technology, United States)","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: YouTube Video of Workshop)","category":"page"},{"location":"#How-to-cite?","page":"Introduction","title":"How to cite?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Tobias Thummerer, Johannes Stoljar and Lars Mikelsons. 2022. NeuralFMU: presenting a workflow for integrating hybrid NeuralODEs into real-world applications. Electronics 11, 19, 3202. DOI: 10.3390/electronics11193202","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. NeuralFMU: towards structural integration of FMUs into neural networks. Martin SjÃ¶lund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, LinkÃ¶ping, Sweden, September 20-24, 2021. LinkÃ¶ping University Electronic Press, LinkÃ¶ping (LinkÃ¶ping Electronic Conference Proceedings ; 181), 297-306. DOI: 10.3384/ecp21181297","category":"page"},{"location":"#Related-publications?","page":"Introduction","title":"Related publications?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Tobias Thummerer, Johannes Tintenherr, Lars Mikelsons 2021. Hybrid modeling of the human cardiovascular system using NeuralFMUs Journal of Physics: Conference Series 2090, 1, 012155. DOI: 10.1088/1742-6596/2090/1/012155","category":"page"}]
}
