var documenterSearchIndex = {"docs":
[{"location":"examples/workshops/","page":"Pluto Workshops","title":"Pluto Workshops","text":"Pluto based notebooks, that can easyly be executed on your own Pluto-Setup.","category":"page"},{"location":"examples/workshops/","page":"Pluto Workshops","title":"Pluto Workshops","text":"<iframe src=\"../pluto-src/index.html\" style=\"height:500px;width:100%;\"></iframe>","category":"page"},{"location":"contents/","page":"Contents","title":"Contents","text":"Depth = 2","category":"page"},{"location":"examples/juliacon_2023/#Using-NeuralODEs-in-real-life-applications","page":"JuliaCon 2023","title":"Using NeuralODEs in real life applications","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Tutorial by Tobias Thummerer | Last edit: November 08 2023","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"This workshop was held at the JuliaCon 2023 | July 25 2023 | MIT (Boston, USA)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Keywords: #NeuralODE, #NeuralFMU, #SciML, #PeNODE, #HybridModeling","category":"page"},{"location":"examples/juliacon_2023/#Workshop-Video","page":"JuliaCon 2023","title":"Workshop Video","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: YouTube Video of Workshop)","category":"page"},{"location":"examples/juliacon_2023/#License","page":"JuliaCon 2023","title":"License","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# Copyright (c) 2023 Tobias Thummerer, Lars Mikelsons\n# Licensed under the MIT license. \n# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details.\n\n# This workshop was held at the JuliaCon2023 @ MIT (Boston)","category":"page"},{"location":"examples/juliacon_2023/#Introduction","page":"JuliaCon 2023","title":"Introduction","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"NeuralODEs lead to amazing results in academic examples. But the expectations are often being disappointed as soon as one tries to adapt this concept for real life use cases. Bad convergence behavior, handling of discontinuities and/or instabilities are just some of the stumbling blocks that might pop up during the first steps. During the workshop, we want to show how to integrate real life industrial models in NeuralODEs using FMI and present sophisticated training strategies.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"This tutorial can be used in two ways:","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"As a single script, showing how a NeuralFMU can be setup and trained. Results can be loaded from a precomputed hyperparameter optimization.\nAs a module (see sections Optional: Organize as module) together with the file juliacon_2023_distributedhyperopt.jl to perform your own distributed hyperparameter optimization.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"This workshops divides into five sections:","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Installing / Loading the Packages\nLoading FMU & Data\nNeuralFMU setup\nTraining the NeuralFMU\nResults","category":"page"},{"location":"examples/juliacon_2023/#1.-Installing-/-Loading-the-Packages","page":"JuliaCon 2023","title":"1. Installing / Loading the Packages","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Before we start modeling our NeuralODE, we load all required packages. If some packages are still missing, install them by typing import Pkg; Pkg.add(\"[PKG-NAME]\").","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# Loading the required libraries\nusing FMI           # import FMUs into Julia \nusing FMIFlux       # for NeuralFMUs\nusing FMIZoo        # a collection of demo models, including the VLDM\nusing FMIFlux.Flux  # Machine Learning in Julia\n\nimport JLD2         # data format for saving/loading parameters\n\nimport Random       # for fixing the random seed\nusing Plots         # plotting results","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mError requiring `Enzyme` from `LinearSolve`\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  exception =\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   LoadError: ArgumentError: Package LinearSolve does not have Enzyme in its dependencies:\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - You may have a partially installed environment. Try `Pkg.instantiate()`\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     to ensure all packages in the environment are installed.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - Or, if you have LinearSolve checked out for development and have\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     added Enzyme as a dependency but haven't updated your primary\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     environment's manifest file, try `Pkg.resolve()`.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - Otherwise you may need to report an issue with LinearSolve\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   Stacktrace:\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1167\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:223\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [3] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1144\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [4] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:419\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [5] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4mLinearSolve.jl:1\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mRequires.jl:40\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [7] top-level scope\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4minit.jl:16\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [8] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mboot.jl:368\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [9] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4mLinearSolve.jl:1\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [10] \u001b[0m\u001b[1m(::LinearSolve.var\"#88#97\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:101\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [11] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m\u001b[4mtiming.jl:382\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [12] \u001b[0m\u001b[1merr\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mAny, \u001b[90mlistener\u001b[39m::\u001b[0mModule, \u001b[90mmodname\u001b[39m::\u001b[0mString, \u001b[90mfile\u001b[39m::\u001b[0mString, \u001b[90mline\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:47\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [13] \u001b[0m\u001b[1m(::LinearSolve.var\"#87#96\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:100\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [14] \u001b[0m\u001b[1mwithpath\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mAny, \u001b[90mpath\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:37\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [15] \u001b[0m\u001b[1m(::LinearSolve.var\"#86#95\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:99\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [16] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [17] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [18] \u001b[0m\u001b[1mforeach\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mtypeof(Base.invokelatest), \u001b[90mitr\u001b[39m::\u001b[0mVector\u001b[90m{Function}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mabstractarray.jl:2774\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [19] \u001b[0m\u001b[1mloadpkg\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:27\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [20] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [21] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [22] \u001b[0m\u001b[1mrun_package_callbacks\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmodkey\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:869\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [23] \u001b[0m\u001b[1m_tryrequire_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmodkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90msourcepath\u001b[39m::\u001b[0mString, \u001b[90mdepmods\u001b[39m::\u001b[0mVector\u001b[90m{Any}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:944\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [24] \u001b[0m\u001b[1m_require_search_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msourcepath\u001b[39m::\u001b[0mString, \u001b[90mbuild_id\u001b[39m::\u001b[0mUInt64\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1028\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [25] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1315\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [26] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1200\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [27] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1180\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [28] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:223\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [29] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1144\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [30] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mboot.jl:368\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [31] \u001b[0m\u001b[1minclude_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmapexpr\u001b[39m::\u001b[0mtypeof(REPL.softscope), \u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1428\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [32] \u001b[0m\u001b[1msoftscope_include_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[32mSoftGlobalScope\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\SoftGlobalScope\\u4UzH\\src\\\u001b[39m\u001b[90m\u001b[4mSoftGlobalScope.jl:65\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [33] \u001b[0m\u001b[1mexecute_request\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket, \u001b[90mmsg\u001b[39m::\u001b[0mIJulia.Msg\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\IJulia\\Vo51o\\src\\\u001b[39m\u001b[90m\u001b[4mexecute_request.jl:67\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [34] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [35] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [36] \u001b[0m\u001b[1meventloop\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\IJulia\\Vo51o\\src\\\u001b[39m\u001b[90m\u001b[4meventloop.jl:8\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [37] \u001b[0m\u001b[1m(::IJulia.var\"#15#18\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mtask.jl:484\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   in expression starting at C:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\ext\\LinearSolveEnzymeExt.jl:1\n\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Requires C:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\require.jl:51\u001b[39m","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Beside the packages, we use another little script that includes some nice plotting functions specially for this workshop.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# a helper file with some predefined functions to make \"things look nicer\", but are not really relevant to the topic\ninclude(joinpath(@__DIR__, \"juliacon_2023_helpers.jl\"));","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Because notebooks can't handle progress bars, we disable progress bar printing - but feel free to enable it if you are using the code outside of a jupyter notebook. The progress bar gives further helpful information, like the estimated remaining computation time for simulation and training.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# disable progress bars in jupyter notebook\nshowProgress=false;","category":"page"},{"location":"examples/juliacon_2023/#2.-Loading-FMU-and-Data","page":"JuliaCon 2023","title":"2. Loading FMU & Data","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Before starting with hybrid modeling, we load in the used training data and our FMU of the VLDM. We simulate the FMU, plot the results and compare them to data. ","category":"page"},{"location":"examples/juliacon_2023/#2.1-Loading-measurement-data","page":"JuliaCon 2023","title":"2.1 Loading measurement data","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We start by loading in the data (training and validation) used in this tutorial from FMIZoo.jl - a container library for different system model FMUs and corresponding data.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Note: There where two measurements done, so data is a mean value with some deviation around (not an exact line).","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# FMIZoo.jl supports different data sampling rates (by interpolation), sample length for data is 0.1s\ndt = 0.1 \n\n# load data (training) from FMIZoo.jl\ndata = VLDM(:train, dt=dt) \n\n# plot the velocity consumption (training data)\nplot(data.speed_t,              # the time points the speed was captures (from data)\n     data.speed_val;            # the speeds at the considered time points (from data)\n     ribbon=data.speed_dev,     # a `ribbon` for the speed deviation - so the `uncertainty` because we made two measurements - but don't expect too much to see (very little uncertainty)\n     fillalpha=0.3,             # alpha value for the ribbon\n     label=\"Data\",              # the plot label\n     title=\"WLTC (first 40%)\",  # plot title\n     xlabel=\"t [s]\",            # plot x-label\n     ylabel=\"velocity [m/s]\")   # plot y-label","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Further, we load validation data and have a look on it, too.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# load data (validation) from FMIZoo.jl\ndata_validation = VLDM(:validate, dt=dt)\n\n# plot the velocity consumption (validation data)\nplot(data_validation.speed_t, data_validation.speed_val; label=\"Data\", ribbon=data_validation.speed_dev, fillalpha=0.3, title=\"WLTC (complete)\", xlabel=\"t [s]\", ylabel=\"velocity [m/s]\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Let's extract a simulation starting time tStart and stopping time tStop from data - so we simulate as far as data is available. tSave are the points in time we want our ODE solution beeing saved later.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# start (`tStart`) and stop time (`tStop`) for simulation, saving time points for ODE solver (`tSave`)\ntStart = data.consumption_t[1]\ntStop = data.consumption_t[end]\ntSave = data.consumption_t","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"5838-element Vector{Float64}:\n   0.0\n   0.1\n   0.2\n   0.3\n   0.4\n   0.5\n   0.6\n   0.7\n   0.8\n   0.9\n   1.0\n   1.1\n   1.2\n   ⋮\n 582.6\n 582.7\n 582.8\n 582.9\n 583.0\n 583.1\n 583.2\n 583.3\n 583.4\n 583.5\n 583.6\n 583.7","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"So you can see time points are sampled with dt=0.1 as specified and the cycle ranges from 00s to 5837s.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Next is to get a value for the start state x0, so the initial state to solve the FMU and NeuralFMU.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# get start state vector from data (FMIZoo)\nx0 = FMIZoo.getStateVector(data,    # the data container\n                           tStart)  # the point in time where we want the state","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"6-element Vector{Float64}:\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0\n 0.0","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"In this special case, it's all zero, but this is not the default over different system!","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Further, we can check for the loaded FMU parameters, that are paths to the used characterisitc maps used in the model.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# have a look on the FMU parameters (these are the file paths to the characteristic maps, remaining parameters are set to default by the FMU)\ndisplay(data.params)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Dict{String, Any} with 3 entries:\n  \"peFileName\" => \"C:\\\\Users\\\\runneradmin\\\\.julia\\\\packages\\\\FMIZoo\\\\gp8Qi\\\\src…\n  \"edFileName\" => \"C:\\\\Users\\\\runneradmin\\\\.julia\\\\packages\\\\FMIZoo\\\\gp8Qi\\\\src…\n  \"dcFileName\" => \"C:\\\\Users\\\\runneradmin\\\\.julia\\\\packages\\\\FMIZoo\\\\gp8Qi\\\\src…","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"After that, we load the FMU and have a look on its model meta data.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# load our FMU of the VLDM (we take it from the FMIZoo.jl, exported with Dymola 2020x)\nfmu = fmiLoad(\"VLDM\", \"Dymola\", \"2020x\"; type=:ME) \n\n# let's have a look on the model meta data\nfmiInfo(fmu)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tLongitudinaldynamic.LongitudinaldynamicmodelContinuous\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{669889ab-7ab7-4fac-be92-96b6cd0b86a6}\n\tGeneration tool:\t\tDymola Version 2020x (64-bit), 2019-10-10\n\tGeneration time:\t\t2022-07-22T09:32:50Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t28\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t6\n\t\t33554432 [\"driver.accelerationPedalController.PI.x\"]\n\t\t33554433 [\"driver.brakePedalController.PI.x\"]\n\t\t33554434 [\"drivingCycle.s\"]\n\t\t33554435 [\"dynamics.accelerationCalculation.integrator.y\"]\n\t\t33554436 [\"dynamics.accelerationCalculation.limiter.u\", \"dynamics.accelerationCalculation.limIntegrator.y\", \"dynamics.accelerationCalculation.limiter.simplifiedExpr\"]\n\t\t33554437 [\"result.integrator.y\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tLongitudinaldynamic_LongitudinaldynamicmodelContinuous\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tLongitudinaldynamic_LongitudinaldynamicmodelContinuous\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"One can find many useful things, like the number of states (6), inputs (0) and outputs (0), their names and information about supported features. ","category":"page"},{"location":"examples/juliacon_2023/#2.2-Simulating-the-FMU","page":"JuliaCon 2023","title":"2.2 Simulating the FMU","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Simulating is as easy as calling fmiSimulate. Note, that we are putting in the paramter dictionary data.params from above. This FMU has many events, these are detected and handled automatically by FMI.jl.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# let's run a simulation from `tStart` to `tStop`, use the parameters we just viewed for the simulation run\nresultFMU = fmiSimulate(fmu,                        # the loaded FMU of the VLDM \n                        (tStart, tStop);            # the simulation time range\n                        parameters=data.params,     # the parameters for the VLDM\n                        showProgress=showProgress,  # show (or don't) the progres bar\n                        recordValues=:derivatives,  # record all state derivatives\n                        saveat=tSave)               # save solution points at `tSave`\ndisplay(resultFMU)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Model name:\n\tLongitudinaldynamic.LongitudinaldynamicmodelContinuous\nSuccess:\n\ttrue\nf(x)-Evaluations:\n\tIn-place: 351569\n\tOut-of-place: 0\nJacobian-Evaluations:\n\t∂ẋ_∂p: 0\n\t∂ẋ_∂x: 0\n\t∂ẋ_∂u: 0\n\t∂y_∂p: 0\n\t∂y_∂x: 0\n\t∂y_∂u: 0\n\t∂e_∂p: 0\n\t∂e_∂x: 0\n\t∂e_∂u: 0\n\t∂xr_∂xl: 0\nGradient-Evaluations:\n\t∂ẋ_∂t: 0\n\t∂y_∂t: 0\n\t∂e_∂t: 0\nCallback-Evaluations:\n\tCondition (event-indicators): 702563\n\tTime-Choice (event-instances): 58371\n\tAffect (event-handling): 58409\n\tSave values: 5838\n\tSteps completed: 58453\nStates [5838]:\n\t0.0\t[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n\t0.1\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 14.260000000955804]\n\t0.2\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 28.52000000095581]\n\t0.3\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 42.78000000095581]\n\t0.4\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 57.04000000095582]\n\t0.5\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 71.30000000095582]\n\t0.6\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 85.56000000095582]\n\t0.7\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 99.82000000095582]\n\t0.8\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 114.08000000095585]\n\t...\n\t583.7\t[-0.0019167094141548354, -0.05412068948856807, 3131.826061088357, 3131.346887728074, -4.101081869676333e-5, 1.4259873371357084e6]\nValues [5838]:\n\t0.0\t(0.0, 0.0, 0.0, 0.0, -0.1773972602739726, 142.6)\n\t0.1\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.2\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.3\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.4\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.5\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.6\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.7\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t0.8\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\n\t...\n\t583.7\t(0.0, 0.0, 0.0, 0.0, 0.0, 142.6)\nEvents [58409]:\n\tTime-Event @ 0.01s (state-change: false)\n\tTime-Event @ 0.02s (state-change: false)\n\tTime-Event @ 0.03s (state-change: false)\n\tTime-Event @ 0.04s (state-change: false)\n\tTime-Event @ 0.05s (state-change: false)\n\tTime-Event @ 0.06s (state-change: false)\n\tTime-Event @ 0.07s (state-change: false)\n\tTime-Event @ 0.08s (state-change: false)\n\tTime-Event @ 0.09s (state-change: false)\n\t...\n\tTime-Event @ 583.7s (state-change: false)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"This way, you can see interessting metadata on the solution process, like the number of evaluations of the ODE-function, sensitivity or callback evaluations. ","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We can use the plot command to plot simulation results from FMUs, too!","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# Plot the simulation results\nfig = plot(resultFMU;                               # the simulation result from above \n           values=false,                            # don't plot values (:derivatives)\n           stateIndices=6:6,                        # only plot states 6 to 6 -> so state 6 ;-)\n           ylabel=\"Cumulative consumption [Ws]\",    # set the title for the y-label\n           label=\"FMU\")                             # title the plot line \n\n# further plot the (measurement) data values `consumption_val` and deviation between measurements `consumption_dev`\nplot!(fig, data.cumconsumption_t, data.cumconsumption_val; label=\"Data\", ribbon=data.cumconsumption_dev, fillalpha=0.3)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mfmiPlot(...): Number of time events (58370) exceeding 100, disabling automatic plotting of time events (can be forced with keyword `timeEvents=true`).","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"The simulation result we already know from the introduction!","category":"page"},{"location":"examples/juliacon_2023/#3.-NeuralFMU-setup","page":"JuliaCon 2023","title":"3. NeuralFMU setup","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: NeuralFMU)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Equipped with data and a simulation model, we can setup the NeuralFMU as introduced in the workshop.","category":"page"},{"location":"examples/juliacon_2023/#3.1-Pre-and-Post-Processing","page":"JuliaCon 2023","title":"3.1 Pre- and Post-Processing","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We gather the three derivative values from the last simulation run, to have values for initialization of the pre- and post-processing layers.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# variable we want to manipulate - why we are picking exactly these three is shown a few lines later ;-)\nmanipulatedDerVars = [\"der(dynamics.accelerationCalculation.integrator.y)\",\n                      \"der(dynamics.accelerationCalculation.limIntegrator.y)\",\n                      \"der(result.integrator.y)\"]\nmanipulatedDerVals = fmiGetSolutionValue(resultFMU, manipulatedDerVars)\n\n# what happens without propper transformation between FMU- and ANN-domain?\nplot(resultFMU.values.t, manipulatedDerVals[1,:][1]; label=\"original\", xlabel=\"t [s]\", ylabel=\"velocity [m/s]\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"But what happens if we put the velocity into the hyperbolic tangens function?","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"plot!(resultFMU.values.t, tanh.(manipulatedDerVals[1,:][1]); label=\"tanh(velocity)\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"It gets saturated drastically! That's why we need shift- and scale layers for online pre- and post-processing!","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We introduce the ShiftScale-layer for pre-processing our data.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# pre- and post-processing\npreProcess = ShiftScale(manipulatedDerVals);    # we put in the derivatives recorded above, FMIFlux shift and scales so we have a data mean of 0 and a standard deivation of 1 (other activation functions / ranges are possible!)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"How does the velocity look after pushing it through the ShiftScale-layer?","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"testVals = collect(tanh(preProcess(collect(val[t] for val in manipulatedDerVals))[1]) for t in 1:length(resultFMU.values.t))\nplot!(resultFMU.values.t, \n      testVals; \n      label=\"tanh(preProcess(velocity))\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"You can clearly see, that after pre-processing, the trajectory (green) still mirrors the dynamical behaviour of the original system (blue), while the not pre-processed option (orange) just saturates values. ","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# we add some additional \"buffer\" - this is not necessary but helps to preserve peakes\npreProcess.scale[:] *= 0.25;    \n\n# initialize the postPrcess as inverse of the preProcess, but only take indices 2 and 3 (we don't need 1, the vehcile velocity)\npostProcess = ScaleShift(preProcess; indices=2:3);","category":"page"},{"location":"examples/juliacon_2023/#3.2-Building-the-NeuralFMU","page":"JuliaCon 2023","title":"3.2 Building the NeuralFMU","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"To make this more usable, we put the entire NeuralFMU building process (including the pre- and post-processing we had a detailed look on) into a dedicated function build_FMU.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# function that builds the considered NeuralFMU on basis of a given FMU (FMI-Version 2.0) `f`\nfunction build_NFMU(f::FMU2)\n    \n    # pre- and post-processing\n    preProcess = ShiftScale(manipulatedDerVals)         # we put in the derivatives recorded above, FMIFlux shift and scales so we have a data mean of 0 and a standard deivation of 1\n    preProcess.scale[:] *= 0.25                         # add some additional \"buffer\"\n    postProcess = ScaleShift(preProcess; indices=2:3)   # initialize the postPrcess as inverse of the preProcess, but only take indices 2 and 3 (we don't need 1, the vehcile velocity)\n\n    # cache\n    cache = CacheLayer()                        # allocate a cache layer\n    cacheRetrieve = CacheRetrieveLayer(cache)   # allocate a cache retrieve layer, link it to the cache layer\n\n    # we have two signals (acceleration, consumption) and two sources (ANN, FMU), so four gates:\n    # (1) acceleration from FMU (gate=1.0 | open)\n    # (2) consumption  from FMU (gate=1.0 | open)\n    # (3) acceleration from ANN (gate=0.0 | closed)\n    # (4) consumption  from ANN (gate=0.0 | closed)\n    # the acelerations [1,3] and consumptions [2,4] are paired\n    gates = ScaleSum([1.0, 1.0, 0.0, 0.0], [[1,3], [2,4]]) # gates with sum\n\n    # setup the NeuralFMU topology\n    model = Chain(x -> f(; x=x, dx_refs=:all),        # take `x`, put it into the FMU, retrieve all derivatives `dx`\n                  dx -> cache(dx),                    # cache `dx`\n                  dx -> dx[4:6],                      # forward only dx[4, 5, 6]\n                  preProcess,                         # pre-process `dx`\n                  Dense(3, 32, tanh),                 # Dense Layer 3 -> 32 with `tanh` activation\n                  Dense(32, 2, tanh),                 # Dense Layer 32 -> 2 with `tanh` activation \n                  postProcess,                        # post process `dx`\n                  dx -> cacheRetrieve(5:6, dx),       # dynamics FMU | dynamics ANN\n                  gates,                              # compute resulting dx from ANN + FMU\n                  dx -> cacheRetrieve(1:4, dx))       # stack together: dx[1,2,3,4] from cache + dx[5,6] from gates\n\n    solver = Tsit5()\n    \n    # new NeuralFMU \n    neuralFMU = ME_NeuralFMU(f,                 # the FMU used in the NeuralFMU \n                             model,             # the model we specified above \n                             (tStart, tStop),   # a default start ad stop time for solving the NeuralFMU\n                             solver;\n                             saveat=tSave)      # the time points to save the solution at\n    neuralFMU.modifiedState = false             # speed optimization (NeuralFMU state equals FMU state)\n    \n    return neuralFMU \nend","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"build_NFMU (generic function with 1 method)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Let's test the NeuralFMU: First, load the FMU und built a NeuralFMU from it.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# build NeuralFMU\nneuralFMU = build_NFMU(fmu);","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Next, do a simulation for a given start state x0 from FMIZoo.jl.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# simulate and plot the (uninitialized) NeuralFMU\nresultNFMU = neuralFMU(x0,                          # the start state to solve the ODE\n                       (tStart, tStop);             # the simulation range\n                       parameters=data.params,      # the parameters for the VLDM\n                       showProgress=showProgress,   # show progress (or not)\n                       saveat=tSave)                # the time points to save the solution at\n\ndisplay(resultNFMU)     ","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNo solver keyword detected for NeuralFMU.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mContinuous adjoint method is applied, which requires solving backward in time.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis might be not supported by every FMU.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m(This message is only printed once.)\n\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ FMICore C:\\Users\\runneradmin\\.julia\\packages\\FMICore\\7NIyu\\src\\printing.jl:38\u001b[39m\n\n\n\nModel name:\n\tLongitudinaldynamic.LongitudinaldynamicmodelContinuous\nSuccess:\n\ttrue\nf(x)-Evaluations:\n\tIn-place: 409926\n\tOut-of-place: 0\nJacobian-Evaluations:\n\t∂ẋ_∂p: 0\n\t∂ẋ_∂x: 0\n\t∂ẋ_∂u: 0\n\t∂y_∂p: 0\n\t∂y_∂x: 0\n\t∂y_∂u: 0\n\t∂e_∂p: 0\n\t∂e_∂x: 0\n\t∂e_∂u: 0\n\t∂xr_∂xl: 0\nGradient-Evaluations:\n\t∂ẋ_∂t: 0\n\t∂y_∂t: 0\n\t∂e_∂t: 0\nCallback-Evaluations:\n\tCondition (event-indicators): 702407\n\tTime-Choice (event-instances): 58371\n\tAffect (event-handling): 58409\n\tSave values: 0\n\tSteps completed: 58440\nStates [5838]:\n\t0.0\t[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n\t0.1\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 14.260000000955804]\n\t0.2\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 28.52000000095581]\n\t0.3\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 42.78000000095581]\n\t0.4\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 57.04000000095582]\n\t0.5\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 71.30000000095582]\n\t0.6\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 85.56000000095582]\n\t0.7\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 99.82000000095582]\n\t0.8\t[-1.0313822985067192e-12, -1.5470734477600789e-12, 0.0, 7.219676089547036e-12, -1.0224379404543445e-5, 114.08000000095585]\n\t...\n\t583.7\t[-0.0019167094095929496, -0.05412068948173642, 3131.826061088355, 3131.346887534511, -4.3267310775903565e-5, 1.4259877656768537e6]\nEvents [58409]:\n\tTime-Event @ 0.01s (state-change: false)\n\tTime-Event @ 0.02s (state-change: false)\n\tTime-Event @ 0.03s (state-change: false)\n\tTime-Event @ 0.04s (state-change: false)\n\tTime-Event @ 0.05s (state-change: false)\n\tTime-Event @ 0.06s (state-change: false)\n\tTime-Event @ 0.07s (state-change: false)\n\tTime-Event @ 0.08s (state-change: false)\n\tTime-Event @ 0.09s (state-change: false)\n\t...\n\tTime-Event @ 583.7s (state-change: false)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"As for the FMU, we can display the NeuralFMU simulation result and check some statisitics.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Now, let's have a look on the cumulative consumption plot ...","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# plot the NeuralFMU, original FMU and data (cumulative consumption)\nfig = plot(resultNFMU; stateIndices=6:6, stateEvents=false, timeEvents=false, label=\"NeuralFMU (untrained)\", ylabel=\"cumulative consumption [Ws]\")\nplot!(fig, resultFMU; stateIndices=6:6, values=false, stateEvents=false, timeEvents=false, label=\"FMU\")\nplot!(fig, data.cumconsumption_t, data.cumconsumption_val, label=\"Data\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"As you can see, the FMU und NeuralFMU result looks identically - and this is what we expect for a fully open FMU gate and a fully closed ANN gate!","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Finally, unload the FMU and invalidate the NeuralFMU.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# unload FMU / invalidate NeuralFMU\nfmiUnload(fmu)\nneuralFMU = nothing","category":"page"},{"location":"examples/juliacon_2023/#4.-Training-the-NeuralFMU","page":"JuliaCon 2023","title":"4. Training the NeuralFMU","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"An untrained NeuralFMU is not that impressive - so let's train it a bit. ","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We start by defining a time sequence (the time points of data measurements) and the cumulative consumption values we want to train for.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# prepare training data \ntrain_t = data.consumption_t \n\n# data is as \"array of arrays\" required (often we have multidimensional data)\ntrain_data = collect([d] for d in data.cumconsumption_val)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"5838-element Vector{Vector{Float64}}:\n [0.0]\n [-0.41296068176650935]\n [0.26787411983582043]\n [0.7202168791949798]\n [1.0714482470335085]\n [1.390037422822217]\n [2.1200151652794643]\n [2.5196535613914306]\n [2.656369007464336]\n [2.993187294279602]\n [3.4693116134235407]\n [4.049369938809381]\n [4.673174216401814]\n ⋮\n [1.3879359188013095e6]\n [1.3879515067827937e6]\n [1.3879669882976608e6]\n [1.3879825294049252e6]\n [1.3879980607748663e6]\n [1.3880134565080018e6]\n [1.3880287579379592e6]\n [1.388044098663902e6]\n [1.388059371012591e6]\n [1.388074504338062e6]\n [1.3880896849414955e6]\n [1.3881049434185931e6]","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"The data sequence is too long to train on it all at once - so we need to batch our data.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"First, we introduce some hyperparameters. Training success always depends on a good choice of hyperparameters, we use the following hyperparameters in this workshop:","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"BATCHDUR the duration of a single batch element (length) in seconds.\nTRAINDUR specifies the training duration (meassured on data) in seconds.\nETA the update rate eta of the Adam optimizer.\nBETA1 the first momentum coefficient beta_1 of the Adam optimizer.\nBETA2 the second momentum coefficient beta_2 of the Adam optimizer. \nLASTWEIGHT a weighting factor between the last solution point and all remaining solution points.\nSCHEDULER an identifier for the batch scheduler, can be :Sequential, :Random or :LossAccumulation.\nLOSS an identifier for the loss function to use, :MAE or :MSE.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Next, the loss function is defined. The loss is computed on basis of a given solution and data. Dependent on the hyperparameter LOSS, either :MAE or :MSE is used to compute the loss. The hyperparameter LASTWEIGHT determines how much the last solution point is weight against the remaining solution points. For example a value of 03 determines that the last point of the solution contributes 30 to the loss, whereas all remaining solution points contribute 70 in total.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"function _lossFct(solution::FMU2Solution, data::VLDM_Data, LOSS::Symbol, LASTWEIGHT::Real=1.0/length(data.consumption_t) )\n\n    # determine the start/end indices `ts` and `te` in the data array (sampled with 10Hz)\n    ts = dataIndexForTime(solution.states.t[1])\n    te = dataIndexForTime(solution.states.t[end])\n    \n    # retrieve the data from NeuralODE (\"where we are\") and data from measurements (\"where we want to be\") and an allowed deviation (\"we are unsure about\")\n    nfmu_cumconsumption = fmiGetSolutionState(solution, 6; isIndex=true)\n    cumconsumption = data.cumconsumption_val[ts:te]\n    cumconsumption_dev = data.cumconsumption_dev[ts:te]\n\n    Δcumconsumption = 0.0\n    if LOSS == :MAE\n        Δcumconsumption = FMIFlux.Losses.mae_last_element_rel_dev(nfmu_cumconsumption,  # NeuralFMU \n                                                                  cumconsumption,       # data target\n                                                                  cumconsumption_dev,   # data uncertainty\n                                                                  LASTWEIGHT)           # how much do we scale the last point compared to the remaing ones?\n    elseif LOSS == :MSE\n        Δcumconsumption = FMIFlux.Losses.mse_last_element_rel_dev(nfmu_cumconsumption, \n                                                                  cumconsumption, \n                                                                  cumconsumption_dev, \n                                                                  LASTWEIGHT)\n    else\n        @assert false, \"Unknown LOSS: `$(LOSS)`\"\n    end\n    \n    return Δcumconsumption \nend","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"_lossFct (generic function with 2 methods)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Finally, the function train! is defined, that triggers a new training run for a given set of hyperparameters hyper_params, a training ressource ressource and the current training index ind.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# ressource = training time horizon (duration of data seen)\nfunction train!(hyper_params, ressource, ind)\n\n    # make the runs determinisitic by fixing the random seed\n    Random.seed!(1234)\n\n    # training duration (in seconds) equals the given ressource\n    TRAINDUR = ressource\n\n    # unpack the hyperparemters\n    ETA, BETA1, BETA2, BATCHDUR, LASTWEIGHT, SCHEDULER, LOSS = hyper_params\n\n    # compute the number of training steps TRAINDUR / BATCHDUR, but do at least one step\n    steps = max(round(Int, TRAINDUR/BATCHDUR), 1) \n\n    # print a bit of info\n    @info \"--------------\\nStarting run $(ind) with parameters: $(hyper_params) and ressource $(ressource) doing $(steps) step(s).\\n--------------------\"\n\n    # load our FMU (we take one from the FMIZoo.jl, exported with Dymola 2020x)\n    fmu = fmiLoad(\"VLDM\", \"Dymola\", \"2020x\"; type=:ME) \n\n    # built the NeuralFMU on basis of the loaded FMU `fmu`\n    neuralFMU = build_NFMU(fmu)\n\n    # a more efficient execution mode\n    fmiSingleInstanceMode(fmu, true)\n    \n    # batch the data (time, targets), train only on model output index 6, plot batch elements\n    batch = batchDataSolution(neuralFMU,                            # our NeuralFMU model\n                              t -> FMIZoo.getStateVector(data, t),  # a function returning a start state for a given time point `t`, to determine start states for batch elements\n                              train_t,                              # data time points\n                              train_data;                           # data cumulative consumption \n                              batchDuration=BATCHDUR,               # duration of one batch element\n                              indicesModel=6:6,                     # model indices to train on (6 equals the state `cumulative consumption`)\n                              plot=false,                           # don't show intermediate plots (try this outside of Jupyter)\n                              parameters=data.params,               # use the parameters (map file paths) from *FMIZoo.jl*\n                              showProgress=showProgress)            # show or don't show progess bar, as specified at the very beginning\n\n    # limit the maximum number of solver steps to 1000 * BATCHDUR (longer batch elements get more steps)\n    # this allows the NeuralFMU to do 10x more steps (average) than the original FMU, but more should not be tolerated (to stiff system)\n    solverKwargsTrain = Dict{Symbol, Any}(:maxiters => round(Int, 1000*BATCHDUR)) \n    \n    # a smaller dispatch for our custom loss function, only taking the solution object\n    lossFct = (solution::FMU2Solution) -> _lossFct(solution, data, LOSS, LASTWEIGHT)\n\n    # selecting a scheduler for training\n    scheduler = nothing\n    if SCHEDULER == :Random\n        # a scheduler that picks a random batch element\n        scheduler = RandomScheduler(neuralFMU, batch; applyStep=1, plotStep=0)\n    elseif SCHEDULER == :Sequential\n        # a scheduler that picks one batch element after another (in chronological order)\n        scheduler = SequentialScheduler(neuralFMU, batch; applyStep=1, plotStep=0)\n    elseif SCHEDULER == :LossAccumulation\n        # a scheduler that picks the element with largest accumulated loss:\n        # - after every training step, the accumulated loss for every batch element is increased by the current loss value \n        # - when picking a batch element, the accumulated loss is reset to zero\n        # - this promotes selecting elements with larger losses more often, but also prevents starving of elements with small losses\n        scheduler = LossAccumulationScheduler(neuralFMU, batch, lossFct; applyStep=1, plotStep=0, updateStep=1)\n    else \n        @error \"Unknown SCHEDULER: ´$(SCHEDULER)´.\"\n        return nothing\n    end\n\n    # loss for training, do a simulation run on a batch element taken from the scheduler\n    loss = p -> FMIFlux.Losses.loss(neuralFMU,                          # the NeuralFMU to simulate\n                                    batch;                              # the batch to take an element from\n                                    p=p,                                # the NeuralFMU training parameters (given as input)\n                                    parameters=data.params,             # the FMU paraemters\n                                    lossFct=lossFct,                    # our custom loss function\n                                    batchIndex=scheduler.elementIndex,  # the index of the batch element to take, determined by the choosen scheduler\n                                    logLoss=true,                       # log losses after every evaluation\n                                    showProgress=showProgress,          # show progress bar (or don't)\n                                    solverKwargsTrain...)               # the solver kwargs defined above\n\n    # gather the parameters from the NeuralFMU\n    params = FMIFlux.params(neuralFMU)\n\n    # initialize the scheduler, keywords are passed to the NeuralFMU\n    initialize!(scheduler; parameters=data.params, p=params[1], showProgress=showProgress)\n    \n    # initialize Adam optimizer with our hyperparameters\n    optim = Adam(ETA, (BETA1, BETA2))\n   \n    # the actual training\n    FMIFlux.train!(loss,                            # the loss function for training\n                   neuralFMU,                          # the parameters to train\n                   Iterators.repeated((), steps),   # an iterator repeating `steps` times\n                   optim;                           # the optimizer to train\n                   gradient=:ForwardDiff,           # currently, only ForwarDiff leads to good results for multi-event systems\n                   chunk_size=32,                   # ForwardDiff chunk_size (=number of parameter estimations per run)\n                   cb=() -> update!(scheduler),     # update the scheduler after every step \n                   proceed_on_assert=true)          # proceed, even if assertions are thrown, with the next step\n    \n    # the default execution mode\n    fmiSingleInstanceMode(fmu, false)\n\n    # save our result parameters\n    fmiSaveParameters(neuralFMU, joinpath(@__DIR__, \"params\", \"$(ind).jld2\"))\n    \n    # simulate the NeuralFMU on a validation trajectory\n    resultNFMU = neuralFMU(x0, (data_validation.consumption_t[1], data_validation.consumption_t[end]); parameters=data_validation.params, showProgress=showProgress, maxiters=1e7, saveat=data_validation.consumption_t)\n\n    # determine loss on validation data (if the simulation was successfull)\n    validation_loss = nothing \n    if resultNFMU.success\n        # compute the loss on VALIDATION data \n        validation_loss = _lossFct(resultNFMU,      # the NeuralFMU\n                                  data_validation,  # the validation data set \n                                  :MSE)             # use MSE \n    end        \n\n    # unload FMU\n    fmiUnload(fmu)\n\n    # return the loss (or `nothing` if no loss can be determined)\n    return validation_loss\nend","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"train! (generic function with 1 method)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Let's check if the train function is working for a given set of hyperparameters.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# check if the train function is working for a set of given (random) hyperparameters\n#     ([  ETA, BETA1,  BETA2, BATCHDUR, LASTWEIGHT, SCHEDULER, LOSS], RESSOURCE, INDEX)\ntrain!([0.0001,  0.9,  0.999,      4.0,        0.7,   :Random, :MSE],      8.0,     1) ","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m--------------\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39mStarting run 1 with parameters: Any[0.0001, 0.9, 0.999, 4.0, 0.7, :Random, :MSE] and ressource 8.0 doing 2 step(s).\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m--------------------\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCurrent step: 0 | Current element=0 | Next element=92\n\n\n\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mTraining asserted, but continuing: AssertionError(\"Determined gradient containes only zeros.\\nThis might be because the loss function is:\\n(a) not sensitive regarding the model parameters or\\n(b) sensitivities regarding the model parameters are not traceable via AD.\")\n\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ FMIFlux D:\\a\\FMIFlux.jl\\FMIFlux.jl\\src\\neural.jl:1665\u001b[39m\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCurrent step: 1 | Current element=92 | Next element=55\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAVG: 0.0 | MAX: 0.0 | SUM: 0.0\n\n\n\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mTraining asserted, but continuing: AssertionError(\"Determined gradient containes only zeros.\\nThis might be because the loss function is:\\n(a) not sensitive regarding the model parameters or\\n(b) sensitivities regarding the model parameters are not traceable via AD.\")\n\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ FMIFlux D:\\a\\FMIFlux.jl\\FMIFlux.jl\\src\\neural.jl:1665\u001b[39m\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mCurrent step: 2 | Current element=55 | Next element=106\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAVG: 0.0 | MAX: 0.0 | SUM: 0.0\n\n\n\n\n\n9.108986582805376e9","category":"page"},{"location":"examples/juliacon_2023/#5.-Results","page":"JuliaCon 2023","title":"5. Results","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"After training with a set of good hyperparameters, results can be loaded (one set is already preparred if you skipped the optimization).","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# load our FMU (we take one from the FMIZoo.jl, exported with Dymola 2020x)\nfmu = fmiLoad(\"VLDM\", \"Dymola\", \"2020x\"; type=:ME)\n\n# build NeuralFMU\nneuralFMU = build_NFMU(fmu)\n\n# load parameters from hyperparameter optimization\nfmiLoadParameters(neuralFMU, joinpath(@__DIR__, \"juliacon_2023.jld2\"))\n\n# simulate and plot the NeuralFMU\nresultNFMU =   neuralFMU(x0,  (tStart, tStop); parameters=data.params, showProgress=showProgress, saveat=tSave) \nresultFMU  = fmiSimulate(fmu, (tStart, tStop); parameters=data.params, showProgress=showProgress, saveat=tSave) \n\n# plot the NeuralFMU, original FMU and data (cumulative consumption)\nfig = plot(resultNFMU; stateIndices=6:6, stateEvents=false, timeEvents=false, label=\"NeuralFMU\", ylabel=\"cumulative consumption [m/s]\")\nplot!(fig, resultFMU; stateIndices=6:6, values=false, stateEvents=false, timeEvents=false, label=\"FMU\")\nplot!(fig, data.cumconsumption_t, data.cumconsumption_val, label=\"Data\")","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"We also have a ready-to-use function that calculates different errors and plots them.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"plotCumulativeConsumption(resultNFMU, resultFMU, data; filename=joinpath(@__DIR__, \"comparision_train_100.png\"))","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Because the deviation is small, let's check the last 10% of WLTC focussed, so from 90% to 100%.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"plotCumulativeConsumption(resultNFMU, resultFMU, data; range=(0.9, 1.0), filename=joinpath(@__DIR__, \"comparision_train_10.png\"))","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Finally, we should check the results on validation data: The full WLTC cycle.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# get start and stop for the validation cycle (full WLTC)\ntStart_validation = data_validation.cumconsumption_t[1]\ntStop_validation = data_validation.cumconsumption_t[end]\ntSave_validation = data_validation.cumconsumption_t\n\n# simulate the NeuralFMU on validation data\nresultNFMU =   neuralFMU(x0,  (tStart_validation, tStop_validation); parameters=data_validation.params, showProgress=showProgress, saveat=tSave_validation) \nresultFMU  = fmiSimulate(fmu, (tStart_validation, tStop_validation); parameters=data_validation.params, showProgress=showProgress, saveat=tSave_validation) \n\nplotCumulativeConsumption(resultNFMU, resultFMU, data_validation; filename=joinpath(@__DIR__, \"comparision_validation_100.png\"))","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"... and the last 10% ...","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"plotCumulativeConsumption(resultNFMU, resultFMU, data_validation; range=(0.9, 1.0), filename=joinpath(@__DIR__, \"comparision_validation_10.png\"))","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: svg)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Check out the error values in the legend: This is an enhancement of factor x326 on MSE, x22 on MAE and x11 on MAX error, wow!","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"Finally some plotting \"sugar\": A plot showing for which locations in derivative-space the model enhanced the cumulative consumption prediction the most:","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"plotEnhancements(neuralFMU, fmu, data; filename=joinpath(@__DIR__, \"gif_1.gif\"))","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSaved animation to D:\\a\\FMIFlux.jl\\FMIFlux.jl\\examples\\jupyter-src\\gif_1.gif","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"(Image: gif)","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"After we finished, let's finally unload the FMU and invalidate the NeuralFMU.","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# unload FMU / invalidate NeuralFMU\nfmiUnload(fmu)\nneuralFMU = nothing","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"But: We did look on some results, but did not talk about where the used hyperparameters came from ...","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"They come from hyperparameter optimization - and this step is necessary for NeuralODEs too! ","category":"page"},{"location":"examples/juliacon_2023/#Optional:-Organize-as-module","page":"JuliaCon 2023","title":"Optional: Organize as module","text":"","category":"section"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"If you want, you can place all code inside of a module named NODE_Training, this simplifies hyper parameter optimization (if you want to do one).","category":"page"},{"location":"examples/juliacon_2023/","page":"JuliaCon 2023","title":"JuliaCon 2023","text":"# for hyper parameter optimization, place the code in a `module`\n# uncomment the following three lines and place them at the very beginning\n \n#module NODE_Training \n#using DistributedHyperOpt\n#using DistributedHyperOpt.Distributed \n\n# ... and uncomment the following line\n#end # NODE_Training ","category":"page"},{"location":"library/#library","page":"Library Functions","title":"Library Functions","text":"","category":"section"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"","category":"page"},{"location":"library/#FMIFlux-functions","page":"Library Functions","title":"FMIFlux functions","text":"","category":"section"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"CS_NeuralFMU\nME_NeuralFMU\nNeuralFMU","category":"page"},{"location":"library/#FMIFlux.CS_NeuralFMU","page":"Library Functions","title":"FMIFlux.CS_NeuralFMU","text":"Structure definition for a NeuralFMU, that runs in mode Co-Simulation (CS).\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.ME_NeuralFMU","page":"Library Functions","title":"FMIFlux.ME_NeuralFMU","text":"Structure definition for a NeuralFMU, that runs in mode Model Exchange (ME).\n\n\n\n\n\n","category":"type"},{"location":"library/#FMIFlux.NeuralFMU","page":"Library Functions","title":"FMIFlux.NeuralFMU","text":"The mutable struct representing an abstract (simulation mode unknown) NeuralFMU.\n\n\n\n\n\n","category":"type"},{"location":"library/#FMI-2-version-dependent-functions","page":"Library Functions","title":"FMI 2 version dependent functions","text":"","category":"section"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"fmi2DoStepCS\nfmi2EvaluateME\nfmi2InputDoStepCSOutput","category":"page"},{"location":"library/#FMIFlux.fmi2EvaluateME","page":"Library Functions","title":"FMIFlux.fmi2EvaluateME","text":"DEPRECATED:\n\nPerforms something similar to fmiDoStep for ME-FMUs (note, that fmiDoStep is for CS-FMUs only). Event handling (state- and time-events) is supported. If you don't want events to be handled, you can disable event-handling for the NeuralFMU nfmu with the attribute eventHandling = false.\n\nOptional, additional FMU-values can be set via keyword arguments setValueReferences and setValues. Optional, additional FMU-values can be retrieved by keyword argument getValueReferences.\n\nFunction takes the current system state array (\"x\") and returns an array with state derivatives (\"x dot\") and optionally the FMU-values for getValueReferences. Setting the FMU time via argument t is optional, if not set, the current time of the ODE solver around the NeuralFMU is used.\n\n\n\n\n\n","category":"function"},{"location":"library/#FMIFlux.fmi2InputDoStepCSOutput","page":"Library Functions","title":"FMIFlux.fmi2InputDoStepCSOutput","text":"DEPRECATED:\n\nfmi2InputDoStepCSOutput(comp::FMU2Component, \n                        dt::Real, \n                        u::Array{<:Real})\n\nSets all FMU inputs to u, performs a ´´´fmi2DoStep´´´ and returns all FMU outputs.\n\n\n\n\n\n","category":"function"},{"location":"library/#FMI-version-independent-functions","page":"Library Functions","title":"FMI version independent functions","text":"","category":"section"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"fmiDoStepCS\nfmiEvaluateME\nfmiInputDoStepCSOutput","category":"page"},{"location":"library/#FMIFlux.fmiDoStepCS","page":"Library Functions","title":"FMIFlux.fmiDoStepCS","text":"DEPRECATED:\n\nWrapper. Call fmi2DoStepCS for more information.\n\n\n\n\n\n","category":"function"},{"location":"library/#FMIFlux.fmiEvaluateME","page":"Library Functions","title":"FMIFlux.fmiEvaluateME","text":"DEPRECATED:\n\nWrapper. Call fmi2EvaluateME for more information.\n\n\n\n\n\n","category":"function"},{"location":"library/#FMIFlux.fmiInputDoStepCSOutput","page":"Library Functions","title":"FMIFlux.fmiInputDoStepCSOutput","text":"DEPRECATED:\n\nWrapper. Call fmi2InputDoStepCSOutput for more information.\n\n\n\n\n\n","category":"function"},{"location":"library/#Additional-functions","page":"Library Functions","title":"Additional functions","text":"","category":"section"},{"location":"library/","page":"Library Functions","title":"Library Functions","text":"mse_interpolate\ntransferParams!","category":"page"},{"location":"library/#FMIFlux.mse_interpolate","page":"Library Functions","title":"FMIFlux.mse_interpolate","text":"Compares non-equidistant (or equidistant) datapoints by linear interpolating and comparing at given interpolation points t_comp.  (Zygote-friendly: Zygote can differentiate through via AD.)\n\n\n\n\n\n","category":"function"},{"location":"related/#Related-Publications","page":"Related Publication","title":"Related Publications","text":"","category":"section"},{"location":"related/","page":"Related Publication","title":"Related Publication","text":"Thummerer T, Kircher J and Mikelsons L: Neural FMU: Towards structual integration of FMUs into neural networks (Preprint, accepted 14th International Modelica Conference) pdf|DOI","category":"page"},{"location":"related/","page":"Related Publication","title":"Related Publication","text":"Thummerer T, Tintenherr J, Mikelsons L: Hybrid modeling of the human cardiovascular system using NeuralFMUs (Preprint, accepted 10th International Conference on Mathematical Modeling in Physical Sciences) pdf|DOI","category":"page"},{"location":"examples/mdpi_2022/#Physics-enhanced-NeuralODEs-in-real-world-applications","page":"MDPI 2022","title":"Physics-enhanced NeuralODEs in real-world applications","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Tutorial by Tobias Thummerer based on the paper NeuralFMU: presenting a workflow for integrating hybrid NeuralODEs into real-world applications","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"📚📚📚 This tutorial is archieved (so keeping it runnable is low priority), for a more up-to-date version see the Workshop for JuliaCon2023 📚📚📚","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"","category":"page"},{"location":"examples/mdpi_2022/#Keywords","page":"MDPI 2022","title":"Keywords","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"PeNODE, NeuralODE, Universal Differential Equation, Hybrid Modeling, Functional Mock-up Unit, FMU, NeuralFMU","category":"page"},{"location":"examples/mdpi_2022/#License","page":"MDPI 2022","title":"License","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons\n# Licensed under the MIT license. \n# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details.","category":"page"},{"location":"examples/mdpi_2022/#Introduction","page":"MDPI 2022","title":"Introduction","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"In this tutorial, a vehicle longitudinal-dynamics model (VLDM) as used in automotive industry, is extended to a NeuralFMU (PeNODE) to make better consumption predictions. You don't know what NeuralFMUs/PeNODEs are? No problem, this will be briefly explained during this tutorial, too.","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"This tutorial is a more easy, code-focussed version of the paper [1], if you find it useful for your work, please cite the linked paper. In this example, a real-world simulation model is enhanced in terms of accuracy using a so called physics-enhanced neural ordinary differential equation (PeNode). Basically, this is an extension to the NeuralODE concept and looks as can be seen in Fig. 1.","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"(Image: NeuralFMU.svg)","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Fig.1: A possible representation for a physics-enhanced neural ordinary differential equation (PeNODE). An ODE model computes the system state derivative dotvecx based on a given system state vecx, inputs vecu and time t. The state derivative dotvecx is manipulated by the ANN into hatdotvecx and finally integrated into the next system state vecx(t+h). PeNODEs that include FMUs instead of symbolic ODEs are called NeuralFMUs.","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Note, that this is only one possible topology of a PeNODE, there could be an additional artifical neural network (ANN) before the ODE (that might share some connections with the other ANN). Further also other signals, like FMU state derivatives, inputs and outputs could be connected to the ANN(s). ODEs are in general not very handy, for modeling real applications, a more suitable container for ODEs is needed. The most common model exchange format in industry is the Functional Mock-up interface (FMI), models exported with FMI are called Functional Mock-up unit (FMU). Especially model-exchange FMUs can be seen as containers for ODEs. For more information, see (fmi-standard.org). So if you want to use a real model from your modeling tool (with FMI support), you can simply export a FMU instead of handling large and bulky ODEs. If PeNODEs use FMUs instead of ODEs, they are called NeuralFMUs [2].","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"If that was a little bit fast, don't worry: This will be explained in detail later on.","category":"page"},{"location":"examples/mdpi_2022/#Formats","page":"MDPI 2022","title":"Formats","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Besides, this Jupyter Notebook there is also a Julia file with the same name, which contains only the code cells. For the documentation there is a Markdown file corresponding to the notebook.  ","category":"page"},{"location":"examples/mdpi_2022/#Installation-prerequisites","page":"MDPI 2022","title":"Installation prerequisites","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":" Description Command\n1. Enter Package Manager via ]\n2. Install FMI via add FMI\n3. Install FMIFlux via add FMIFlux\n4. Install FMIZoo via add FMIZoo\n5. Install Plots via add Plots\n6. Install Random via add Random\n7. Install JLD2 via add JLD2","category":"page"},{"location":"examples/mdpi_2022/#Part-1:-Loading-the-FMU","page":"MDPI 2022","title":"Part 1: Loading the FMU","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"To run the example, the previously installed packages must be included. ","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# Loading in the required libraries\nusing FMIFlux       # for NeuralFMUs\nusing FMI           # import FMUs into Julia \nusing FMIZoo        # a collection of demo models, including the VLDM\nusing FMIFlux.Flux  # Machine Learning in Julia\n\nimport FMI.DifferentialEquations: Tsit5     # import the Tsit5-solver\nimport FMI: FMU2Solution\nusing JLD2                                  # data format for saving/loading parameters\n\n# plotting\nimport Plots        # default plotting framework\n\n# for interactive plotting\n# import PlotlyJS     # plotting (interactive)\n# Plots.plotlyjs()    # actiavte PlotlyJS as default plotting backend\n\n# Let's fix the random seed to make our program determinsitic (ANN layers are initialized indeterminsitic otherwise)\nimport Random \nRandom.seed!(1234)\n\n# we use the Tsit5 solver for ODEs here \nsolver = Tsit5();   ","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Next, we load the FMU from the FMIZoo.jl and have a brief look on its metadata. For a more detailed view, see the Modelica model.","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# load our FMU (we take one from the FMIZoo.jl, exported with Dymola 2022x)\nfmu = fmiLoad(\"VLDM\", \"Dymola\", \"2020x\"; type=:ME, logLevel=FMI.FMIImport.FMULogLevelInfo)  # `FMULogLevelInfo` = \"Log everything that might be interesting!\", default is `FMULogLevelWarn`\n\n# let's have a look on the model meta data\nfmiInfo(fmu)","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"As you can see, in section States there are six states listed:","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"ID Value Reference Value Name(s) Description\n1 33554432 \"driver.accelerationPedalController.PI.x\" PI-Controller state (integrated error), accelerating\n2 33554433 \"driver.brakePedalController.PI.x\" PI-Controller state (integrated error), braking\n3 33554434 \"drivingCycle.s\" vehicle position (target)\n4 33554435 \"dynamics.accelerationCalculation.integrator.y\" vehicle position (actual)\n5 33554436 \"dynamics.accelerationCalculation.limiter.u\", \"dynamics.accelerationCalculation.limIntegrator.y\" vehicle velocity (actual)\n6 33554437 \"result.integrator.y\" cumulative consumption * 3600","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Next thing is having a look on the real measurement data, that comes with the FMU. The VLDM and corresponding data are based on the Component Library for Full Vehicle Simulations [3].","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# load data from FMIZoo.jl, gather simulation parameters for FMU\ndata = FMIZoo.VLDM(:train)\ntStart = data.cumconsumption_t[1]\ntStop = data.cumconsumption_t[end]\ntSave = data.cumconsumption_t\n\n# have a look on the FMU parameters (these are the file paths to the characteristic maps)\ndata.params","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Finally, we do a single simulation run and compare the simulation output to the real data.","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# let's run a simulation from `tStart` to `tStop`, use the parameters we just viewed for the simulation run\nresultFMU = fmiSimulate(fmu, (tStart, tStop); parameters=data.params) \nfig = fmiPlot(resultFMU)                                                                        # Plot it, but this is a bit too much, so ...\nfig = fmiPlot(resultFMU; stateIndices=6:6)                                                      # ... only plot the state #6 and ...\nfig = fmiPlot(resultFMU; stateIndices=6:6, ylabel=\"Cumulative consumption [Ws]\", label=\"FMU\")   # ... add some helpful labels!\n\n# further plot the (measurement) data values `consumption_val` and deviation between measurements `consumption_dev`\nPlots.plot!(fig, data.cumconsumption_t, data.cumconsumption_val; label=\"Data\", ribbon=data.cumconsumption_dev, fillalpha=0.3)","category":"page"},{"location":"examples/mdpi_2022/#Part-2:-Designing-the-Topology","page":"MDPI 2022","title":"Part 2: Designing the Topology","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"After we have successful loaded the FMU, had a look inside its model description and simulated it, we want to build a hybrid model (NeuralFMU) with our FMU as its core. ","category":"page"},{"location":"examples/mdpi_2022/#Part-2a:-Interfaces-between-ANNs-and-FMUs","page":"MDPI 2022","title":"Part 2a: Interfaces between ANNs and FMUs","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"What happens between ANNs and FMUs?","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Note, that FMUs and ANNs don't operate within the same numerical ranges. Whereas FMU signals can basically use the entire range of a Float64, ANNs operate the best in a range that suits theire activation functions. Many activation functions saturate their input values. Consider the tanh-activation, that acts almost linear close around 0, but drastically saturates values further away from zero:","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"for i in [0.0, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n    println(\"tanh($(i)) = $(tanh(i))\")\nend","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Similarly for the opposite direction: Signals from ANNs into FMUs may be too small, because of the limited output of the ANNs (or better: their activation functions). To prevent this issue, an appropriate transformation (like shifting and scaling) between ANNs and FMUs is necessary. In the following code section, the results of ignoring this is shown, together with a fix by using the provided ScaleShift- and ShiftScale-layers from FMIFlux.jl.","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# variable we want to manipulate - why we are picking exactly these three is shown a few lines later ;-)\nmanipulatedDerVars = [\"der(dynamics.accelerationCalculation.integrator.y)\",\n                      \"der(dynamics.accelerationCalculation.limIntegrator.y)\",\n                      \"der(result.integrator.y)\"]\n# alternative: manipulatedDerVars = fmu.modelDescription.derivativeValueReferences[4:6]\n\n# reference simulation to record the derivatives \nresultFMU = fmiSimulate(fmu, (tStart, tStop), parameters=data.params, recordValues=:derivatives, saveat=tSave) \nvals = fmiGetSolutionValue(resultFMU, manipulatedDerVars)\n\n# what happens without propper transformation between FMU- and ANN-domain?\nPlots.plot(resultFMU.values.t, vals[1,:][1]; label=\"vehicle velocity\");\nPlots.plot!(resultFMU.values.t, tanh.(vals[1,:][1]); label=\"tanh(velocity)\")\n\n# setup shift/scale layers for pre-processing\npreProcess = ShiftScale(vals)\n\n# check what it's doing now ...\ntestVals = collect(preProcess(collect(val[t] for val in vals))[1] for t in 1:length(resultFMU.values.t))\nPlots.plot(resultFMU.values.t, testVals; label=\"velocity (pre-processed)\");\nPlots.plot!(resultFMU.values.t, tanh.(testVals); label=\"tanh(velocity)\")","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# add some additional \"buffer\"\npreProcess.scale[:] *= 0.5 \n\n# and check again what it's doing now ...\ntestVals = collect(preProcess(collect(val[t] for val in vals))[1] for t in 1:length(resultFMU.values.t))\nPlots.plot(resultFMU.values.t, testVals; label=\"velocity (pre-processed)\");\nPlots.plot!(resultFMU.values.t, tanh.(testVals); label=\"tanh(velocity)\")","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# ... also check the consumption\ntestVals = collect(preProcess(collect(val[t] for val in vals))[3] for t in 1:length(resultFMU.values.t))\nPlots.plot(resultFMU.values.t, testVals; label=\"vehicle consumption (pre-processed)\");\nPlots.plot!(resultFMU.values.t, tanh.(testVals); label=\"tanh(consumption)\")","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# setup scale/shift layer (inverse transformation) for post-processing\n# we don't an inverse transform for the entire preProcess, only for the 2nd element (acceleration)\npostProcess = ScaleShift(preProcess; indices=2:2)","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"As a little extra, these shifting and scaling parameters are optimized together with the ANN parameters in the later training process!","category":"page"},{"location":"examples/mdpi_2022/#Part-2b:-ANN-in-and-output","page":"MDPI 2022","title":"Part 2b: ANN in- and output","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Besides shifting and scaling, a major question is: What signals should be fed into the ANN and what signals should be output by it? We need to make some considerations:","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"What should be learned? In theory, we could manipulate every interface signal from and to the FMU, but in real life this is not efficient. The more signals we connect, the more partial derivatives need to be determined during training. So if there is something you know about the model (and often there is more than just something) you can use that knowledge to make your hybrid model more efficient. So ask yourself: What should be learned? And right after that: How could it be learned? In mechanical applications the answer will often be: A force (or momentum in rotational systems). Forces result in a change of acceleration, so they can be expressed by an additional acceleration. In mechanical systems, the acceleration is almost always a state derivative (the derivative of the velocity), so in many cases, manipulating the most differentiated state derivative - the acceleration - is a very good choice. \nHow many ANNs do we need? Technically, you can add an arbitrary number of ANNs around your FMU (you can also use multiple FMUs if you want). But again, one should not use more than a single ANN if there is no good reason to do so. A second ANN before the FMU can be useful for example, if measurment offsets or similar effects should be corrected. Often, a single ANN to modify the state dynamics is sufficient.\nWhat signals from the FMU should be inserted into the ANN? In theory, we could use them all, meaning all states, state derivatives, time, inputs, outputs and other variables that are accessible through FMI. You know what comes next: Using less signals is the better choice, of course. If you know that the physical effect (here: the friction force), you have also an idea of what influences this effect or at least you know what values will have no impact and can be neglected to enhance training performance.","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"At this specific example, the following considerations were made:","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":" Consideration Considered inputs for the ANN\n1. we have no system inputs, so vecu=, nothing to add \n2. we have no system outputs, so vecy=, nothing to add \n3. we know that the effect is not explicitly time-dependent on t, nothing to add \n4. we have six states, that may influence the effect, add them x_1 x_2 x_3 x_4 x_5 x_6\n5. we have six state derivatives, that may influence the effect, add them x_1 x_2 x_3 x_4 x_5 x_6 dotx_1 dotx_2 dotx_3 dotx_4 dotx_5 dotx_6\n6. the system is modelled as second order ODE, the state x_5 (velocity) equlas the state derivative dotx_4, remove x_5 x_1 x_2 x_3 x_4 x_6 dotx_1 dotx_2 dotx_3 dotx_4 dotx_5 dotx_6\n7. we know that the friction effect is not dependent on the driver controller, remove two states (x_1 and x_2) and state derivatives (dotx_1 and dotx_2) x_3 x_4 x_6 dotx_3 dotx_4 dotx_5 dotx_6\n8. we know that the friction effect is not dependent on the target driving cycle position x_3 or velocity dotx_3, remove them x_4 x_6 dotx_4 dotx_5 dotx_6\n9. we assume that the friction effect is not dependent on the vehicle position x_4, remove x_4 x_6 dotx_4 dotx_5 dotx_6\n10. we assume that the friction effect is not dependent on the accumulated vehicle consumption x_6, remove x_6 dotx_4 dotx_5 dotx_6","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"These considerations lead to the following topology:","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"(Image: usedneuralfmu.svg)","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Fig.2: The used topology for a NeuralFMU in this example. The ANN operates based on the signals dotx_4 dotx_5 dotx_6 from the FMU, but only modifies the signal hatdotx_5. The gates p_FMU and p_ANN control how much the dynamics of FMU and ANN contribute to the NeuralFMU dynamics. Starting with p_FMU=10 and p_ANN=00 makes an initialization routine obsolete, because the dynamics of the NeuralFMU equal the dynamics of the FMU, see [1] for further details.","category":"page"},{"location":"examples/mdpi_2022/#Part-2c:-Translating-topology-to-Julia","page":"MDPI 2022","title":"Part 2c: Translating topology to Julia","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"To implement the signal bypass in a layer sequence, two layers named CacheLayer and CacheRetrieveLayer are used to cache and retrieve arbitrary values:","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# setup cache layers \ncache = CacheLayer()\ncacheRetrieve = CacheRetrieveLayer(cache)\n\ngates = ScaleSum([1.0, 0.0]) # signal from FMU (#1 = 1.0), signal from ANN (#2 = 0.0)\n\n# setup the NeuralFMU topology\nnet = Chain(x -> fmu(; x=x, dx_refs=:all),      # take `x`, put it into the FMU, retrieve all `dx`\n            dx -> cache(dx),                    # cache `dx`\n            dx -> dx[4:6],                      # forward only dx[4, 5, 6]\n            preProcess,                         # pre-process `dx`\n            Dense(3, 32, tanh),                 # Dense Layer 3 -> 32 with `tanh` activasion\n            Dense(32, 1, tanh),                 # Dense Layer 32 -> 1 with `tanh` activasion \n            postProcess,                        # post process `dx`\n            dx -> cacheRetrieve(5:5, dx),       # dynamics FMU | dynamics ANN\n            gates,                              # compute resulting dx from ANN + FMU\n            dx -> cacheRetrieve(1:4, dx, 6:6))  # stack together: dx[1,2,3,4] from cache + dx from ANN + dx[6] from cache\n\n# build NeuralFMU\nneuralFMU = ME_NeuralFMU(fmu, net, (tStart, tStop), solver; saveat=tSave)\nneuralFMU.modifiedState = false # speed optimization (no ANN before the FMU)\n\n# get start state vector from data (FMIZoo)\nx0 = FMIZoo.getStateVector(data, tStart)\n\n# simulate and plot the (uninitialized) NeuralFMU\nresultNFMU_original = neuralFMU(x0, (tStart, tStop); parameters=data.params, showProgress=true) \nfig = fmiPlot(resultNFMU_original; stateIndices=5:5, label=\"NeuralFMU (original)\", ylabel=\"velocity [m/s]\")\n\n# plot the original FMU and data\nfmiPlot!(fig, resultFMU; stateIndices=5:5, values=false)\nPlots.plot!(fig, data.speed_t, data.speed_val, label=\"Data\")","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"As to expect, all trajectories overlap.","category":"page"},{"location":"examples/mdpi_2022/#Part-2d:-Initialization","page":"MDPI 2022","title":"Part 2d: Initialization","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"In general, initialization of (phyiscs-enhanced) NeuralODEs is challenging, because ANNs are initialized random by default. In this case we are using a special initialization method introducing two gates, that control how much of the original FMU dynamics and how much of the ANN dynamics is introduced to the final model dynamics. See the paper [1] for a deeper insight.","category":"page"},{"location":"examples/mdpi_2022/#Part-3:-Training","page":"MDPI 2022","title":"Part 3: Training","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Finally: The actual training!","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Basically, you can use your custom loss function, batching strategies and optimsation routines with FMIFlux.jl. Because we need to keep it short here, we use some tools already shipped with FMIFlux.jl.","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# prepare training data (array of arrays required)\ntrain_data = collect([d] for d in data.cumconsumption_val)\ntrain_t = data.cumconsumption_t \n\n# switch to a more efficient execution configuration, allocate only a single FMU instance, see:\n# https://thummeto.github.io/FMI.jl/dev/features/#Execution-Configuration\nfmu.executionConfig = FMI.FMIImport.FMU2_EXECUTION_CONFIGURATION_NOTHING\nc, _ = FMIFlux.prepareSolveFMU(neuralFMU.fmu, nothing, neuralFMU.fmu.type, true, false, false, false, true, data.params; x0=x0)\n\n# batch the data (time, targets), train only on model output index 6, plot batch elements\nbatch = batchDataSolution(neuralFMU, t -> FMIZoo.getStateVector(data, t), train_t, train_data;\n    batchDuration=10.0, indicesModel=6:6, plot=false, parameters=data.params, showProgress=false) # try `plot=true` to show the batch elements, try `showProgress=true` to display simulation progress\n\n# limit the maximum number of solver steps to 1e5 and maximum simulation/training duration to 30 minutes\nsolverKwargsTrain = Dict{Symbol, Any}(:maxiters => 1e5, :max_execution_duration => 10.0*60.0)\n\n# picks a modified MSE, which weights the last time point MSE with 25% and the remaining element MSE with 75%\n# this promotes training a continuous function, even when training on batch elements\nfunction lossFct(solution::FMU2Solution)\n    ts = dataIndexForTime(solution.states.t[1])\n    te = dataIndexForTime(solution.states.t[end])\n\n    a = fmiGetSolutionState(solution, 6; isIndex=true)\n    b = train_data[ts:te]\n    return FMIFlux.Losses.mse_last_element_rel(a, b, 0.5)\nend\n\n# initialize a \"worst error growth scheduler\" (updates all batch losses, pick the batch element with largest error increase)\n# apply the scheduler after every training step, plot the current status every 25 steps and update all batch element losses every 5 steps\nscheduler = LossAccumulationScheduler(neuralFMU, batch, lossFct; applyStep=1, plotStep=25, updateStep=5)\nupdateScheduler = () -> update!(scheduler)\n\n# defines a loss for the entire batch (accumulate error of batch elements)\nbatch_loss = p -> FMIFlux.Losses.batch_loss(neuralFMU, batch; \n    showProgress=false, p=p, parameters=data.params, update=true, lossFct=lossFct, logLoss=true, solverKwargsTrain...) # try `showProgress=true` to display simulation progress\n\n# loss for training, take element from the worst element scheduler\nloss = p -> FMIFlux.Losses.loss(neuralFMU, batch; \n    showProgress=false, p=p, parameters=data.params, lossFct=lossFct, batchIndex=scheduler.elementIndex, logLoss=false, solverKwargsTrain...) # try `showProgress=true` to display simulation progress\n\n# we start with a slightly opended ANN gate (1%) and a almost completely opened FMU gate (99%)\ngates.scale[:] = [0.99, 0.01] \n\n# gather the parameters from the NeuralFMU\nparams = FMIFlux.params(neuralFMU)\n\nparams[1][end-1] = 0.99\nparams[1][end] = 0.01\n\n# for training, we use the Adam optimizer with step size 1e-3\noptim = Adam(1e-3) \n\n# let's check the loss we are starting with ...\nloss_before = batch_loss(params[1])\n\n# initialize the scheduler \ninitialize!(scheduler; parameters=data.params, p=params[1], showProgress=false)","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"Finally, the lines we are waiting for so long:","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"batchLen = length(batch)\n\n# we use ForwardDiff for gradinet determination, because the FMU throws multiple events per time instant (this is not supported by reverse mode AD)\n# the chunk_size controls the nuber of forward evaluations of the model (the bigger, the less evaluations)\nFMIFlux.train!(loss, neuralFMU, Iterators.repeated((), batchLen), optim; gradient=:ForwardDiff, chunk_size=32, cb=updateScheduler) \nloss_after = batch_loss(params[1])","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"The batch loss (\"AVG\" and \"MAX\") is only updated every 5 steps, as defined in the scheduler. Every 25 steps, we plot the current batch element losses. Please note, that we only did around 100 training steps, so training has not converged for now. But we are curious and want to have a look on the intermediate results. ","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"After training, it seems a good idea to store the optimized parameters for later use:","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# save the parameters (so we can use them tomorrow again)\nparamsPath = joinpath(@__DIR__, \"params_$(scheduler.step)steps.jld2\")\nfmiSaveParameters(neuralFMU, paramsPath)\n\n# switch back to the default execution configuration, see:\n# https://thummeto.github.io/FMI.jl/dev/features/#Execution-Configuration\nfmu.executionConfig = FMI.FMIImport.FMU2_EXECUTION_CONFIGURATION_NO_RESET\nFMIFlux.finishSolveFMU(neuralFMU.fmu, c, false, true)","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"The loss has decreased, but the final question is: Are we better? This can be easily checked by running a simulation and compare it to the training data:","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# check what had been learned by the NeuralFMU, simulate it ...\nresultNFMU_train = neuralFMU(x0, (tStart, tStop); parameters=data.params, showProgress=true, recordValues=manipulatedDerVars, maxiters=1e7) # [120s]\n\n# Load parameters \nfmiLoadParameters(neuralFMU, paramsPath)\n\n# are we better?\nmse_NFMU = FMIFlux.Losses.mse(data.cumconsumption_val, fmiGetSolutionState(resultNFMU_train, 6; isIndex=true))\nmse_FMU  = FMIFlux.Losses.mse(data.cumconsumption_val, fmiGetSolutionState(resultFMU, 6; isIndex=true))\n\n# ... and plot it\nfig = fmiPlot(resultNFMU_train; stateIndices=6:6, values=false, stateEvents=false, label=\"NeuralFMU\", title=\"Training Data\");\nfmiPlot!(fig, resultFMU; stateIndices=6:6, stateEvents=false, values=false, label=\"FMU\");\nPlots.plot!(fig, train_t, data.cumconsumption_val, label=\"Data\", ribbon=data.cumconsumption_dev, fillalpha=0.3)","category":"page"},{"location":"examples/mdpi_2022/#Part-4:-Results-discussion","page":"MDPI 2022","title":"Part 4: Results discussion","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"WIP: coming soon!","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"# clean-up\nfmiUnload(fmu) ","category":"page"},{"location":"examples/mdpi_2022/#Source","page":"MDPI 2022","title":"Source","text":"","category":"section"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"[1] Tobias Thummerer, Johannes Stoljar and Lars Mikelsons. 2022. NeuralFMU: presenting a workflow for integrating hybrid NeuralODEs into real-world applications. Electronics 11, 19, 3202. DOI: 10.3390/electronics11193202","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"[2] Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. NeuralFMU: towards structural integration of FMUs into neural networks. Martin Sjölund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, Linköping, Sweden, September 20-24, 2021. Linköping University Electronic Press, Linköping (Linköping Electronic Conference Proceedings ; 181), 297-306. DOI: 10.3384/ecp21181297","category":"page"},{"location":"examples/mdpi_2022/","page":"MDPI 2022","title":"MDPI 2022","text":"[3] Danquah, B.; Koch, A.; Weis, T.; Lienkamp, M.; Pinnel, A. 2019. Modular, Open Source Simulation Approach: Application to Design and Analyze Electric Vehicles. In Proceedings of the IEEE 2019 Fourteenth International Conference on Ecological Vehicles and Renewable Energies (EVER), Monte Carlo, Monaco, 8–10 May 2019; pp. 1–8. DOI: 10.1109/EVER.2019.8813568.","category":"page"},{"location":"examples/overview/#Examples-Overview","page":"Overview","title":"Examples - Overview","text":"","category":"section"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"This section discusses the included examples of the FMIFlux.jl library. You can execute them on your machine and get detailed information about all of the steps.  If you require further information about the function calls, see library functions section.  For more information related to the setup and simulation of an FMU see FMI.jl library.","category":"page"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"The examples are intended for users who work in the field of first principle and/or data driven modeling and are further interested in hybrid model building.  The examples show how to combine FMUs with machine learning (\"NeuralFMU\") and illustrates the advantages of this approach.","category":"page"},{"location":"examples/overview/#Examples","page":"Overview","title":"Examples","text":"","category":"section"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"Simple CS-NeuralFMU: Showing how to train a NeuralFMU in Co-Simulation-Mode.\nSimple ME-NeuralFMU: Showing how to train a NeuralFMU in Model-Exchange-Mode.\nGrowing Horizon ME-NeuralFMU: Growing horizon training technique for a ME-NeuralFMU.","category":"page"},{"location":"examples/overview/#Advanced-examples:-Demo-applications","page":"Overview","title":"Advanced examples: Demo applications","text":"","category":"section"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"JuliaCon 2023: Using NeuralODEs in real life applications: An example for a NeuralODE in a real world engineering scenario.\nModelica Conference 2021: NeuralFMUs: Showing basics on how to train a NeuralFMU (Contribution for the Modelica Conference 2021).","category":"page"},{"location":"examples/overview/#Archived","page":"Overview","title":"Archived","text":"","category":"section"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"MDPI 2022: Physics-enhanced NeuralODEs in real-world applications: An example for a NeuralODE in a real world modeling scenario (Contribution in MDPI Electronics 2022).","category":"page"},{"location":"examples/overview/#Workshops","page":"Overview","title":"Workshops","text":"","category":"section"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"Pluto based notebooks, that can easyly be executed on your own Pluto-Setup.","category":"page"},{"location":"examples/overview/","page":"Overview","title":"Overview","text":"HybridModelingUsingFMI: Workshop at MODPROD 2024 (Linköping University, Sweden)","category":"page"},{"location":"examples/simple_hybrid_ME/#Creation-and-training-of-ME-NeuralFMUs","page":"Simple ME-NeuralFMU","title":"Creation and training of ME-NeuralFMUs","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Tutorial by Johannes Stoljar, Tobias Thummerer","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Last edit: 15.11.2023","category":"page"},{"location":"examples/simple_hybrid_ME/#License","page":"Simple ME-NeuralFMU","title":"License","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons, Johannes Stoljar\n# Licensed under the MIT license. \n# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details.","category":"page"},{"location":"examples/simple_hybrid_ME/#Motivation","page":"Simple ME-NeuralFMU","title":"Motivation","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The Julia Package FMIFlux.jl is motivated by the application of hybrid modeling. This package enables the user to integrate his simulation model between neural networks (NeuralFMU). For this, the simulation model must be exported as FMU (functional mock-up unit), which corresponds to a widely used standard. The big advantage of hybrid modeling with artificial neural networks is, that effects that are difficult to model (because they might be unknown) can be easily learned by the neural networks. For this purpose, the NeuralFMU is trained with measurement data containing the not modeled physical effect. The final product is a simulation model including the originally not modeled effects. Another big advantage of the NeuralFMU is that it works with little data, because the FMU already contains the characteristic functionality of the simulation and only the missing effects are added.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"NeuralFMUs do not need to be as easy as in this example. Basically a NeuralFMU can combine different ANN topologies that manipulate any FMU-input (system state, system inputs, time) and any FMU-output (system state derivative, system outputs, other system variables). However, for this example a NeuralFMU topology as shown in the following picture is used.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: NeuralFMU.svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"NeuralFMU (ME) from [1].","category":"page"},{"location":"examples/simple_hybrid_ME/#Introduction-to-the-example","page":"Simple ME-NeuralFMU","title":"Introduction to the example","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In this example, simplified modeling of a one-dimensional spring pendulum (without friction) is compared to a model of the same system that includes a nonlinear friction model. The FMU with the simplified model will be named simpleFMU in the following and the model with the friction will be named realFMU. At the beginning, the actual state of both simulations is shown, whereby clear deviations can be seen in the graphs. The realFMU serves as a reference graph. The simpleFMU is then integrated into a NeuralFMU architecture and a training of the entire network is performed. After the training the final state is compared again to the realFMU. It can be clearly seen that by using the NeuralFMU, learning of the friction process has taken place.  ","category":"page"},{"location":"examples/simple_hybrid_ME/#Target-group","page":"Simple ME-NeuralFMU","title":"Target group","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The example is primarily intended for users who work in the field of first principle and/or hybrid modeling and are further interested in hybrid model building. The example wants to show how simple it is to combine FMUs with machine learning and to illustrate the advantages of this approach.","category":"page"},{"location":"examples/simple_hybrid_ME/#Other-formats","page":"Simple ME-NeuralFMU","title":"Other formats","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Besides, this Jupyter Notebook there is also a Julia file with the same name, which contains only the code cells and for the documentation there is a Markdown file corresponding to the notebook.  ","category":"page"},{"location":"examples/simple_hybrid_ME/#Getting-started","page":"Simple ME-NeuralFMU","title":"Getting started","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/#Installation-prerequisites","page":"Simple ME-NeuralFMU","title":"Installation prerequisites","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":" Description Command\n1. Enter Package Manager via ]\n2. Install FMI via add FMI\n3. Install FMIFlux via add FMIFlux\n4. Install FMIZoo via add FMIZoo\n5. Install DifferentialEquations via add DifferentialEquations\n6. Install Plots via add Plots\n7. Install Random via add Random","category":"page"},{"location":"examples/simple_hybrid_ME/#Code-section","page":"Simple ME-NeuralFMU","title":"Code section","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"To run the example, the previously installed packages must be included. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# imports\nusing FMI\nusing FMIFlux\nusing FMIFlux.Flux\nusing FMIZoo\nusing DifferentialEquations: Tsit5\nimport Plots\n\n# set seed\nimport Random\nRandom.seed!(42);","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mError requiring `Enzyme` from `LinearSolve`\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  exception =\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   LoadError: ArgumentError: Package LinearSolve does not have Enzyme in its dependencies:\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - You may have a partially installed environment. Try `Pkg.instantiate()`\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     to ensure all packages in the environment are installed.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - Or, if you have LinearSolve checked out for development and have\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     added Enzyme as a dependency but haven't updated your primary\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     environment's manifest file, try `Pkg.resolve()`.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - Otherwise you may need to report an issue with LinearSolve\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   Stacktrace:\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1167\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:223\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [3] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1144\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [4] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:419\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [5] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4mLinearSolve.jl:1\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mRequires.jl:40\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [7] top-level scope\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4minit.jl:16\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [8] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mboot.jl:368\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [9] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4mLinearSolve.jl:1\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [10] \u001b[0m\u001b[1m(::LinearSolve.var\"#88#97\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:101\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [11] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m\u001b[4mtiming.jl:382\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [12] \u001b[0m\u001b[1merr\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mAny, \u001b[90mlistener\u001b[39m::\u001b[0mModule, \u001b[90mmodname\u001b[39m::\u001b[0mString, \u001b[90mfile\u001b[39m::\u001b[0mString, \u001b[90mline\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:47\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [13] \u001b[0m\u001b[1m(::LinearSolve.var\"#87#96\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:100\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [14] \u001b[0m\u001b[1mwithpath\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mAny, \u001b[90mpath\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:37\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [15] \u001b[0m\u001b[1m(::LinearSolve.var\"#86#95\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:99\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [16] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [17] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [18] \u001b[0m\u001b[1mforeach\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mtypeof(Base.invokelatest), \u001b[90mitr\u001b[39m::\u001b[0mVector\u001b[90m{Function}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mabstractarray.jl:2774\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [19] \u001b[0m\u001b[1mloadpkg\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:27\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [20] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [21] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [22] \u001b[0m\u001b[1mrun_package_callbacks\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmodkey\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:869\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [23] \u001b[0m\u001b[1m_tryrequire_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmodkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90msourcepath\u001b[39m::\u001b[0mString, \u001b[90mdepmods\u001b[39m::\u001b[0mVector\u001b[90m{Any}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:944\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [24] \u001b[0m\u001b[1m_require_search_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msourcepath\u001b[39m::\u001b[0mString, \u001b[90mbuild_id\u001b[39m::\u001b[0mUInt64\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1028\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [25] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1315\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [26] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1200\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [27] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1180\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [28] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:223\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [29] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1144\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [30] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mboot.jl:368\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [31] \u001b[0m\u001b[1minclude_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmapexpr\u001b[39m::\u001b[0mtypeof(REPL.softscope), \u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1428\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [32] \u001b[0m\u001b[1msoftscope_include_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[32mSoftGlobalScope\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\SoftGlobalScope\\u4UzH\\src\\\u001b[39m\u001b[90m\u001b[4mSoftGlobalScope.jl:65\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [33] \u001b[0m\u001b[1mexecute_request\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket, \u001b[90mmsg\u001b[39m::\u001b[0mIJulia.Msg\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\IJulia\\Vo51o\\src\\\u001b[39m\u001b[90m\u001b[4mexecute_request.jl:67\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [34] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [35] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [36] \u001b[0m\u001b[1meventloop\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\IJulia\\Vo51o\\src\\\u001b[39m\u001b[90m\u001b[4meventloop.jl:8\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [37] \u001b[0m\u001b[1m(::IJulia.var\"#15#18\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mtask.jl:484\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   in expression starting at C:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\ext\\LinearSolveEnzymeExt.jl:1\n\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Requires C:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\require.jl:51\u001b[39m","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"After importing the packages, the path to the Functional Mock-up Units (FMUs) is set. The FMU is a model exported meeting the Functional Mock-up Interface (FMI) Standard. The FMI is a free standard (fmi-standard.org) that defines a container and an interface to exchange dynamic models using a combination of XML files, binaries and C code zipped into a single file. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The object-orientated structure of the SpringPendulum1D (simpleFMU) can be seen in the following graphic and corresponds to a simple modeling.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In contrast, the model SpringFrictionPendulum1D (realFMU) is somewhat more accurate, because it includes a friction component. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Next, the start time and end time of the simulation are set. Finally, a step size is specified to store the results of the simulation at these time steps.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"tStart = 0.0\ntStep = 0.01\ntStop = 5.0\ntSave = collect(tStart:tStep:tStop)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"501-element Vector{Float64}:\n 0.0\n 0.01\n 0.02\n 0.03\n 0.04\n 0.05\n 0.06\n 0.07\n 0.08\n 0.09\n 0.1\n 0.11\n 0.12\n ⋮\n 4.89\n 4.9\n 4.91\n 4.92\n 4.93\n 4.94\n 4.95\n 4.96\n 4.97\n 4.98\n 4.99\n 5.0","category":"page"},{"location":"examples/simple_hybrid_ME/#RealFMU","page":"Simple ME-NeuralFMU","title":"RealFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In the next lines of code the FMU of the realFMU model from FMIZoo.jl is loaded and the information about the FMU is shown.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"realFMU = fmiLoad(\"SpringFrictionPendulum1D\", \"Dymola\", \"2022x\")\nfmiInfo(realFMU)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringFrictionPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{2e178ad3-5e9b-48ec-a7b2-baa5669efc0c}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:12Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t24\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\", \"mass.v_relfric\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In the next steps the parameters are defined. The first parameter is the initial position of the mass, which is initilized with 05𝑚. The second parameter is the initial velocity of the mass, which is initialized with 0fracms. The FMU hase two states: The first state is the position of the mass and the second state is the velocity. In the function fmiSimulate() the realFMU is simulated, still specifying the start and end time, the parameters and which variables are recorded. After the simulation is finished the result of the realFMU can be plotted. This plot also serves as a reference for the other model (simpleFMU).","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"initStates = [\"s0\", \"v0\"]\nx₀ = [0.5, 0.0]\nparams = Dict(zip(initStates, x₀))\nvrs = [\"mass.s\", \"mass.v\", \"mass.a\", \"mass.f\"]\n\nrealSimData = fmiSimulate(realFMU, (tStart, tStop); parameters=params, recordValues=vrs, saveat=tSave)\nfmiPlot(realSimData)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"\u001b[34mSimulating CS-FMU ...   0%|█                             |  ETA: N/A\u001b[39m\n\n\u001b[34mSimulating CS-FMU ... 100%|██████████████████████████████| Time: 0:00:02\u001b[39m","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The data from the simulation of the realFMU, are divided into position and velocity data. These data will be needed later. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"velReal = fmi2GetSolutionValue(realSimData, \"mass.v\")\nposReal = fmi2GetSolutionValue(realSimData, \"mass.s\")","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"501-element Vector{Float64}:\n 0.5\n 0.5002235448486548\n 0.5008715291319449\n 0.5019478597521578\n 0.5034570452098334\n 0.5053993458877354\n 0.5077764240578201\n 0.5105886522837868\n 0.5138351439717114\n 0.5175150321322992\n 0.521627087567517\n 0.5261682148972211\n 0.5311370185654775\n ⋮\n 1.0657564963384756\n 1.066930862706352\n 1.0679715872270086\n 1.068876303469867\n 1.0696434085045978\n 1.0702725656148622\n 1.0707609890298837\n 1.071107075846018\n 1.0713093338869186\n 1.0713672546639146\n 1.0713672546629138\n 1.071367254661913","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"After extracting the data, the FMU is cleaned-up.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"fmiUnload(realFMU)","category":"page"},{"location":"examples/simple_hybrid_ME/#SimpleFMU","page":"Simple ME-NeuralFMU","title":"SimpleFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The following lines load, simulate and plot the simpleFMU just like the realFMU. The differences between both systems can be clearly seen from the plots. In the plot for the realFMU it can be seen that the oscillation continues to decrease due to the effect of the friction. If you simulate long enough, the oscillation would come to a standstill in a certain time. The oscillation in the simpleFMU behaves differently, since the friction was not taken into account here. The oscillation in this model would continue to infinity with the same oscillation amplitude. From this observation the desire of an improvement of this model arises.     ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"simpleFMU = fmiLoad(\"SpringPendulum1D\", \"Dymola\", \"2022x\")\nfmiInfo(simpleFMU)\n\nvrs = [\"mass.s\", \"mass.v\", \"mass.a\"]\nsimpleSimData = fmiSimulate(simpleFMU, (tStart, tStop); recordValues=vrs, saveat=tSave, reset=false)\nfmiPlot(simpleSimData)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{fc15d8c4-758b-48e6-b00e-5bf47b8b14e5}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:23Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t0\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The data from the simulation of the simpleFMU, are divided into position and velocity data. These data will be needed later to plot the results. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"velSimple = fmi2GetSolutionValue(simpleSimData, \"mass.v\")\nposSimple = fmi2GetSolutionValue(simpleSimData, \"mass.s\")","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"501-element Vector{Float64}:\n 0.5\n 0.5003127019074967\n 0.5012175433745238\n 0.5027172504687035\n 0.504812416566759\n 0.5075012719497328\n 0.5107830165354977\n 0.5146534880772458\n 0.5191107030735219\n 0.5241484264969329\n 0.5297629811612266\n 0.5359472314461261\n 0.5426950964528339\n ⋮\n 1.6842615646003007\n 1.6884869953422783\n 1.6921224800662573\n 1.69516502108285\n 1.6976144547672483\n 1.6994659284032172\n 1.7007174453690572\n 1.7013675684067706\n 1.7014154196220592\n 1.7008606804843265\n 1.69970552855305\n 1.6979508813706","category":"page"},{"location":"examples/simple_hybrid_ME/#NeuralFMU","page":"Simple ME-NeuralFMU","title":"NeuralFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/#Loss-function","page":"Simple ME-NeuralFMU","title":"Loss function","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In order to train our model, a loss function must be implemented. The solver of the NeuralFMU can calculate the gradient of the loss function. The gradient descent is needed to adjust the weights in the neural network so that the sum of the error is reduced and the model becomes more accurate.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The loss function in this implementation consists of the mean squared error (mse) from the real position of the realFMU simulation (posReal) and the position data of the network (posNet). $ e{mse} = \\frac{1}{n} \\sum\\limits{i=0}^n (posReal[i] - posNet[i])^2 $","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"As it is indicated with the comments, one could also additionally consider the mse from the real velocity (velReal) and the velocity from the network (velNet). The error in this case would be calculated from the sum of both errors.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# loss function for training\nfunction lossSum(p)\n    global posReal\n    solution = neuralFMU(x₀; p=p)\n\n    posNet = fmi2GetSolutionState(solution, 1; isIndex=true)\n    \n    FMIFlux.Losses.mse(posReal, posNet) \nend","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"lossSum (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_ME/#Callback","page":"Simple ME-NeuralFMU","title":"Callback","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"To output the loss in certain time intervals, a callback is implemented as a function in the following. Here a counter is incremented, every twentieth pass the loss function is called and the average error is printed out.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# callback function for training\nglobal counter = 0\nfunction callb(p)\n    global counter += 1\n    if counter % 20 == 1\n        avgLoss = lossSum(p[1])\n        @info \"Loss [$counter]: $(round(avgLoss, digits=5))   Avg displacement in data: $(round(sqrt(avgLoss), digits=5))\"\n    end\nend","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"callb (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_ME/#Structure-of-the-NeuralFMU","page":"Simple ME-NeuralFMU","title":"Structure of the NeuralFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"In the following, the topology of the NeuralFMU is constructed. It consists of an input layer, which then leads into the simpleFMU model. The ME-FMU computes the state derivatives for a given system state. Following the simpleFMU is a dense layer that has exactly as many inputs as the model has states (and therefore state derivatives). The output of this layer consists of 16 output nodes and a tanh activation function. The next layer has 16 input and output nodes with the same activation function. The last layer is again a dense layer with 16 input nodes and the number of states as outputs. Here, it is important that no tanh-activation function follows, because otherwise the pendulums state values would be limited to the interval -11.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# NeuralFMU setup\nnumStates = fmiGetNumberOfStates(simpleFMU)\n\nnet = Chain(x -> simpleFMU(x=x, dx_refs=:all),\n            Dense(numStates, 16, tanh),\n            Dense(16, 16, tanh),\n            Dense(16, numStates))","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Chain(\n  var\"#1#2\"(),\n  Dense(2 => 16, tanh),                 \u001b[90m# 48 parameters\u001b[39m\n  Dense(16 => 16, tanh),                \u001b[90m# 272 parameters\u001b[39m\n  Dense(16 => 2),                       \u001b[90m# 34 parameters\u001b[39m\n) \u001b[90m                  # Total: 6 arrays, \u001b[39m354 parameters, 1.758 KiB.","category":"page"},{"location":"examples/simple_hybrid_ME/#Definition-of-the-NeuralFMU","page":"Simple ME-NeuralFMU","title":"Definition of the NeuralFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"The instantiation of the ME-NeuralFMU is done as a one-liner. The FMU (simpleFMU), the structure of the network net, start tStart and end time tStop, the numerical solver Tsit5() and the time steps tSave for saving are specified.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"neuralFMU = ME_NeuralFMU(simpleFMU, net, (tStart, tStop), Tsit5(); saveat=tSave);","category":"page"},{"location":"examples/simple_hybrid_ME/#Plot-before-training","page":"Simple ME-NeuralFMU","title":"Plot before training","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Here the state trajectory of the simpleFMU is recorded. Doesn't really look like a pendulum yet, but the system is random initialized by default. In the plots later on, the effect of learning can be seen.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"solutionBefore = neuralFMU(x₀)\nfmiPlot(solutionBefore)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNo solver keyword detected for NeuralFMU.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mContinuous adjoint method is applied, which requires solving backward in time.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis might be not supported by every FMU.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m(This message is only printed once.)\n\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ FMICore C:\\Users\\runneradmin\\.julia\\packages\\FMICore\\7NIyu\\src\\printing.jl:38\u001b[39m","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/#Training-of-the-NeuralFMU","page":"Simple ME-NeuralFMU","title":"Training of the NeuralFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"For the training of the NeuralFMU the parameters are extracted. The known Adam optimizer for minimizing the gradient descent is used as further passing parameters. In addition, the previously defined loss and callback function, as well as the number of epochs are passed.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# train\nparamsNet = FMIFlux.params(neuralFMU)\n\noptim = Adam()\nFMIFlux.train!(lossSum, neuralFMU, Iterators.repeated((), 300), optim; cb=()->callb(paramsNet)) ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1]: 14.31508   Avg displacement in data: 3.78353\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [21]: 2.0444   Avg displacement in data: 1.42982\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [41]: 0.36163   Avg displacement in data: 0.60135\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [61]: 0.11469   Avg displacement in data: 0.33866\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [81]: 0.0737   Avg displacement in data: 0.27147\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [101]: 0.06571   Avg displacement in data: 0.25633\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [121]: 0.06033   Avg displacement in data: 0.24562\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [141]: 0.05599   Avg displacement in data: 0.23663\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [161]: 0.05242   Avg displacement in data: 0.22894\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [181]: 0.0495   Avg displacement in data: 0.22249\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [201]: 0.04714   Avg displacement in data: 0.21712\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [221]: 0.04522   Avg displacement in data: 0.21265\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [241]: 0.04366   Avg displacement in data: 0.20896\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [261]: 0.04239   Avg displacement in data: 0.20589\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [281]: 0.04135   Avg displacement in data: 0.20334","category":"page"},{"location":"examples/simple_hybrid_ME/#Comparison-of-the-plots","page":"Simple ME-NeuralFMU","title":"Comparison of the plots","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Here three plots are compared with each other and only the position of the mass is considered. The first plot represents the simpleFMU, the second represents the realFMU (reference) and the third plot represents the result after training the NeuralFMU. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"# plot results mass.s\nsolutionAfter = neuralFMU(x₀)\n\nfig = Plots.plot(xlabel=\"t [s]\", ylabel=\"mass position [m]\", linewidth=2,\n                 xtickfontsize=12, ytickfontsize=12,\n                 xguidefontsize=12, yguidefontsize=12,\n                 legendfontsize=8, legend=:topright)\n\nPlots.plot!(fig, tSave, posSimple, label=\"SimpleFMU\", linewidth=2)\nPlots.plot!(fig, tSave, posReal, label=\"RealFMU\", linewidth=2)\nPlots.plot!(fig, solutionAfter; stateIndices=1:1, values=false, label=\"NeuralFMU (300 epochs)\", linewidth=2)\nfig ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/#Continue-training-and-plotting","page":"Simple ME-NeuralFMU","title":"Continue training and plotting","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"As can be seen from the previous figure, the plot of the NeuralFMU has not yet fully converged against the realFMU, so the training of the NeuralFMU is continued. After further training, the plot of NeuralFMU is added to the figure again. The effect of the longer training can be recognized well, since the plot of the NeuralFMU had further converged. ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"FMIFlux.train!(lossSum, neuralFMU, Iterators.repeated((), 1200), optim; cb=()->callb(paramsNet)) \n# plot results mass.s\nsolutionAfter = neuralFMU(x₀)\nPlots.plot!(fig, solutionAfter; stateIndices=1:1, values=false, label=\"NeuralFMU (1500 epochs)\", linewidth=2)\nfig ","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [301]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [321]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [341]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [361]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [381]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [401]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [421]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [441]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [461]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [481]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [501]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [521]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [541]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [561]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [581]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [601]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [621]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [641]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [661]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [681]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [701]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [721]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [741]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [761]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [781]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [801]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [821]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [841]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [861]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [881]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [901]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [921]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [941]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [961]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [981]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1001]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1021]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1041]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1061]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1081]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1101]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1121]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1141]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1161]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1181]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1201]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1221]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1241]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1261]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1281]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1301]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1321]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1341]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1361]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1381]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1401]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1421]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1441]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1461]: 0.04052   Avg displacement in data: 0.20129\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1481]: 0.04052   Avg displacement in data: 0.20129","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Finally, the FMU is cleaned-up.","category":"page"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"fmiUnload(simpleFMU)","category":"page"},{"location":"examples/simple_hybrid_ME/#Summary","page":"Simple ME-NeuralFMU","title":"Summary","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"Based on the plots, it can be seen that the NeuralFMU is able to adapt the friction model of the realFMU. After 300 runs, the curves do not overlap very well, but this can be achieved by longer training (1000 runs) or a better initialization.","category":"page"},{"location":"examples/simple_hybrid_ME/#Source","page":"Simple ME-NeuralFMU","title":"Source","text":"","category":"section"},{"location":"examples/simple_hybrid_ME/","page":"Simple ME-NeuralFMU","title":"Simple ME-NeuralFMU","text":"[1] Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. NeuralFMU: towards structural integration of FMUs into neural networks. Martin Sjölund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, Linköping, Sweden, September 20-24, 2021. Linköping University Electronic Press, Linköping (Linköping Electronic Conference Proceedings ; 181), 297-306. DOI: 10.3384/ecp21181297","category":"page"},{"location":"faq/#FAQ","page":"FAQ","title":"FAQ","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"This list some common - often numerical - errors, that can be fixed by better understanding the ODE-Problem inside your FMU.","category":"page"},{"location":"faq/#Double-callback-crossing","page":"FAQ","title":"Double callback crossing","text":"","category":"section"},{"location":"faq/#Description","page":"FAQ","title":"Description","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Error message, a double zero-crossing happened, often during training a NeuralFMU.","category":"page"},{"location":"faq/#Example","page":"FAQ","title":"Example","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Double callback crossing floating pointer reducer errored. Report this issue.","category":"page"},{"location":"faq/#Reason","page":"FAQ","title":"Reason","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"This could be, because the event inside of a NeuralFMU can't be located (often when using Zygote). ","category":"page"},{"location":"faq/#Fix","page":"FAQ","title":"Fix","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Try to increase the root search interpolation points, this is computational expensive for FMUs with many events- and event-indicators. This can be done using fmu.executionConfig.rootSearchInterpolationPoints = 100 (default value is 10).","category":"page"},{"location":"examples/growing_horizon_ME/#ME-NeuralFMUs-using-Growing-Horizon","page":"Growing Horizon ME-NeuralFMU","title":"ME-NeuralFMUs using Growing Horizon","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"Tutorial by Johannes Stoljar, Tobias Thummerer","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"Last edit: 08.11.2023","category":"page"},{"location":"examples/growing_horizon_ME/#LICENSE","page":"Growing Horizon ME-NeuralFMU","title":"LICENSE","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"# Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons, Johannes Stoljar\n# Licensed under the MIT license. \n# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details.","category":"page"},{"location":"examples/growing_horizon_ME/#Motivation","page":"Growing Horizon ME-NeuralFMU","title":"Motivation","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"The Julia Package FMIFlux.jl is motivated by the application of hybrid modeling. This package enables the user to integrate his simulation model between neural networks (NeuralFMU). For this, the simulation model must be exported as FMU (functional mock-up unit), which corresponds to a widely used standard. The big advantage of hybrid modeling with artificial neural networks is, that effects that are difficult to model (because they might be unknown) can be easily learned by the neural networks. For this purpose, the NeuralFMU is trained with measurement data containing the not modeled physical effect. The final product is a simulation model including the originally not modeled effects. Another big advantage of the NeuralFMU is that it works with little data, because the FMU already contains the characteristic functionality of the simulation and only the missing effects are added.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"NeuralFMUs do not need to be as easy as in this example. Basically a NeuralFMU can combine different ANN topologies that manipulate any FMU-input (system state, system inputs, time) and any FMU-output (system state derivative, system outputs, other system variables). However, for this example a NeuralFMU topology as shown in the following picture is used.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"(Image: NeuralFMU.svg)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"NeuralFMU (ME) from [1].","category":"page"},{"location":"examples/growing_horizon_ME/#Introduction-to-the-example","page":"Growing Horizon ME-NeuralFMU","title":"Introduction to the example","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"In this example, simplified modeling of a one-dimensional spring pendulum (without friction) is compared to a model of the same system that includes a nonlinear friction model. The FMU with the simplified model will be named simpleFMU in the following and the model with the friction will be named fricFMU. At the beginning, the actual state of both simulations is shown, whereby clear deviations can be seen in the graphs. The fricFMU serves as a reference graph. The simpleFMU is then integrated into a NeuralFMU architecture and a training of the entire network is performed. After the training the final state is compared again to the fircFMU. It can be clearly seen that by using the NeuralFMU, learning of the friction process has taken place.  ","category":"page"},{"location":"examples/growing_horizon_ME/#Target-group","page":"Growing Horizon ME-NeuralFMU","title":"Target group","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"The example is primarily intended for users who work in the field of first principle and/or hybrid modeling and are further interested in hybrid model building. The example wants to show how simple it is to combine FMUs with machine learning and to illustrate the advantages of this approach.","category":"page"},{"location":"examples/growing_horizon_ME/#Other-formats","page":"Growing Horizon ME-NeuralFMU","title":"Other formats","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"Besides, this Jupyter Notebook there is also a Julia file with the same name, which contains only the code cells and for the documentation there is a Markdown file corresponding to the notebook.  ","category":"page"},{"location":"examples/growing_horizon_ME/#Getting-started","page":"Growing Horizon ME-NeuralFMU","title":"Getting started","text":"","category":"section"},{"location":"examples/growing_horizon_ME/#Installation-prerequisites","page":"Growing Horizon ME-NeuralFMU","title":"Installation prerequisites","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":" Description Command\n1. Enter Package Manager via ]\n2. Install FMI via add FMI\n3. Install FMIFlux via add FMIFlux\n4. Install FMIZoo via add FMIZoo\n5. Install Plots via add Plots\n6. Install Random via add Random","category":"page"},{"location":"examples/growing_horizon_ME/#Code-section","page":"Growing Horizon ME-NeuralFMU","title":"Code section","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"To run the example, the previously installed packages must be included. ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"# imports\nusing FMI\nusing FMI.FMIImport: fmi2StringToValueReference, fmi2ValueReference, fmi2Real\nusing FMIFlux\nusing FMIFlux.Flux\nusing FMIZoo\nusing FMI.DifferentialEquations: Tsit5\nusing Statistics: mean, std\nusing Plots\n\n# set seed\nimport Random\nRandom.seed!(1234);","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mError requiring `Enzyme` from `LinearSolve`\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  exception =\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   LoadError: ArgumentError: Package LinearSolve does not have Enzyme in its dependencies:\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - You may have a partially installed environment. Try `Pkg.instantiate()`\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     to ensure all packages in the environment are installed.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - Or, if you have LinearSolve checked out for development and have\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     added Enzyme as a dependency but haven't updated your primary\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     environment's manifest file, try `Pkg.resolve()`.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - Otherwise you may need to report an issue with LinearSolve\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   Stacktrace:\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1167\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:223\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [3] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1144\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [4] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:419\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [5] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4mLinearSolve.jl:1\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mRequires.jl:40\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [7] top-level scope\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4minit.jl:16\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [8] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mboot.jl:368\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [9] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4mLinearSolve.jl:1\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [10] \u001b[0m\u001b[1m(::LinearSolve.var\"#88#97\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:101\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [11] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m\u001b[4mtiming.jl:382\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [12] \u001b[0m\u001b[1merr\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mAny, \u001b[90mlistener\u001b[39m::\u001b[0mModule, \u001b[90mmodname\u001b[39m::\u001b[0mString, \u001b[90mfile\u001b[39m::\u001b[0mString, \u001b[90mline\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:47\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [13] \u001b[0m\u001b[1m(::LinearSolve.var\"#87#96\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:100\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [14] \u001b[0m\u001b[1mwithpath\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mAny, \u001b[90mpath\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:37\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [15] \u001b[0m\u001b[1m(::LinearSolve.var\"#86#95\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:99\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [16] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [17] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [18] \u001b[0m\u001b[1mforeach\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mtypeof(Base.invokelatest), \u001b[90mitr\u001b[39m::\u001b[0mVector\u001b[90m{Function}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mabstractarray.jl:2774\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [19] \u001b[0m\u001b[1mloadpkg\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:27\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [20] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [21] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [22] \u001b[0m\u001b[1mrun_package_callbacks\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmodkey\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:869\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [23] \u001b[0m\u001b[1m_tryrequire_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmodkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90msourcepath\u001b[39m::\u001b[0mString, \u001b[90mdepmods\u001b[39m::\u001b[0mVector\u001b[90m{Any}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:944\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [24] \u001b[0m\u001b[1m_require_search_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msourcepath\u001b[39m::\u001b[0mString, \u001b[90mbuild_id\u001b[39m::\u001b[0mUInt64\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1028\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [25] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1315\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [26] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1200\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [27] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1180\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [28] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:223\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [29] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1144\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [30] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mboot.jl:368\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [31] \u001b[0m\u001b[1minclude_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmapexpr\u001b[39m::\u001b[0mtypeof(REPL.softscope), \u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1428\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [32] \u001b[0m\u001b[1msoftscope_include_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[32mSoftGlobalScope\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\SoftGlobalScope\\u4UzH\\src\\\u001b[39m\u001b[90m\u001b[4mSoftGlobalScope.jl:65\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [33] \u001b[0m\u001b[1mexecute_request\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket, \u001b[90mmsg\u001b[39m::\u001b[0mIJulia.Msg\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\IJulia\\Vo51o\\src\\\u001b[39m\u001b[90m\u001b[4mexecute_request.jl:67\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [34] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [35] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [36] \u001b[0m\u001b[1meventloop\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\IJulia\\Vo51o\\src\\\u001b[39m\u001b[90m\u001b[4meventloop.jl:8\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [37] \u001b[0m\u001b[1m(::IJulia.var\"#15#18\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mtask.jl:484\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   in expression starting at C:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\ext\\LinearSolveEnzymeExt.jl:1\n\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Requires C:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\require.jl:51\u001b[39m","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"After importing the packages, the path to the Functional Mock-up Units (FMUs) is set. The FMU is a model exported meeting the Functional Mock-up Interface (FMI) Standard. The FMI is a free standard (fmi-standard.org) that defines a container and an interface to exchange dynamic models using a combination of XML files, binaries and C code zipped into a single file. ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"The object-orientated structure of the SpringPendulum1D (simpleFMU) can be seen in the following graphic and corresponds to a simple modeling.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"In contrast, the model SpringFrictionPendulum1D (fricFMU) is somewhat more accurate, because it includes a friction component. ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"Next, the start time and end time of the simulation are set. Finally, a step size is specified to store the results of the simulation at these time steps.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"tStart = 0.0\ntStep = 0.1\ntStop = 5.0\ntSave = collect(tStart:tStep:tStop)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"51-element Vector{Float64}:\n 0.0\n 0.1\n 0.2\n 0.3\n 0.4\n 0.5\n 0.6\n 0.7\n 0.8\n 0.9\n 1.0\n 1.1\n 1.2\n ⋮\n 3.9\n 4.0\n 4.1\n 4.2\n 4.3\n 4.4\n 4.5\n 4.6\n 4.7\n 4.8\n 4.9\n 5.0","category":"page"},{"location":"examples/growing_horizon_ME/#*fricFMU*","page":"Growing Horizon ME-NeuralFMU","title":"fricFMU","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"In the next lines of code the FMU of the fricFMU model from FMIZoo.jl is loaded and the information about the FMU is shown.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"fricFMU = fmiLoad(\"SpringFrictionPendulum1D\", \"Dymola\", \"2022x\")\nfmiInfo(fricFMU)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringFrictionPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{2e178ad3-5e9b-48ec-a7b2-baa5669efc0c}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:12Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t24\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\", \"mass.v_relfric\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"In the function fmiSimulate() the fricFMU is simulated, still specifying the start and end time, the parameters and which variables are recorded. After the simulation is finished the result of the fricFMU can be plotted. This plot also serves as a reference for the other model (simpleFMU).","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"vrs = [\"mass.s\", \"mass.v\", \"mass.a\", \"mass.f\"]\nsolFric = fmiSimulate(fricFMU, (tStart, tStop); recordValues=vrs, saveat=tSave)\nplot(solFric)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"\u001b[34mSimulating CS-FMU ...   0%|█                             |  ETA: N/A\u001b[39m\n\n\u001b[34mSimulating CS-FMU ... 100%|██████████████████████████████| Time: 0:00:02\u001b[39m","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"The data from the simulation of the fricFMU, are divided into position and velocity data. These data will be needed later. ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"posFric = fmi2GetSolutionValue(solFric, \"mass.s\")\nvelFric = fmi2GetSolutionValue(solFric, \"mass.v\")","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"51-element Vector{Float64}:\n  0.0\n  0.432852398300982\n  0.8401743918610578\n  1.1702254881462497\n  1.3861768532456016\n  1.4649609400224617\n  1.397962181945595\n  1.1917483098990418\n  0.8657325133644009\n  0.44821918384886916\n -0.02200493896693855\n -0.380560845401747\n -0.7172068753289351\n  ⋮\n -0.19353187721088116\n  0.021605187634145845\n  0.12911473439606144\n  0.2315130895115627\n  0.31667721272388255\n  0.37417576531479746\n  0.3964197153211615\n  0.3795927497483354\n  0.3235539803194403\n  0.2317738499958648\n  0.11061350893737848\n -1.0008118292437196e-10","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"The FMU has two states: The first state is the position of the mass and the second state is the velocity. The initial position of the mass is initialized with 05𝑚. The initial velocity of the mass is initialized with 0fracms. ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"x₀ = [posFric[1], velFric[1]]","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"2-element Vector{Float64}:\n 0.5\n 0.0","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"After extracting the data, the FMU is cleaned-up.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"fmiUnload(fricFMU)","category":"page"},{"location":"examples/growing_horizon_ME/#SimpleFMU","page":"Growing Horizon ME-NeuralFMU","title":"SimpleFMU","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"The following lines load, simulate and plot the simpleFMU just like the fricFMU. The differences between both systems can be clearly seen from the plots. In the plot for the fricFMU it can be seen that the oscillation continues to decrease due to the effect of the friction. If you simulate long enough, the oscillation would come to a standstill in a certain time. The oscillation in the simpleFMU behaves differently, since the friction was not taken into account here. The oscillation in this model would continue to infinity with the same oscillation amplitude. From this observation the desire of an improvement of this model arises.     ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"simpleFMU = fmiLoad(\"SpringPendulum1D\", \"Dymola\", \"2022x\"; type=:ME)\nfmiInfo(simpleFMU)\n\nvrs = [\"mass.s\", \"mass.v\", \"mass.a\"]\nsolSimple = fmiSimulate(simpleFMU, (tStart, tStop); recordValues=vrs, saveat=tSave)\nplot(solSimple)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{fc15d8c4-758b-48e6-b00e-5bf47b8b14e5}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:23Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t0\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################\n\n\n\u001b[34mSimulating ME-FMU ...   0%|█                             |  ETA: N/A\u001b[39m\n\n\u001b[34mSimulating ME-FMU ... 100%|██████████████████████████████| Time: 0:00:09\u001b[39m","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"The data from the simulation of the simpleFMU, are divided into position and velocity data. These data will be needed later to plot the results. ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"posSimple = fmi2GetSolutionValue(solSimple, \"mass.s\")\nvelSimple = fmi2GetSolutionValue(solSimple, \"mass.v\")","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"51-element Vector{Float64}:\n  0.0\n  0.5900499045575546\n  1.1215848686403096\n  1.541892887990106\n  1.809292251922929\n  1.897265115600142\n  1.797087259817532\n  1.518693266896391\n  1.0896913136721704\n  0.5526252840128629\n -0.03924428436005998\n -0.6272220176030365\n -1.1529984931243986\n  ⋮\n -0.4389974278206929\n  0.15680920523609004\n  0.7370651557739741\n  1.244226766096815\n  1.6279991034408674\n  1.850323680279787\n  1.889152693194497\n  1.7406354911553794\n  1.4195004423851794\n  0.9575943302840277\n  0.4007241257092793\n -0.1958856419517666","category":"page"},{"location":"examples/growing_horizon_ME/#NeuralFMU","page":"Growing Horizon ME-NeuralFMU","title":"NeuralFMU","text":"","category":"section"},{"location":"examples/growing_horizon_ME/#Loss-function-with-growing-horizon","page":"Growing Horizon ME-NeuralFMU","title":"Loss function with growing horizon","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"In order to train our model, a loss function must be implemented. The solver of the NeuralFMU can calculate the gradient of the loss function. The gradient descent is needed to adjust the weights in the neural network so that the sum of the error is reduced and the model becomes more accurate.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"The loss function in this implementation consists of the mean squared error (mse) from the Fric position of the fricFMU simulation (posFric) and the position data of the network (posNet). $ e{mse} = \\frac{1}{n} \\sum\\limits{i=0}^n (posFric[i] - posNet[i])^2 $ A growing horizon is applied, whereby the horizon only goes over the first five values. For this horizon the mse is calculated.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"# loss function for training\nglobal horizon = 5\nfunction lossSum(p)\n    global posFric, neuralFMU, horizon\n\n    solution = neuralFMU(x₀, (tSave[1], tSave[horizon]); p=p, saveat=tSave[1:horizon]) # here, the NeuralODE is solved only for the time horizon\n\n    posNet = fmi2GetSolutionState(solution, 1; isIndex=true)\n\n    FMIFlux.Losses.mse(posFric[1:horizon], posNet)\nend","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"lossSum (generic function with 1 method)","category":"page"},{"location":"examples/growing_horizon_ME/#Function-for-plotting","page":"Growing Horizon ME-NeuralFMU","title":"Function for plotting","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"In this section the function for plotting is defined. The function plotResults() creates a new figure object. In dieses figure objekt werden dann die aktuellsten Ergebnisse von fricFMU, simpleFMU und neuralFMU gegenübergestellt. ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"To output the loss in certain time intervals, a callback is implemented as a function in the following. Here a counter is incremented, every twentieth pass the loss function is called and the average error is printed out.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"function plotResults()\n    global neuralFMU\n    solNeural = neuralFMU(x₀, (tStart, tStop); saveat=tSave)\n    \n    fig = Plots.plot(xlabel=\"t [s]\", ylabel=\"mass position [m]\", linewidth=2,\n                     xtickfontsize=12, ytickfontsize=12,\n                     xguidefontsize=12, yguidefontsize=12,\n                     legendfontsize=8, legend=:topright)\n    \n    plot!(fig, solSimple; stateIndices=1:1, values=false, label=\"SimpleFMU\", linewidth=2)\n    plot!(fig, solFric; valueIndices=1:1, label=\"FricFMU\", linewidth=2)\n    plot!(fig, solNeural; stateIndices=1:1, label=\"NeuralFMU\", linewidth=2)\n    fig\nend","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"plotResults (generic function with 1 method)","category":"page"},{"location":"examples/growing_horizon_ME/#Callback","page":"Growing Horizon ME-NeuralFMU","title":"Callback","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"To output the loss in certain time intervals, a callback is implemented as a function in the following. Here a counter is incremented, every twentieth pass the loss function is called and the average error is printed out.  As soon as a limit value (in this example 0.1) is undershot, the horizon is extended by the next two values.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"# callback function for training\nglobal counter = 0\nfunction callb(p)\n    global counter, horizon \n    counter += 1\n   \n    if counter % 50 == 1\n        avgLoss = lossSum(p[1])\n        @info \"  Loss [$counter] for horizon $horizon : $(round(avgLoss, digits=5))\\nAvg displacement in data: $(round(sqrt(avgLoss), digits=5))\"\n        \n        if avgLoss <= 0.01\n            horizon += 2\n            horizon = min(length(tSave), horizon)\n        end\n   \n        # fig = plotResults()\n        # println(\"Figure update.\")\n        # display(fig)\n    end\nend\n","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"callb (generic function with 1 method)","category":"page"},{"location":"examples/growing_horizon_ME/#Pre-and-Postprocessing","page":"Growing Horizon ME-NeuralFMU","title":"Pre- and Postprocessing","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"In the following functions for pre-processing and post-processing are defined. The function preProc is normalized the input values to mean of zero and a standard deviation of one. ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"global meanVal = 0.0\nglobal stdVal = 0.0\n\nfunction preProc!(data)\n    global meanVal, stdVal\n\n    meanVal = mean(data)\n    stdVal = std(data)\n    \n    (data .- meanVal) ./ stdVal    \nend ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"preProc! (generic function with 1 method)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"For post-processing, the previous normalization is undone by applying the calculation steps in reverse order.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"function postProc!(data)\n    global meanVal, stdVal\n    \n    (data .* stdVal) .+ meanVal\nend ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"postProc! (generic function with 1 method)","category":"page"},{"location":"examples/growing_horizon_ME/#Structure-of-the-NeuralFMU","page":"Growing Horizon ME-NeuralFMU","title":"Structure of the NeuralFMU","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"In the following, the topology of the NeuralFMU is constructed. It consists of an input layer, which then leads into the simpleFMU model. The ME-FMU computes the state derivatives for a given system state. Following the simpleFMU is a dense layer that has exactly as many inputs as the model has states (and therefore state derivatives). The output of this layer consists of 16 output nodes and a tanh activation function. The next layer has 16 input and output nodes with the same activation function. The last layer is again a dense layer with 16 input nodes and the number of states as outputs. Here, it is important that no tanh-activation function follows, because otherwise the pendulums state values would be limited to the interval -11.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"# NeuralFMU setup\nnumStates = fmiGetNumberOfStates(simpleFMU)\nadditionalVRs = [fmi2StringToValueReference(simpleFMU, \"mass.m\")]\nnumAdditionalVRs = length(additionalVRs)\n\nnet = Chain(\n    x -> simpleFMU(x=x, dx_refs=:all, y_refs=additionalVRs),\n    preProc!,\n    Dense(numStates+numAdditionalVRs, 16, tanh),\n    postProc!,\n    preProc!,\n    Dense(16, 16, tanh),\n    postProc!,\n    preProc!,\n    Dense(16, numStates),\n    postProc!,\n)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"Chain(\n  var\"#1#2\"(),\n  preProc!,\n  Dense(3 => 16, tanh),                 \u001b[90m# 64 parameters\u001b[39m\n  postProc!,\n  preProc!,\n  Dense(16 => 16, tanh),                \u001b[90m# 272 parameters\u001b[39m\n  postProc!,\n  preProc!,\n  Dense(16 => 2),                       \u001b[90m# 34 parameters\u001b[39m\n  postProc!,\n) \u001b[90m                  # Total: 6 arrays, \u001b[39m370 parameters, 1.820 KiB.","category":"page"},{"location":"examples/growing_horizon_ME/#Definition-of-the-NeuralFMU","page":"Growing Horizon ME-NeuralFMU","title":"Definition of the NeuralFMU","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"The instantiation of the ME-NeuralFMU is done as a one-liner. The FMU (simpleFMU), the structure of the network net, start tStart and end time tStop, the numerical solver Tsit5() and the time steps tSave for saving are specified.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"neuralFMU = ME_NeuralFMU(simpleFMU, net, (tStart, tStop), Tsit5(); saveat=tSave);","category":"page"},{"location":"examples/growing_horizon_ME/#Plot-before-training","page":"Growing Horizon ME-NeuralFMU","title":"Plot before training","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"Here the state trajectory of the simpleFMU is recorded. Doesn't really look like a pendulum yet, but the system is random initialized by default. In the plots later on, the effect of learning can be seen.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"solutionBefore = neuralFMU(x₀)\nfmiPlot(solutionBefore)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNo solver keyword detected for NeuralFMU.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mContinuous adjoint method is applied, which requires solving backward in time.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis might be not supported by every FMU.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m(This message is only printed once.)\n\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ FMICore C:\\Users\\runneradmin\\.julia\\packages\\FMICore\\7NIyu\\src\\printing.jl:38\u001b[39m","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/growing_horizon_ME/#Training-of-the-NeuralFMU","page":"Growing Horizon ME-NeuralFMU","title":"Training of the NeuralFMU","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"For the training of the NeuralFMU the parameters are extracted. The known Adam optimizer for minimizing the gradient descent is used as further passing parameters. In addition, the previously defined loss and callback function, as well as the number of epochs are passed.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"# train\nparamsNet = Flux.params(neuralFMU)\n\noptim = Adam()\nFMIFlux.train!(lossSum, neuralFMU, Iterators.repeated((), 1000), optim; cb=()->callb(paramsNet)) ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1] for horizon 5 : 0.04198\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.20488\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [51] for horizon 5 : 0.00035\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.01877\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [101] for horizon 7 : 9.0e-5\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.00959\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [151] for horizon 9 : 3.0e-5\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.00537\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [201] for horizon 11 : 0.00016\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.01256\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [251] for horizon 13 : 0.00057\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.02384\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [301] for horizon 15 : 0.00129\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.03588\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [351] for horizon 17 : 0.00114\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.03383\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [401] for horizon 19 : 5.0e-5\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.00711\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [451] for horizon 21 : 2.0e-5\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.0044\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [501] for horizon 23 : 3.0e-5\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.00521\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [551] for horizon 25 : 2.0e-5\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.0045\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [601] for horizon 27 : 4.0e-5\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.00619\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [651] for horizon 29 : 0.0001\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.00993\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [701] for horizon 31 : 0.00024\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.01555\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [751] for horizon 33 : 0.00042\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.02048\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [801] for horizon 35 : 0.00043\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.02064\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [851] for horizon 37 : 0.00038\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.01948\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [901] for horizon 39 : 0.00034\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.01843\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [951] for horizon 41 : 0.00031\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39mAvg displacement in data: 0.01752","category":"page"},{"location":"examples/growing_horizon_ME/#Comparison-of-the-plots","page":"Growing Horizon ME-NeuralFMU","title":"Comparison of the plots","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"Here three plots are compared with each other and only the position of the mass is considered. The first plot represents the simpleFMU, the second represents the fricFMU (reference) and the third plot represents the result after training the NeuralFMU. ","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"# plot results mass.s\nplotResults()","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"Finally, the FMU is cleaned-up.","category":"page"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"fmiUnload(simpleFMU)","category":"page"},{"location":"examples/growing_horizon_ME/#Summary","page":"Growing Horizon ME-NeuralFMU","title":"Summary","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"Based on the plots, it can be seen that the NeuralFMU is able to adapt the friction model of the fricFMU. After 1000 training steps, the curves already overlap quite well, but this can be further improved by longer training or a better initialization.","category":"page"},{"location":"examples/growing_horizon_ME/#Source","page":"Growing Horizon ME-NeuralFMU","title":"Source","text":"","category":"section"},{"location":"examples/growing_horizon_ME/","page":"Growing Horizon ME-NeuralFMU","title":"Growing Horizon ME-NeuralFMU","text":"[1] Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. NeuralFMU: towards structural integration of FMUs into neural networks. Martin Sjölund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, Linköping, Sweden, September 20-24, 2021. Linköping University Electronic Press, Linköping (Linköping Electronic Conference Proceedings ; 181), 297-306. DOI: 10.3384/ecp21181297","category":"page"},{"location":"examples/simple_hybrid_CS/#Creation-and-training-of-CS-NeuralFMUs","page":"Simple CS-NeuralFMU","title":"Creation and training of CS-NeuralFMUs","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Tutorial by Johannes Stoljar, Tobias Thummerer","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Last edit: 15.11.2023","category":"page"},{"location":"examples/simple_hybrid_CS/#License","page":"Simple CS-NeuralFMU","title":"License","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons, Johannes Stoljar\n# Licensed under the MIT license. \n# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details.","category":"page"},{"location":"examples/simple_hybrid_CS/#Motivation","page":"Simple CS-NeuralFMU","title":"Motivation","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"The Julia Package FMIFlux.jl is motivated by the application of hybrid modeling. This package enables the user to integrate his simulation model between neural networks (NeuralFMU). For this, the simulation model must be exported as FMU (functional mock-up unit), which corresponds to a widely used standard. The big advantage of hybrid modeling with artificial neural networks is, that effects that are difficult to model (because they might be unknown) can be easily learned by the neural networks. For this purpose, the NeuralFMU is trained with measurement data containing the not modeled physical effect. The final product is a simulation model including the originally not modeled effects. Another big advantage of the NeuralFMU is that it works with little data, because the FMU already contains the characteristic functionality of the simulation and only the missing effects are added.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"NeuralFMUs do not need to be as easy as in this example. Basically a NeuralFMU can combine different ANN topologies that manipulate any FMU-input (system state, system inputs, time) and any FMU-output (system state derivative, system outputs, other system variables). However, for this example a NeuralFMU topology as shown in the following picture is used.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"(Image: CS-NeuralFMU.svg)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"NeuralFMU (CS) from [1].","category":"page"},{"location":"examples/simple_hybrid_CS/#Introduction-to-the-example","page":"Simple CS-NeuralFMU","title":"Introduction to the example","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"In this example, the model of a one-dimensional spring pendulum (with an external acting force) is used to learn the initial states. For this purpose, on the one hand the initial position of the mass of the pendulum is shifted and on the other hand the default position of the mass from the model is used. The model with the shifted initial position serves as reference and is called referenceFMU in the following. The model with the default position is further referenced with defaultFMU. At the beginning, the actual state of both simulations is shown, whereby clear deviations can be seen in the graphs. Afterwards, the defaultFMU is integrated into a co-simulation NeuralFMU (CS-NeuralFMU) architecture. By training the NeuralFMU, an attempt is made to learn the initial displacement of the referenceFMU. It can be clearly seen that the NeuralFMU learns this shift well in just a few training steps. ","category":"page"},{"location":"examples/simple_hybrid_CS/#Target-group","page":"Simple CS-NeuralFMU","title":"Target group","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"The example is primarily intended for users who work in the field of first principle and/or hybrid modeling and are further interested in hybrid model building. The example wants to show how simple it is to combine FMUs with machine learning and to illustrate the advantages of this approach.","category":"page"},{"location":"examples/simple_hybrid_CS/#Other-formats","page":"Simple CS-NeuralFMU","title":"Other formats","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Besides, this Jupyter Notebook there is also a Julia file with the same name, which contains only the code cells and for the documentation there is a Markdown file corresponding to the notebook.  ","category":"page"},{"location":"examples/simple_hybrid_CS/#Getting-started","page":"Simple CS-NeuralFMU","title":"Getting started","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/#Installation-prerequisites","page":"Simple CS-NeuralFMU","title":"Installation prerequisites","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":" Description Command\n1. Enter Package Manager via ]\n2. Install FMI via add FMI\n3. Install FMIFlux via add FMIFlux\n4. Install FMIZoo via add FMIZoo\n5. Install DifferentialEquations via add DifferentialEquations\n6. Install Plots via add Plots\n7. Install Random via add Random","category":"page"},{"location":"examples/simple_hybrid_CS/#Code-section","page":"Simple CS-NeuralFMU","title":"Code section","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"To run the example, the previously installed packages must be included. ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# imports\nusing FMI\nusing FMIFlux\nusing FMIFlux.Flux\nusing FMIZoo\nusing DifferentialEquations: Tsit5\nimport Plots\n\n# set seed\nimport Random\nRandom.seed!(1234);","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mError requiring `Enzyme` from `LinearSolve`\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  exception =\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   LoadError: ArgumentError: Package LinearSolve does not have Enzyme in its dependencies:\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - You may have a partially installed environment. Try `Pkg.instantiate()`\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     to ensure all packages in the environment are installed.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - Or, if you have LinearSolve checked out for development and have\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     added Enzyme as a dependency but haven't updated your primary\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     environment's manifest file, try `Pkg.resolve()`.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - Otherwise you may need to report an issue with LinearSolve\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   Stacktrace:\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1167\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:223\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [3] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1144\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [4] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:419\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [5] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4mLinearSolve.jl:1\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mRequires.jl:40\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [7] top-level scope\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4minit.jl:16\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [8] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mboot.jl:368\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [9] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4mLinearSolve.jl:1\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [10] \u001b[0m\u001b[1m(::LinearSolve.var\"#88#97\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:101\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [11] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m\u001b[4mtiming.jl:382\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [12] \u001b[0m\u001b[1merr\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mAny, \u001b[90mlistener\u001b[39m::\u001b[0mModule, \u001b[90mmodname\u001b[39m::\u001b[0mString, \u001b[90mfile\u001b[39m::\u001b[0mString, \u001b[90mline\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:47\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [13] \u001b[0m\u001b[1m(::LinearSolve.var\"#87#96\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:100\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [14] \u001b[0m\u001b[1mwithpath\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mAny, \u001b[90mpath\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:37\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [15] \u001b[0m\u001b[1m(::LinearSolve.var\"#86#95\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:99\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [16] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [17] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [18] \u001b[0m\u001b[1mforeach\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mtypeof(Base.invokelatest), \u001b[90mitr\u001b[39m::\u001b[0mVector\u001b[90m{Function}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mabstractarray.jl:2774\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [19] \u001b[0m\u001b[1mloadpkg\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:27\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [20] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [21] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [22] \u001b[0m\u001b[1mrun_package_callbacks\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmodkey\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:869\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [23] \u001b[0m\u001b[1m_tryrequire_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmodkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90msourcepath\u001b[39m::\u001b[0mString, \u001b[90mdepmods\u001b[39m::\u001b[0mVector\u001b[90m{Any}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:944\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [24] \u001b[0m\u001b[1m_require_search_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msourcepath\u001b[39m::\u001b[0mString, \u001b[90mbuild_id\u001b[39m::\u001b[0mUInt64\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1028\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [25] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1315\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [26] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1200\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [27] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1180\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [28] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:223\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [29] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1144\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [30] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mboot.jl:368\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [31] \u001b[0m\u001b[1minclude_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmapexpr\u001b[39m::\u001b[0mtypeof(REPL.softscope), \u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1428\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [32] \u001b[0m\u001b[1msoftscope_include_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[32mSoftGlobalScope\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\SoftGlobalScope\\u4UzH\\src\\\u001b[39m\u001b[90m\u001b[4mSoftGlobalScope.jl:65\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [33] \u001b[0m\u001b[1mexecute_request\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket, \u001b[90mmsg\u001b[39m::\u001b[0mIJulia.Msg\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\IJulia\\Vo51o\\src\\\u001b[39m\u001b[90m\u001b[4mexecute_request.jl:67\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [34] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [35] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [36] \u001b[0m\u001b[1meventloop\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\IJulia\\Vo51o\\src\\\u001b[39m\u001b[90m\u001b[4meventloop.jl:8\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [37] \u001b[0m\u001b[1m(::IJulia.var\"#15#18\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mtask.jl:484\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   in expression starting at C:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\ext\\LinearSolveEnzymeExt.jl:1\n\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Requires C:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\require.jl:51\u001b[39m","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"After importing the packages, the path to the Functional Mock-up Units (FMUs) is set. The FMU is a model exported meeting the Functional Mock-up Interface (FMI) Standard. The FMI is a free standard (fmi-standard.org) that defines a container and an interface to exchange dynamic models using a combination of XML files, binaries and C code zipped into a single file. ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"The objec-orientated structure of the SpringPendulumExtForce1D can be seen in the following graphic. This model is a simple spring pendulum without friction, but with an external force. ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Next, the start time and end time of the simulation are set. Finally, a step size is specified to store the results of the simulation at these time steps.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"tStart = 0.0\ntStep = 0.01\ntStop = 5.0\ntSave = tStart:tStep:tStop","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"0.0:0.01:5.0","category":"page"},{"location":"examples/simple_hybrid_CS/#ReferenceFMU","page":"Simple CS-NeuralFMU","title":"ReferenceFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"In the next lines of code the FMU of the referenceFMU model is loaded from FMIZoo.jl and the information about the FMU is shown.  ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"referenceFMU = fmiLoad(\"SpringPendulumExtForce1D\", \"Dymola\", \"2022x\")\nfmiInfo(referenceFMU)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringPendulumExtForce1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{df5ebe46-3c86-42a5-a68a-7d008395a7a3}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:33Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t0\n\tInputs:\t\t\t\t1\n\t\t352321536 [\"extForce\"]\n\tOutputs:\t\t\t2\n\t\t335544320 [\"accSensor.v\", \"der(accSensor.flange.s)\", \"v\", \"der(speedSensor.flange.s)\", \"speedSensor.v\"]\n\t\t335544321 [\"der(accSensor.v)\", \"a\", \"accSensor.a\"]\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringPendulumExtForce1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringPendulumExtForce1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"In the next steps the parameters are defined. The first parameter is the initial position of the mass, which is initilized with 13𝑚. The second parameter is the initial velocity of the mass, which is initilized with 0fracms. The FMU hase two states: The first state is the position of the mass and the second state is the velocity. In the function fmiSimulate() the referenceFMU is simulated, still specifying the start and end time, the parameters and which variables are recorded. After the simulation is finished the result of the referenceFMU can be plotted. This plot also serves as a reference for the later CS-NeuralFMU model.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"param = Dict(\"mass_s0\" => 1.3, \"mass.v\" => 0.0)   # increase amplitude, invert phase\nvrs = [\"mass.s\", \"mass.v\", \"mass.a\"]\nreferenceSimData = fmiSimulate(referenceFMU, (tStart, tStop); parameters=param, recordValues=vrs, saveat=tSave)\nfmiPlot(referenceSimData)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"\u001b[34mSimulating CS-FMU ...   0%|█                             |  ETA: N/A\u001b[39m\n\n\u001b[34mSimulating CS-FMU ... 100%|██████████████████████████████| Time: 0:00:02\u001b[39m","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"The data from the simulation of the referenceFMU, are divided into position, velocity and acceleration data. The data for the acceleration will be needed later. ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"posReference = fmi2GetSolutionValue(referenceSimData, vrs[1])\nvelReference = fmi2GetSolutionValue(referenceSimData, vrs[2])\naccReference = fmi2GetSolutionValue(referenceSimData, vrs[3])","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"501-element Vector{Float64}:\n -1.9999999999999996\n -1.9988827275812904\n -1.9958127258179004\n -1.9907908533763607\n -1.9837918439669844\n -1.9748258342855118\n -1.963890162864621\n -1.9510089134488018\n -1.9361810148909009\n -1.9194099484303728\n -1.9007374108186537\n -1.8801634598739092\n -1.8576990114645708\n  ⋮\n  1.9971927754348462\n  2.0126501310664713\n  2.026070116129912\n  2.037424725618772\n  2.0467236772128947\n  2.0541004250985972\n  2.0594240680173828\n  2.062679095787284\n  2.0638499982263325\n  2.0629212651525553\n  2.059877386383986\n  2.0548550901379925","category":"page"},{"location":"examples/simple_hybrid_CS/#DefaultFMU","page":"Simple CS-NeuralFMU","title":"DefaultFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"The following is a renaming for the referenceFMU to defaultFMU. The previous initial position of the mass is now set to the default position of the defaultFMU. The initial position of the mass is initilized with 05𝑚 and initial velocity of the mass is initialized with 0fracms.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"defaultFMU = referenceFMU\nparam = Dict(\"mass_s0\" => 0.5, \"mass.v\" => 0.0)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Dict{String, Float64} with 2 entries:\n  \"mass_s0\" => 0.5\n  \"mass.v\"  => 0.0","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"The following simulate and plot the defaultFMU just like the referenceFMU. The differences between both systems can be clearly seen from the plots. In the plots for the defaultFMU you can see that other oscillations occur due to the different starting positions. On the one hand the oscillation of the defaultFMU starts in the opposite direction of the referenceFMU and on the other hand the graphs for the velocity and acceleration differ clearly in the amplitude. In the following we try to learn the initial shift of the position so that the graphs for the acceleration of both graphs match.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"defaultSimData = fmiSimulate(defaultFMU, (tStart, tStop); parameters=param, recordValues=vrs, saveat=tSave)\nfmiPlot(defaultSimData)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"The data from the simualtion of the defaultFMU, are divided into position, velocity and acceleration data. The data for the acceleration will be needed later.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"posDefault = fmi2GetSolutionValue(defaultSimData, vrs[1])\nvelDefault = fmi2GetSolutionValue(defaultSimData, vrs[2])\naccDefault = fmi2GetSolutionValue(defaultSimData, vrs[3])","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"501-element Vector{Float64}:\n  6.0\n  5.996872980925033\n  5.987824566254761\n  5.9728274953129645\n  5.95187583433241\n  5.9249872805026715\n  5.892169834645022\n  5.853465119227542\n  5.808892969264781\n  5.75851573503067\n  5.702370188387734\n  5.640527685538739\n  5.573049035471661\n  ⋮\n -5.842615646003006\n -5.884869953422783\n -5.921224800662572\n -5.9516502108284985\n -5.976144547672481\n -5.994659284032171\n -6.007174453690571\n -6.013675684067705\n -6.014154196220591\n -6.008606804843264\n -5.997055285530499\n -5.979508813705998","category":"page"},{"location":"examples/simple_hybrid_CS/#CS-NeuralFMU","page":"Simple CS-NeuralFMU","title":"CS-NeuralFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"In this section, the defaultFMU is inserted into a CS-NeuralFMU architecture. It has the goal to learn the initial state of the referenceFMU.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"For the external force, a simple function is implemented that always returns a force of 0N at each time point. Also, all other functions and implementations would be possible here. Only for simplification reasons the function was chosen so simply.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"function extForce(t)\n    return [0.0]\nend ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"extForce (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_CS/#Loss-function","page":"Simple CS-NeuralFMU","title":"Loss function","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"In order to train our model, a loss function must be implemented. The solver of the NeuralFMU can calculate the gradient of the loss function. The gradient descent is needed to adjust the weights in the neural network so that the sum of the error is reduced and the model becomes more accurate.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"The loss function in this implementation consists of the mean squared error (mse) from the acceleration data of the referenceFMU simulation (accReference) and the acceleration data of the network (accNet).","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"e_mse = frac1n sumlimits_i=0^n (accReferencei - accNeti)^2","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# loss function for training\nfunction lossSum(p)\n    solution = csNeuralFMU(extForce, tStep, (tStart, tStop); p=p) # saveat=tSave\n\n    accNet = fmi2GetSolutionValue(solution, 2; isIndex=true)\n    \n    FMIFlux.Losses.mse(accReference, accNet)\nend","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"lossSum (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_CS/#Callback","page":"Simple CS-NeuralFMU","title":"Callback","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"To output the loss in certain time intervals, a callback is implemented as a function in the following. Here a counter is incremented, every twentieth pass the loss function is called and the average error is printed out.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# callback function for training\nglobal counter = 0\nfunction callb(p)\n    global counter += 1\n\n    if counter % 25 == 1\n        avgLoss = lossSum(p[1])\n        @info \"Loss [$counter]: $(round(avgLoss, digits=5))\"\n    end\nend","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"callb (generic function with 1 method)","category":"page"},{"location":"examples/simple_hybrid_CS/#Structure-of-the-CS-NeuralFMU","page":"Simple CS-NeuralFMU","title":"Structure of the CS-NeuralFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"In the following, the topology of the CS-NeuralFMU is constructed. It consists of an input layer, which then leads into the defaultFMU model. The CS-FMU computes the outputs for the given system state and time step. After the defaultFMU follows a dense layer, which has exactly as many inputs as the model has outputs. The output of this layer consists of 16 output nodes and a tanh activation function. The next layer has 16 input and output nodes with the same activation function. The last layer is again a dense layer with 16 input nodes and the number of model outputs as output nodes. Here, it is important that no tanh-activation function follows, because otherwise the pendulums state values would be limited to the interval -11.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# check outputs\noutputs = defaultFMU.modelDescription.outputValueReferences \nnumOutputs = length(outputs)\ndisplay(outputs)\n\n# check inputs\ninputs = defaultFMU.modelDescription.inputValueReferences \nnumInputs = length(inputs)\ndisplay(inputs)\n\n# NeuralFMU setup\nnet = Chain(u -> defaultFMU(;u_refs=inputs, u=u, y_refs=outputs),\n            Dense(numOutputs, 16, tanh),\n            Dense(16, 16, tanh),\n            Dense(16, numOutputs))","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"2-element Vector{UInt32}:\n 0x14000000\n 0x14000001\n\n\n\n1-element Vector{UInt32}:\n 0x15000000\n\n\n\n\n\nChain(\n  var\"#1#2\"(),\n  Dense(2 => 16, tanh),                 \u001b[90m# 48 parameters\u001b[39m\n  Dense(16 => 16, tanh),                \u001b[90m# 272 parameters\u001b[39m\n  Dense(16 => 2),                       \u001b[90m# 34 parameters\u001b[39m\n) \u001b[90m                  # Total: 6 arrays, \u001b[39m354 parameters, 1.758 KiB.","category":"page"},{"location":"examples/simple_hybrid_CS/#Definition-of-the-CS-NeuralFMU","page":"Simple CS-NeuralFMU","title":"Definition of the CS-NeuralFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"The instantiation of the CS-NeuralFMU is done as a one-liner. The FMU defaultFMU, the structure of the network net, start tStart and end time tStop, and the time steps tSave for saving are specified.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"csNeuralFMU = CS_NeuralFMU(defaultFMU, net, (tStart, tStop));","category":"page"},{"location":"examples/simple_hybrid_CS/#Plot-before-training","page":"Simple CS-NeuralFMU","title":"Plot before training","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Here the state trajectory of the extForceFMU is recorded. Doesn't really look like a pendulum yet, but the system is random initialized by default. In the plots later on, the effect of learning can be seen.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"solutionBefore = csNeuralFMU(extForce, tStep, (tStart, tStop)) # ; saveat=tSave\naccNeuralFMU = fmi2GetSolutionValue(solutionBefore, 1; isIndex=true)\nPlots.plot(tSave, accNeuralFMU, label=\"acc CS-NeuralFMU\", linewidth=2)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_CS/#Training-of-the-CS-NeuralFMU","page":"Simple CS-NeuralFMU","title":"Training of the CS-NeuralFMU","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"For the training of the CS-NeuralFMU the parameters are extracted. The known Adam optimizer for minimizing the gradient descent is used as further passing parameters. In addition, the previously defined loss and callback function, as well as the number of epochs are passed.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# train\nparamsNet = FMIFlux.params(csNeuralFMU)\n\noptim = Adam()\nFMIFlux.train!(lossSum, csNeuralFMU, Iterators.repeated((), 250), optim; cb=()->callb(paramsNet))","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [1]: 2.37052\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [26]: 0.30045\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [51]: 0.04673\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [76]: 0.03035\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [101]: 0.0182\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [126]: 0.01046\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [151]: 0.00573\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [176]: 0.00305\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [201]: 0.00164\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mLoss [226]: 0.00092","category":"page"},{"location":"examples/simple_hybrid_CS/#Comparison-of-the-plots","page":"Simple CS-NeuralFMU","title":"Comparison of the plots","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Here three plots are compared with each other and only the acceleration of the mass is considered. The first plot presents the defaultFMU, the second the referenceFMU and the third plot the result after training the CS-NeuralFMU. ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"# plot results mass.a\nsolutionAfter = csNeuralFMU(extForce, tStep, (tStart, tStop)) # saveat=tSave, p=paramsNet[1]\n\nfig = Plots.plot(xlabel=\"t [s]\", ylabel=\"mass acceleration [m/s^2]\", linewidth=2,\n                 xtickfontsize=12, ytickfontsize=12,\n                 xguidefontsize=12, yguidefontsize=12,\n                 legendfontsize=8, legend=:topright)\n\naccNeuralFMU = fmi2GetSolutionValue(solutionAfter, 2; isIndex=true)\n\nPlots.plot!(fig, tSave, accDefault, label=\"defaultFMU\", linewidth=2)\nPlots.plot!(fig, tSave, accReference, label=\"referenceFMU\", linewidth=2)\nPlots.plot!(fig, tSave, accNeuralFMU, label=\"CS-NeuralFMU (1000 eps.)\", linewidth=2)\nfig ","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"(Image: svg)","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Finally, the FMU is cleaned-up.","category":"page"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"fmiUnload(defaultFMU)","category":"page"},{"location":"examples/simple_hybrid_CS/#Summary","page":"Simple CS-NeuralFMU","title":"Summary","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"Based on the plots, it can be clearly seen that the CS-NeuralFMU model is able to learn the shift of the initial position. Even after only 1000 training steps, the curves overlap very much, so no further training with more runs is needed.","category":"page"},{"location":"examples/simple_hybrid_CS/#Source","page":"Simple CS-NeuralFMU","title":"Source","text":"","category":"section"},{"location":"examples/simple_hybrid_CS/","page":"Simple CS-NeuralFMU","title":"Simple CS-NeuralFMU","text":"[1] Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. NeuralFMU: towards structural integration of FMUs into neural networks. Martin Sjölund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, Linköping, Sweden, September 20-24, 2021. Linköping University Electronic Press, Linköping (Linköping Electronic Conference Proceedings ; 181), 297-306. DOI: 10.3384/ecp21181297","category":"page"},{"location":"examples/modelica_conference_2021/#ME-NeuralFMU-from-the-Modelica-Conference-2021","page":"Modelica Conference 2021","title":"ME-NeuralFMU from the Modelica Conference 2021","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Tutorial by Johannes Stoljar, Tobias Thummerer","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Last edit: 29.03.2023","category":"page"},{"location":"examples/modelica_conference_2021/#License","page":"Modelica Conference 2021","title":"License","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons, Johannes Stoljar\n# Licensed under the MIT license. \n# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details.","category":"page"},{"location":"examples/modelica_conference_2021/#Motivation","page":"Modelica Conference 2021","title":"Motivation","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The Julia Package FMIFlux.jl is motivated by the application of hybrid modeling. This package enables the user to integrate his simulation model between neural networks (NeuralFMU). For this, the simulation model must be exported as FMU (functional mock-up unit), which corresponds to a widely used standard. The big advantage of hybrid modeling with artificial neural networks is, that the effects that are difficult to model (because they might be unknown) can be easily learned by the neural networks. For this purpose, the NeuralFMU is trained with measurement data containing the not modeled physical effect. The final product is a simulation model including the originally not modeled effects. Another big advantage of the NeuralFMU is that it works with little data, because the FMU already contains the characteristic functionality of the simulation and only the missing effects are added.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"NeuralFMUs do not need to be as easy as in this example. Basically a NeuralFMU can combine different ANN topologies that manipulate any FMU-input (system state, system inputs, time) and any FMU-output (system state derivative, system outputs, other system variables). However, for this example a NeuralFMU topology as shown in the following picture is used.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: NeuralFMU.svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"NeuralFMU (ME) from [1].","category":"page"},{"location":"examples/modelica_conference_2021/#Introduction-to-the-example","page":"Modelica Conference 2021","title":"Introduction to the example","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In this example, simplified modeling of a one-dimensional spring pendulum (without friction) is compared to a model of the same system that includes a nonlinear friction model. The FMU with the simplified model will be named simpleFMU in the following and the model with the friction will be named realFMU. At the beginning, the actual state of both simulations is shown, whereby clear deviations can be seen in the graphs. In addition, the initial states are changed for both models and these graphs are also contrasted, and the differences can again be clearly seen. The realFMU serves as a reference graph. The simpleFMU is then integrated into a NeuralFMU architecture and a training of the entire network is performed. After the training the final state is compared again to the realFMU. It can be clearly seen that by using the NeuralFMU, learning of the friction process has taken place.  ","category":"page"},{"location":"examples/modelica_conference_2021/#Target-group","page":"Modelica Conference 2021","title":"Target group","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The example is primarily intended for users who work in the field of first principle and/or hybrid modeling and are further interested in hybrid model building. The example wants to show how simple it is to combine FMUs with machine learning and to illustrate the advantages of this approach.","category":"page"},{"location":"examples/modelica_conference_2021/#Other-formats","page":"Modelica Conference 2021","title":"Other formats","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Besides, this Jupyter Notebook there is also a Julia file with the same name, which contains only the code cells. For the documentation there is a Markdown file corresponding to the notebook.  ","category":"page"},{"location":"examples/modelica_conference_2021/#Getting-started","page":"Modelica Conference 2021","title":"Getting started","text":"","category":"section"},{"location":"examples/modelica_conference_2021/#Installation-prerequisites","page":"Modelica Conference 2021","title":"Installation prerequisites","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":" Description Command\n1. Enter Package Manager via ]\n2. Install FMI via add FMI\n3. Install FMIFlux via add FMIFlux\n4. Install FMIZoo via add FMIZoo\n5. Install DifferentialEquations via add DifferentialEquations\n6. Install Plots via add Plots\n7. Install Random via add Random","category":"page"},{"location":"examples/modelica_conference_2021/#Code-section","page":"Modelica Conference 2021","title":"Code section","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"To run the example, the previously installed packages must be included. ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# imports\nusing FMI\nusing FMIFlux\nusing FMIFlux.Flux\nusing FMIZoo\nusing DifferentialEquations: Tsit5\nimport Plots\n\n# set seed\nimport Random\nRandom.seed!(1234);","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mError requiring `Enzyme` from `LinearSolve`\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m  exception =\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   LoadError: ArgumentError: Package LinearSolve does not have Enzyme in its dependencies:\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - You may have a partially installed environment. Try `Pkg.instantiate()`\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     to ensure all packages in the environment are installed.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - Or, if you have LinearSolve checked out for development and have\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     added Enzyme as a dependency but haven't updated your primary\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     environment's manifest file, try `Pkg.resolve()`.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   - Otherwise you may need to report an issue with LinearSolve\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   Stacktrace:\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1167\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [2] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:223\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [3] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1144\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [4] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90m_path\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mBase.jl:419\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [5] \u001b[0m\u001b[1minclude\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mx\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4mLinearSolve.jl:1\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mRequires.jl:40\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [7] top-level scope\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4minit.jl:16\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [8] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mboot.jl:368\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m     [9] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\src\\\u001b[39m\u001b[90m\u001b[4mLinearSolve.jl:1\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [10] \u001b[0m\u001b[1m(::LinearSolve.var\"#88#97\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:101\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [11] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m\u001b[4mtiming.jl:382\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [12] \u001b[0m\u001b[1merr\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mAny, \u001b[90mlistener\u001b[39m::\u001b[0mModule, \u001b[90mmodname\u001b[39m::\u001b[0mString, \u001b[90mfile\u001b[39m::\u001b[0mString, \u001b[90mline\u001b[39m::\u001b[0mAny\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:47\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [13] \u001b[0m\u001b[1m(::LinearSolve.var\"#87#96\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:100\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [14] \u001b[0m\u001b[1mwithpath\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mAny, \u001b[90mpath\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:37\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [15] \u001b[0m\u001b[1m(::LinearSolve.var\"#86#95\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[35mLinearSolve\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:99\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [16] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [17] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [18] \u001b[0m\u001b[1mforeach\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mtypeof(Base.invokelatest), \u001b[90mitr\u001b[39m::\u001b[0mVector\u001b[90m{Function}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mabstractarray.jl:2774\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [19] \u001b[0m\u001b[1mloadpkg\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[36mRequires\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\\u001b[39m\u001b[90m\u001b[4mrequire.jl:27\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [20] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [21] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [22] \u001b[0m\u001b[1mrun_package_callbacks\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmodkey\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:869\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [23] \u001b[0m\u001b[1m_tryrequire_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmodkey\u001b[39m::\u001b[0mBase.PkgId, \u001b[90mpath\u001b[39m::\u001b[0mString, \u001b[90msourcepath\u001b[39m::\u001b[0mString, \u001b[90mdepmods\u001b[39m::\u001b[0mVector\u001b[90m{Any}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:944\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [24] \u001b[0m\u001b[1m_require_search_from_serialized\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId, \u001b[90msourcepath\u001b[39m::\u001b[0mString, \u001b[90mbuild_id\u001b[39m::\u001b[0mUInt64\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1028\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [25] \u001b[0m\u001b[1m_require\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mpkg\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1315\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [26] \u001b[0m\u001b[1m_require_prelocked\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90muuidkey\u001b[39m::\u001b[0mBase.PkgId\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1200\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [27] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1180\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [28] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mlock.jl:223\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [29] \u001b[0m\u001b[1mrequire\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90minto\u001b[39m::\u001b[0mModule, \u001b[90mmod\u001b[39m::\u001b[0mSymbol\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1144\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [30] \u001b[0m\u001b[1meval\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mboot.jl:368\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [31] \u001b[0m\u001b[1minclude_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mmapexpr\u001b[39m::\u001b[0mtypeof(REPL.softscope), \u001b[90mmod\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mloading.jl:1428\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [32] \u001b[0m\u001b[1msoftscope_include_string\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mm\u001b[39m::\u001b[0mModule, \u001b[90mcode\u001b[39m::\u001b[0mString, \u001b[90mfilename\u001b[39m::\u001b[0mString\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[32mSoftGlobalScope\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\SoftGlobalScope\\u4UzH\\src\\\u001b[39m\u001b[90m\u001b[4mSoftGlobalScope.jl:65\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [33] \u001b[0m\u001b[1mexecute_request\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket, \u001b[90mmsg\u001b[39m::\u001b[0mIJulia.Msg\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\IJulia\\Vo51o\\src\\\u001b[39m\u001b[90m\u001b[4mexecute_request.jl:67\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [34] \u001b[0m\u001b[1m#invokelatest#2\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:729\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [35] \u001b[0m\u001b[1minvokelatest\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[90m.\\\u001b[39m\u001b[90m\u001b[4messentials.jl:726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [36] \u001b[0m\u001b[1meventloop\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90msocket\u001b[39m::\u001b[0mZMQ.Socket\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90mC:\\Users\\runneradmin\\.julia\\packages\\IJulia\\Vo51o\\src\\\u001b[39m\u001b[90m\u001b[4meventloop.jl:8\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    [37] \u001b[0m\u001b[1m(::IJulia.var\"#15#18\")\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   \u001b[90m    @ \u001b[39m\u001b[33mIJulia\u001b[39m \u001b[90m.\\\u001b[39m\u001b[90m\u001b[4mtask.jl:484\u001b[24m\u001b[39m\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m   in expression starting at C:\\Users\\runneradmin\\.julia\\packages\\LinearSolve\\qCLK7\\ext\\LinearSolveEnzymeExt.jl:1\n\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Requires C:\\Users\\runneradmin\\.julia\\packages\\Requires\\Z8rfN\\src\\require.jl:51\u001b[39m","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"After importing the packages, the path to the Functional Mock-up Units (FMUs) is set. The exported FMU is a model meeting the Functional Mock-up Interface (FMI) Standard. The FMI is a free standard (fmi-standard.org) that defines a container and an interface to exchange dynamic models using a combination of XML files, binaries and C code zipped into a single file. ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The object-orientated structure of the SpringPendulum1D (simpleFMU) can be seen in the following graphic and corresponds to a simple modeling.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In contrast, the model SpringFrictionPendulum1D (realFMU) is somewhat more accurate, because it includes a friction component. ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Next, the start time and end time of the simulation are set. Finally, a step size is specified to store the results of the simulation at these time steps.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"tStart = 0.0\ntStep = 0.01\ntStop = 4.0\ntSave = collect(tStart:tStep:tStop)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"401-element Vector{Float64}:\n 0.0\n 0.01\n 0.02\n 0.03\n 0.04\n 0.05\n 0.06\n 0.07\n 0.08\n 0.09\n 0.1\n 0.11\n 0.12\n ⋮\n 3.89\n 3.9\n 3.91\n 3.92\n 3.93\n 3.94\n 3.95\n 3.96\n 3.97\n 3.98\n 3.99\n 4.0","category":"page"},{"location":"examples/modelica_conference_2021/#RealFMU","page":"Modelica Conference 2021","title":"RealFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the next lines of code the FMU of the realFMU model from FMIZoo.jl is loaded and the information about the FMU is shown.  ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"realFMU = fmiLoad(\"SpringFrictionPendulum1D\", \"Dymola\", \"2022x\")\nfmiInfo(realFMU)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringFrictionPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{2e178ad3-5e9b-48ec-a7b2-baa5669efc0c}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:12Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t24\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\", \"mass.v_relfric\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringFrictionPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the following two subsections, the realFMU is simulated twice with different initial states to show what effect the choice of initial states has.","category":"page"},{"location":"examples/modelica_conference_2021/#Default-initial-states","page":"Modelica Conference 2021","title":"Default initial states","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the next steps the parameters are defined. The first parameter is the initial position of the mass, which is initialized with 05m, the second parameter is the initial velocity, which is initialized with 0fracms. In the function fmiSimulate() the realFMU is simulated, still specifying the start and end time, the parameters and which variables are recorded. After the simulation is finished the result of the realFMU can be plotted. This plot also serves as a reference for the other model (simpleFMU). The extracted data will still be needed later on.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"initStates = [\"s0\", \"v0\"]\nx₀ = [0.5, 0.0]\nparams = Dict(zip(initStates, x₀))\nvrs = [\"mass.s\", \"mass.v\", \"mass.a\", \"mass.f\"]\n\nrealSimData = fmiSimulate(realFMU, (tStart, tStop); parameters=params, recordValues=vrs, saveat=tSave)\nposReal = fmi2GetSolutionValue(realSimData, \"mass.s\")\nvelReal = fmi2GetSolutionValue(realSimData, \"mass.v\")\nfmiPlot(realSimData)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"\u001b[34mSimulating CS-FMU ...   0%|█                             |  ETA: N/A\u001b[39m\n\n\u001b[34mSimulating CS-FMU ... 100%|██████████████████████████████| Time: 0:00:02\u001b[39m","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/#Define-functions","page":"Modelica Conference 2021","title":"Define functions","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The structure of the previous code section is used more often in the further sections, so for clarity the previously explained code section for setting the paramters and simulating are combined into one function simulate().","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function simulate(FMU, initStates, x₀, variables, tStart, tStop, tSave)\n    params = Dict(zip(initStates, x₀))\n    return fmiSimulate(FMU, (tStart, tStop); parameters=params, recordValues=variables, saveat=tSave)\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"simulate (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Also, a function to extract the position and velocity from the simulation data is created.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function extractPosVel(simData)\n    if simData.states === nothing\n        posData = fmi2GetSolutionValue(simData, \"mass.s\")\n        velData = fmi2GetSolutionValue(simData, \"mass.v\")\n    else\n        posData = fmi2GetSolutionState(simData, 1; isIndex=true)\n        velData = fmi2GetSolutionState(simData, 2; isIndex=true)\n    end\n\n    return posData, velData\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"extractPosVel (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/#Modified-initial-states","page":"Modelica Conference 2021","title":"Modified initial states","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In contrast to the previous section, other initial states are selected. The position of the mass is initialized with 10m and the velocity is initialized with -15fracms. With the modified initial states the realFMU is simulated and a graph is generated.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"xMod₀ = [1.0, -1.5]\nrealSimDataMod = simulate(realFMU, initStates, xMod₀, vrs, tStart, tStop, tSave)\nfmiPlot(realSimDataMod)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"After the plots are created, the FMU is unloaded.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"fmiUnload(realFMU)","category":"page"},{"location":"examples/modelica_conference_2021/#SimpleFMU","page":"Modelica Conference 2021","title":"SimpleFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The following lines load the simpleFMU from FMIZoo.jl. ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"simpleFMU = fmiLoad(\"SpringPendulum1D\", \"Dymola\", \"2022x\")\nfmiInfo(simpleFMU)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"#################### Begin information for FMU ####################\n\tModel name:\t\t\tSpringPendulum1D\n\tFMI-Version:\t\t\t2.0\n\tGUID:\t\t\t\t{fc15d8c4-758b-48e6-b00e-5bf47b8b14e5}\n\tGeneration tool:\t\tDymola Version 2022x (64-bit), 2021-10-08\n\tGeneration time:\t\t2022-05-19T06:54:23Z\n\tVar. naming conv.:\t\tstructured\n\tEvent indicators:\t\t0\n\tInputs:\t\t\t\t0\n\tOutputs:\t\t\t0\n\tStates:\t\t\t\t2\n\t\t33554432 [\"mass.s\"]\n\t\t33554433 [\"mass.v\"]\n\tSupports Co-Simulation:\t\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n\t\tVar. com. steps:\ttrue\n\t\tInput interpol.:\ttrue\n\t\tMax order out. der.:\t1\n\tSupports Model-Exchange:\ttrue\n\t\tModel identifier:\tSpringPendulum1D\n\t\tGet/Set State:\t\ttrue\n\t\tSerialize State:\ttrue\n\t\tDir. Derivatives:\ttrue\n##################### End information for FMU #####################","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The differences between both systems can be clearly seen from the plots in the subchapters. In the plot for the realFMU it can be seen that the oscillation continues to decrease due to the effect of the friction. If you simulate long enough, the oscillation would come to a standstill in a certain time. The oscillation in the simpleFMU behaves differently, since the friction was not taken into account here. The oscillation in this model would continue to infinity with the same oscillation amplitude. From this observation the desire of an improvement of this model arises.     ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the following two subsections, the simpleFMU is simulated twice with different initial states to show what effect the choice of initial states has.","category":"page"},{"location":"examples/modelica_conference_2021/#Default-initial-states-2","page":"Modelica Conference 2021","title":"Default initial states","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Similar to the simulation of the realFMU, the simpleFMU is also simulated with the default values for the position and velocity of the mass and then plotted. There is one difference, however, as another state representing a fixed displacement is set. In addition, the last variable is also removed from the variables to be plotted.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"initStates = [\"mass_s0\", \"mass_v0\", \"fixed.s0\"]\ndisplacement = 0.1\nxSimple₀ = vcat(x₀, displacement)\nvrs = vrs[1:end-1]\n\nsimpleSimData = simulate(simpleFMU, initStates, xSimple₀, vrs, tStart, tStop, tSave)\nfmiPlot(simpleSimData)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/#Modified-initial-states-2","page":"Modelica Conference 2021","title":"Modified initial states","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The same values for the initial states are used for this simulation as for the simulation from the realFMU with the modified initial states.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"xSimpleMod₀ = vcat(xMod₀, displacement)\n\nsimpleSimDataMod = simulate(simpleFMU, initStates, xSimpleMod₀, vrs, tStart, tStop, tSave)\nfmiPlot(simpleSimDataMod)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/#NeuralFMU","page":"Modelica Conference 2021","title":"NeuralFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/#Loss-function","page":"Modelica Conference 2021","title":"Loss function","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In order to train our model, a loss function must be implemented. The solver of the NeuralFMU can calculate the gradient of the loss function. The gradient descent is needed to adjust the weights in the neural network so that the sum of the error is reduced and the model becomes more accurate.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The error function in this implementation consists of the mean of the mean squared errors. The first part of the addition is the deviation of the position and the second part is the deviation of the velocity. The mean squared error (mse) for the position consists from the real position of the realFMU simulation (posReal) and the position data of the network (posNet). The mean squared error for the velocity consists of the real velocity of the realFMU simulation (velReal) and the velocity data of the network (velNet). $ e{loss} = \\frac{1}{2} \\Bigl[ \\frac{1}{n} \\sum\\limits{i=0}^n (posReal[i] - posNet[i])^2 + \\frac{1}{n} \\sum\\limits_{i=0}^n (velReal[i] - velNet[i])^2 \\Bigr]$","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# loss function for training\nfunction lossSum(p)\n    global x₀\n    solution = neuralFMU(x₀; p=p)\n\n    posNet, velNet = extractPosVel(solution)\n\n    (FMIFlux.Losses.mse(posReal, posNet) + FMIFlux.Losses.mse(velReal, velNet)) / 2.0\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"lossSum (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/#Callback","page":"Modelica Conference 2021","title":"Callback","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"To output the loss in certain time intervals, a callback is implemented as a function in the following. Here a counter is incremented, every fiftieth pass the loss function is called and the average error is printed out. Also, the parameters for the velocity in the first layer are kept to a fixed value.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# callback function for training\nglobal counter = 0\nfunction callb(p)\n    global counter\n    counter += 1\n\n    # freeze first layer parameters (2,4,6) for velocity -> (static) direct feed trough for velocity\n    # parameters for position (1,3,5) are learned\n    p[1][2] = 0.0\n    p[1][4] = 1.0\n    p[1][6] = 0.0\n\n    if counter % 50 == 1\n        avgLoss = lossSum(p[1])\n        @info \"  Loss [$counter]: $(round(avgLoss, digits=5))\n        Avg displacement in data: $(round(sqrt(avgLoss), digits=5))\n        Weight/Scale: $(paramsNet[1][1])   Bias/Offset: $(paramsNet[1][5])\"\n    end\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"callb (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/#Functions-for-plotting","page":"Modelica Conference 2021","title":"Functions for plotting","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In this section some important functions for plotting are defined. The function generate_figure() creates a new figure object and sets some attributes.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function generate_figure(title, xLabel, yLabel, xlim=:auto)\n    Plots.plot(\n        title=title, xlabel=xLabel, ylabel=yLabel, linewidth=2,\n        xtickfontsize=12, ytickfontsize=12, xguidefontsize=12, yguidefontsize=12,\n        legendfontsize=12, legend=:topright, xlim=xlim)\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"generate_figure (generic function with 2 methods)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the following function, the data of the realFMU, simpleFMU and neuralFMU are summarized and displayed in a graph.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function plot_results(title, xLabel, yLabel, interval, realData, simpleData, neuralData)\n    linestyles = [:dot, :solid]\n    \n    fig = generate_figure(title, xLabel, yLabel)\n    Plots.plot!(fig, interval, simpleData, label=\"SimpleFMU\", linewidth=2)\n    Plots.plot!(fig, interval, realData, label=\"Reference\", linewidth=2)\n    for i in 1:length(neuralData)\n        Plots.plot!(fig, neuralData[i][1], neuralData[i][2], label=\"NeuralFMU ($(i*2500))\", \n                    linewidth=2, linestyle=linestyles[i], linecolor=:green)\n    end\n    Plots.display(fig)\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"plot_results (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"This is the superordinate function, which at the beginning extracts the position and velocity from the simulation data (realSimData, realSimDataMod, simpleSimData,..., solutionAfterMod). Four graphs are then generated, each comparing the corresponding data from the realFMU, simpleFMU, and neuralFMU. The comparison is made with the simulation data from the simulation with the default and modified initial states. According to the data, the designation of the title and the naming of the axes is adapted.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function plot_all_results(realSimData, realSimDataMod, simpleSimData, \n        simpleSimDataMod, solutionAfter, solutionAfterMod)    \n    # collect all data\n    posReal, velReal = extractPosVel(realSimData)\n    posRealMod, velRealMod = extractPosVel(realSimDataMod)\n    posSimple, velSimple = extractPosVel(simpleSimData)\n    posSimpleMod, velSimpleMod = extractPosVel(simpleSimDataMod)\n    \n    run = length(solutionAfter)\n    \n    posNeural, velNeural = [], []\n    posNeuralMod, velNeuralMod = [], []\n    for i in 1:run\n        dataNeural = extractPosVel(solutionAfter[i])\n        time = fmi2GetSolutionTime(solutionAfter[i])\n\n        push!(posNeural, (time, dataNeural[1]))\n        push!(velNeural, (time, dataNeural[2]))\n        \n        dataNeuralMod = extractPosVel(solutionAfterMod[i])\n        time = fmi2GetSolutionTime(solutionAfterMod[i])\n        push!(posNeuralMod, (time, dataNeuralMod[1]))\n        push!(velNeuralMod, (time, dataNeuralMod[2]))\n    end\n         \n    # plot results s (default initial states)\n    xLabel=\"t [s]\"\n    yLabel=\"mass position [m]\"\n    title = \"Default: Mass position after Run: $(run)\"\n    plot_results(title, xLabel, yLabel, tSave, posReal, posSimple, posNeural)\n\n    # plot results s (modified initial states)\n    title = \"Modified: Mass position after Run: $(run)\"\n    plot_results(title, xLabel, yLabel, tSave, posRealMod, posSimpleMod, posNeuralMod)\n\n    # plot results v (default initial states)\n    yLabel=\"mass velocity [m/s]\"\n    title = \"Default: Mass velocity after Run: $(run)\"\n    plot_results(title, xLabel, yLabel, tSave, velReal, velSimple, velNeural)\n\n    # plot results v (modified initial states)    \n    title = \"Modified: Mass velocity after Run: $(run)\"\n    plot_results(title, xLabel, yLabel, tSave, velRealMod, velSimpleMod, velNeuralMod)\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"plot_all_results (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The function plot_friction_model() compares the friction model of the realFMU, simpleFMU and neuralFMU. For this, the velocity and force from the simulation data of the realFMU is needed. The force data is calculated with the extracted last layer of the neuralFMU to the real velocity in line 9 by iterating over the vector velReal. In the next rows, the velocity and force data (if available) for each of the three FMUs are combined into a matrix. The first row of the matrix corresponds to the later x-axis and here the velocity is plotted. The second row corresponds to the y-axis and here the force is plotted. This matrix is sorted and plotted by the first entries (velocity) with the function sortperm(). The graph with at least three graphs is plotted in line 33. As output this function has the forces of the neuralFMU.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function plot_friction_model(realSimData, netBottom, forces)    \n    linestyles = [:dot, :solid]\n    \n    velReal = fmi2GetSolutionValue(realSimData, \"mass.v\")\n    forceReal = fmi2GetSolutionValue(realSimData, \"mass.f\")\n\n    push!(forces, zeros(length(velReal)))\n    for i in 1:length(velReal)\n        forces[end][i] = -netBottom([velReal[i], 0.0])[2]\n    end\n\n    run = length(forces) \n    \n    fig = generate_figure(\"Friction model $(run)\", \"v [m/s]\", \"friction force [N]\", (-1.25, 1.25))\n\n    fricSimple = hcat(velReal, zeros(length(velReal)))\n    fricSimple[sortperm(fricSimple[:, 1]), :]\n    Plots.plot!(fig, fricSimple[:,1], fricSimple[:,2], label=\"SimpleFMU\", linewidth=2)\n\n    fricReal = hcat(velReal, forceReal)\n    fricReal[sortperm(fricReal[:, 1]), :]\n    Plots.plot!(fig, fricReal[:,1], fricReal[:,2], label=\"reference\", linewidth=2)\n\n    for i in 1:run\n        fricNeural = hcat(velReal, forces[i])\n        fricNeural[sortperm(fricNeural[:, 1]), :]\n        Plots.plot!(fig, fricNeural[:,1], fricNeural[:,2], label=\"NeuralFMU ($(i*2500))\", \n                    linewidth=2, linestyle=linestyles[i], linecolor=:green)\n        @info \"Friction model $i mse: $(FMIFlux.Losses.mse(fricNeural[:,2], fricReal[:,2]))\"\n    end\n    flush(stderr)\n\n    Plots.display(fig)\n    \n    return forces   \nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"plot_friction_model (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The following function is used to display the different displacement modells of the realFMU, simpleFMU and neuralFMU. The displacement of the realFMU and simpleFMU is very trivial and is only a constant. The position data of the realFMU is needed to calculate the displacement. The displacement for the neuralFMU is calculated using the first extracted layer of the neural network, subtracting the real position and the displacement of the simpleFMU. Also in this function, the graphs of the three FMUs are compared in a plot.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"function plot_displacement_model(realSimData, netTop, displacements, tSave, displacement)\n    linestyles = [:dot, :solid]\n    \n    posReal = fmi2GetSolutionValue(realSimData, \"mass.s\")\n    \n    push!(displacements, zeros(length(posReal)))\n    for i in 1:length(posReal)\n        displacements[end][i] = netTop([posReal[i], 0.0])[1] - posReal[i] - displacement\n    end\n\n    run = length(displacements)\n    fig = generate_figure(\"Displacement model $(run)\", \"t [s]\", \"displacement [m]\")\n    Plots.plot!(fig, [tSave[1], tSave[end]], [displacement, displacement], label=\"simpleFMU\", linewidth=2)\n    Plots.plot!(fig, [tSave[1], tSave[end]], [0.0, 0.0], label=\"reference\", linewidth=2)\n    for i in 1:run\n        Plots.plot!(fig, tSave, displacements[i], label=\"NeuralFMU ($(i*2500))\", \n                    linewidth=2, linestyle=linestyles[i], linecolor=:green)\n    end\n\n    Plots.display(fig)\n    \n    return displacements\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"plot_displacement_model (generic function with 1 method)","category":"page"},{"location":"examples/modelica_conference_2021/#Structure-of-the-NeuralFMU","page":"Modelica Conference 2021","title":"Structure of the NeuralFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"In the following, the topology of the NeuralFMU is constructed. It consists of a dense layer that has exactly as many inputs and outputs as the model has states numStates (and therefore state derivatives). It also sets the initial weights and offsets for the first dense layer, as well as the activation function, which consists of the identity. An input layer follows, which then leads into the simpleFMU model. The ME-FMU computes the state derivatives for a given system state. Following the simpleFMU is a dense layer that has numStates states. The output of this layer consists of 8 output nodes and a identity activation function. The next layer has 8 input and output nodes with a tanh activation function. The last layer is again a dense layer with 8 input nodes and the number of states as outputs. Here, it is important that no tanh-activation function follows, because otherwise the pendulums state values would be limited to the interval -11.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# NeuralFMU setup\nnumStates = fmiGetNumberOfStates(simpleFMU)\n\n# diagonal matrix \ninitW = zeros(numStates, numStates)\nfor i in 1:numStates\n    initW[i,i] = 1\nend\n\nnet = Chain(Dense(numStates, numStates,  identity),\n            x -> simpleFMU(x=x, dx_refs=:all),\n            Dense(numStates, 8, identity),\n            Dense(8, 8, tanh),\n            Dense(8, numStates))","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Chain(\n  Dense(2 => 2),                        \u001b[90m# 6 parameters\u001b[39m\n  var\"#1#2\"(),\n  Dense(2 => 8),                        \u001b[90m# 24 parameters\u001b[39m\n  Dense(8 => 8, tanh),                  \u001b[90m# 72 parameters\u001b[39m\n  Dense(8 => 2),                        \u001b[90m# 18 parameters\u001b[39m\n) \u001b[90m                  # Total: 8 arrays, \u001b[39m120 parameters, 992 bytes.","category":"page"},{"location":"examples/modelica_conference_2021/#Definition-of-the-NeuralFMU","page":"Modelica Conference 2021","title":"Definition of the NeuralFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The instantiation of the ME-NeuralFMU is done as a one-liner. The FMU (simpleFMU), the structure of the network net, start tStart and end time tStop, the numerical solver Tsit5() and the time steps tSave for saving are specified.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"neuralFMU = ME_NeuralFMU(simpleFMU, net, (tStart, tStop), Tsit5(); saveat=tSave);","category":"page"},{"location":"examples/modelica_conference_2021/#Plot-before-training","page":"Modelica Conference 2021","title":"Plot before training","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Here the state trajectory of the simpleFMU is recorded. Doesn't really look like a pendulum yet, but the system is random initialized by default. In the plots later on, the effect of learning can be seen.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"solutionBefore = neuralFMU(x₀)\nfmiPlot(solutionBefore)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mNo solver keyword detected for NeuralFMU.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mContinuous adjoint method is applied, which requires solving backward in time.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mThis might be not supported by every FMU.\n\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m(This message is only printed once.)\n\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ FMICore C:\\Users\\runneradmin\\.julia\\packages\\FMICore\\7NIyu\\src\\printing.jl:38\u001b[39m","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/#Training-of-the-NeuralFMU","page":"Modelica Conference 2021","title":"Training of the NeuralFMU","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"For the training of the NeuralFMU the parameters are extracted. All parameters of the first layer are set to the absolute value.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"# train\nparamsNet = FMIFlux.params(neuralFMU)\n\nfor i in 1:length(paramsNet[1])\n    if paramsNet[1][i] < 0.0 \n        paramsNet[1][i] = -paramsNet[1][i]\n    end\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The well-known Adam optimizer for minimizing the gradient descent is used as further passing parameters. Additionally, the previously defined loss and callback function as well as a one for the number of epochs are passed. Only one epoch is trained so that the NeuralFMU is precompiled.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"optim = Adam()\nFMIFlux.train!(lossSum, neuralFMU, Iterators.repeated((), 1), optim; cb=()->callb(paramsNet)) ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1]: 0.64142\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.80089\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.5550727972914904   Bias/Offset: 0.0009999999899994582","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Some vectors for collecting data are initialized and the number of runs, epochs and iterations are set.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"solutionAfter = []\nsolutionAfterMod = []\nforces = []\ndisplacements = []\n\nnumRuns = 2\nnumEpochs= 5\nnumIterations = 500;","category":"page"},{"location":"examples/modelica_conference_2021/#Training-loop","page":"Modelica Conference 2021","title":"Training loop","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"The code section shown here represents the training loop. The loop is structured so that it has numRuns runs, where each run has numEpochs epochs, and the training is performed at each epoch with numIterations iterations. In lines 9 and 10, the data for the neuralFMU for the default and modified initial states are appended to the corresponding vectors. The plots for the opposition of position and velocity is done in line 13 by calling the function plot_all_results. In the following lines the last layers are extracted from the neuralFMU and formed into an independent network netBottom. The parameters for the netBottom network come from the original architecture and are shared. In line 20, the new network is used to represent the friction model in a graph. An analogous construction of the next part of the training loop, where here the first layer is taken from the neuralFMU and converted to its own network netTop. This network is used to record the displacement model. The different graphs are generated for each run and can thus be compared. ","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"for run in 1:numRuns\n    @time for epoch in 1:numEpochs\n        @info \"Run: $(run)/$(numRuns)  Epoch: $(epoch)/$(numEpochs)\"\n        FMIFlux.train!(lossSum, neuralFMU, Iterators.repeated((), numIterations), optim; cb=()->callb(paramsNet))\n    end\n    flush(stderr)\n    flush(stdout)\n    \n    push!(solutionAfter, neuralFMU(x₀))\n    push!(solutionAfterMod, neuralFMU(xMod₀))\n\n    # generate all plots for the position and velocity\n    plot_all_results(realSimData, realSimDataMod, simpleSimData, simpleSimDataMod, solutionAfter, solutionAfterMod)\n    \n    # friction model extraction\n    layersBottom = neuralFMU.model.layers[3:5]\n    netBottom = Chain(layersBottom...)\n    transferFlatParams!(netBottom, paramsNet, 7)\n    \n    forces = plot_friction_model(realSimData, netBottom, forces) \n    \n    # displacement model extraction\n    layersTop = neuralFMU.model.layers[1:1]\n    netTop = Chain(layersTop...)\n    transferFlatParams!(netTop, paramsNet, 1)\n\n    displacements = plot_displacement_model(realSimData, netTop, displacements, tSave, displacement)\nend","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 1/2  Epoch: 1/5\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [51]: 0.4549\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.67446\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.6028851231915796   Bias/Offset: 0.04828355559237744\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [101]: 0.39139\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.62561\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.6409646484537395   Bias/Offset: 0.08735806986569811\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [151]: 0.3573\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.59775\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.6705313129361227   Bias/Offset: 0.11919690090163508\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [201]: 0.33753\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.58097\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.6940822733697701   Bias/Offset: 0.14525129042945722\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [251]: 0.32536\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.5704\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7129765067937959   Bias/Offset: 0.16638533597170294\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [301]: 0.31727\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.56327\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7281077846473388   Bias/Offset: 0.1831875951196361\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [351]: 0.31095\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.55763\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7401151851399491   Bias/Offset: 0.1960782926331951\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [401]: 0.30274\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.55022\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7494913134931117   Bias/Offset: 0.20521920138722397\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [451]: 0.28765\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.53633\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7570834667450372   Bias/Offset: 0.21052929458275974\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [501]: 0.23864\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.4885\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.763265511863178   Bias/Offset: 0.2104525425573594\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 1/2  Epoch: 2/5\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [551]: 0.17532\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.41872\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7715631189840524   Bias/Offset: 0.21452810025321914\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [601]: 0.03243\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.18008\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7892922750259234   Bias/Offset: 0.2418465365214229\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [651]: 0.02444\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.15633\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7843537998480821   Bias/Offset: 0.23212888648470248\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [701]: 0.0202\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.14214\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7812826353302379   Bias/Offset: 0.2270946676016098\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [751]: 0.01797\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.13406\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7786916793245329   Bias/Offset: 0.22320060014706938\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [801]: 0.01701\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.13043\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7764426038754145   Bias/Offset: 0.22011561004842548\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [851]: 0.01604\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.12665\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.774628670336757   Bias/Offset: 0.21786511744422063\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [901]: 0.01576\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.12554\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.77318852938423   Bias/Offset: 0.21640112817927337\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [951]: 0.0153\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.12369\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7714837713281952   Bias/Offset: 0.21463330423482357\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1001]: 0.01475\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.12145\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7700020188293136   Bias/Offset: 0.21331499223231953\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 1/2  Epoch: 3/5\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1051]: 0.01455\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.12061\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7685497254265342   Bias/Offset: 0.2122124806873035\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1101]: 0.01452\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.12051\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7669981729441928   Bias/Offset: 0.21100839625459603\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1151]: 0.01399\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.11829\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7654316325868997   Bias/Offset: 0.2097952559688302\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1201]: 0.01369\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.11699\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7640676142228295   Bias/Offset: 0.2089367225997708\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1251]: 0.01349\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.11613\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7623892439002146   Bias/Offset: 0.207704889126865\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1301]: 0.01302\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.11409\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7608489445844248   Bias/Offset: 0.20661321063512564\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1351]: 0.01299\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.11398\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7593526296444657   Bias/Offset: 0.20558804494623992\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1401]: 0.01268\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.11262\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7578600523946859   Bias/Offset: 0.20462035539880227\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1451]: 0.01244\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.11151\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7562913409873459   Bias/Offset: 0.20354570527525187\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1501]: 0.01221\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.11048\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.754751882201362   Bias/Offset: 0.20248144035294505\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 1/2  Epoch: 4/5\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1551]: 0.01186\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.10893\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7531915935667031   Bias/Offset: 0.20135072372724824\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1601]: 0.01185\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.10886\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7516590191436273   Bias/Offset: 0.20019512238496412\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1651]: 0.01135\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.10654\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7502272138927651   Bias/Offset: 0.19913457639766907\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1701]: 0.01123\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.10595\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7488408809165489   Bias/Offset: 0.19809602298355294\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1751]: 0.01107\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.10521\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7474340330215761   Bias/Offset: 0.1970742693169464\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1801]: 0.01091\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.10443\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7460834762628212   Bias/Offset: 0.19610386330970456\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1851]: 0.01113\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.10549\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7447006975022545   Bias/Offset: 0.19513781935264726\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1901]: 0.01032\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.10161\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7432568626833963   Bias/Offset: 0.19380331360344485\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [1951]: 0.01002\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.10012\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7420835755049895   Bias/Offset: 0.19275807347247914\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2001]: 0.00985\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.09922\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.741076801876852   Bias/Offset: 0.19198834681974786\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 1/2  Epoch: 5/5\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2051]: 0.00963\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.09814\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7398698780928032   Bias/Offset: 0.19110322319974019\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2101]: 0.00944\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.09714\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7387364050184646   Bias/Offset: 0.1902584230794854\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2151]: 0.0092\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.09592\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7376537985094141   Bias/Offset: 0.18934912933881343\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2201]: 0.00889\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.09428\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7366777510432025   Bias/Offset: 0.18835661433608997\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2251]: 0.00855\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.09247\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7357906511840346   Bias/Offset: 0.18743648360208276\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2301]: 0.00841\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.0917\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7350464615465715   Bias/Offset: 0.18689924432984248\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2351]: 0.00812\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.09013\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7339969121110451   Bias/Offset: 0.18612124222507648\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2401]: 0.00793\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.08908\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7326717516638203   Bias/Offset: 0.1851036885505445\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2451]: 0.00753\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.08677\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7316912283399576   Bias/Offset: 0.18440136814990418\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2501]: 0.0073\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.08546\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7306344356827853   Bias/Offset: 0.1837703778691197\n\n\n682.588271 seconds (3.21 G allocations: 152.365 GiB, 3.18% gc time, 0.02% compilation time)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFriction model 1 mse: 15.12669966211756","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 2/2  Epoch: 1/5\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2551]: 0.0066\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.08122\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7294722625067702   Bias/Offset: 0.18293225499668095\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2601]: 0.00603\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.07767\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7287466673253917   Bias/Offset: 0.18225209958887134\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2651]: 0.0052\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.07213\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7287485382586419   Bias/Offset: 0.18182518699673822\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2701]: 0.0055\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.07418\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7303833567220868   Bias/Offset: 0.1825839482615801\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2751]: 0.00366\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.06053\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7323123677078334   Bias/Offset: 0.18358269036117894\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2801]: 0.00338\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.05815\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7343381283573703   Bias/Offset: 0.185258715292315\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2851]: 0.00303\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.05508\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7357657911860008   Bias/Offset: 0.18671734475678212\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2901]: 0.00282\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.05313\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7366622322683765   Bias/Offset: 0.1879260940466228\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [2951]: 0.00256\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.05059\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.737421537531958   Bias/Offset: 0.18924429261110745\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3001]: 0.00253\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.05026\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7380334506224158   Bias/Offset: 0.19047329704402016\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 2/2  Epoch: 2/5\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3051]: 0.00239\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.04888\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7385903595946945   Bias/Offset: 0.1917115498635097\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3101]: 0.0023\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.04795\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7390400912707692   Bias/Offset: 0.19291638530884084\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3151]: 0.00221\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.047\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7393522712352036   Bias/Offset: 0.19396778704456763\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3201]: 0.00208\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.04556\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.739587683661609   Bias/Offset: 0.19499576904301963\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3251]: 0.00192\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.04385\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7397489875943187   Bias/Offset: 0.1958994492662145\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3301]: 0.00182\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.04269\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7399296146171744   Bias/Offset: 0.19683965719681404\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3351]: 0.00166\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.04075\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7400502417505842   Bias/Offset: 0.1976832990758858\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3401]: 0.00163\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.04041\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.740239652566954   Bias/Offset: 0.19866305352151065\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3451]: 0.0017\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.04122\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7401438188882128   Bias/Offset: 0.19926984912385387\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3501]: 0.0015\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.03874\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.740137231197973   Bias/Offset: 0.1999925148736434\n\n\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 2/2  Epoch: 3/5\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3551]: 0.00136\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.03686\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7400907075538734   Bias/Offset: 0.20068189455069224\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3601]: 0.0013\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.03601\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.740058838515693   Bias/Offset: 0.20139228434198345\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3651]: 0.00122\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.03493\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7398959381755673   Bias/Offset: 0.20195059329011372\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3701]: 0.00118\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.03433\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7398924125748179   Bias/Offset: 0.20268393178184924\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3751]: 0.00116\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.03402\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7397913844781383   Bias/Offset: 0.203332075636317\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3801]: 0.00106\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.03255\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7396309459970485   Bias/Offset: 0.20382819668032928\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3851]: 0.00095\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.03088\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7396012149387735   Bias/Offset: 0.2044014248812001\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3901]: 0.00098\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.0313\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7395948430627212   Bias/Offset: 0.20518920029356646\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [3951]: 0.00092\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.0303\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7393542186212828   Bias/Offset: 0.20567073983842699\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4001]: 0.00086\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02939\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7391909099704085   Bias/Offset: 0.20620592991292247\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 2/2  Epoch: 4/5\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4051]: 0.00081\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02854\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7390344904609177   Bias/Offset: 0.20674164449484883\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4101]: 0.00077\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02772\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7388752088174673   Bias/Offset: 0.2072692342280151\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4151]: 0.00072\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02692\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.738712359127193   Bias/Offset: 0.20778760743744454\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4201]: 0.00069\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.0262\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7385363679767349   Bias/Offset: 0.20829650267069688\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4251]: 0.00066\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02563\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7383110581204325   Bias/Offset: 0.20876674662687583\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4301]: 0.00063\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02507\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7380051515299417   Bias/Offset: 0.20914647283901172\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4351]: 0.0006\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02446\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.737664753581302   Bias/Offset: 0.20946736221048162\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4401]: 0.00057\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02386\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.737376150570386   Bias/Offset: 0.20982938021780786\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4451]: 0.00054\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02334\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7370976076274813   Bias/Offset: 0.2101992388385606\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4501]: 0.00052\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02288\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7368127112735554   Bias/Offset: 0.21055998225998276\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRun: 2/2  Epoch: 5/5\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4551]: 0.0005\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02245\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.736520335517526   Bias/Offset: 0.210909552638306\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4601]: 0.00049\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02207\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.736220452975838   Bias/Offset: 0.21124808798443512\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4651]: 0.00047\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02171\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7359126614179736   Bias/Offset: 0.21157621322181722\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4701]: 0.00046\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02149\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7355541140435535   Bias/Offset: 0.2118660594115363\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4751]: 0.00045\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02118\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7352039117175605   Bias/Offset: 0.21214610810577803\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4801]: 0.00044\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02092\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7348672952023434   Bias/Offset: 0.21243023710944609\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4851]: 0.00043\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.0207\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7345252753127329   Bias/Offset: 0.21270565190806262\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4901]: 0.00042\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02053\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7341736844966333   Bias/Offset: 0.21296686384675304\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [4951]: 0.00042\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02041\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.733809832998747   Bias/Offset: 0.21320809663231943\n\n\n\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  Loss [5001]: 0.00042\n\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m        Avg displacement in data: 0.02047\n\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m        Weight/Scale: 0.7334373221851284   Bias/Offset: 0.2134380135556462\n\n\n686.023646 seconds (3.25 G allocations: 153.002 GiB, 3.21% gc time)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFriction model 1 mse: 15.12669966211756\n\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFriction model 2 mse: 18.507130141703147","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"(Image: svg)","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Finally, the FMU is cleaned-up.","category":"page"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"fmiUnload(simpleFMU)","category":"page"},{"location":"examples/modelica_conference_2021/#Summary","page":"Modelica Conference 2021","title":"Summary","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"Based on the plots, it can be seen that the curves of the realFMU and the neuralFMU are very close. The neuralFMU is able to learn the friction and displacement model.","category":"page"},{"location":"examples/modelica_conference_2021/#Source","page":"Modelica Conference 2021","title":"Source","text":"","category":"section"},{"location":"examples/modelica_conference_2021/","page":"Modelica Conference 2021","title":"Modelica Conference 2021","text":"[1] Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. NeuralFMU: towards structural integration of FMUs into neural networks. Martin Sjölund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, Linköping, Sweden, September 20-24, 2021. Linköping University Electronic Press, Linköping (Linköping Electronic Conference Proceedings ; 181), 297-306. DOI: 10.3384/ecp21181297","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: FMIFlux.jl Logo)","category":"page"},{"location":"#FMIFlux.jl","page":"Introduction","title":"FMIFlux.jl","text":"","category":"section"},{"location":"#What-is-FMIFlux.jl?","page":"Introduction","title":"What is FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"FMIFlux.jl is a free-to-use software library for the Julia programming language, which offers the ability to simply place your FMU (fmi-standard.org) everywhere inside of your ML topologies and still keep the resulting models trainable with a standard (or custom) FluxML training process. This includes for example:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"NeuralODEs including FMUs, so called Neural Functional Mock-up Units (NeuralFMUs): ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"You can place FMUs inside of your ML topology.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"PINNs including FMUs, so called Functional Mock-Up Unit informed Neural Networks (FMUINNs): ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"You can evaluate FMUs inside of your loss function. ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: Dev Docs)  (Image: Test (latest)) (Image: Test (LTS)) (Image: Examples) (Image: Build Docs) (Image: Run PkgEval) (Image: Coverage) (Image: ColPrac: Contributor's Guide on Collaborative Practices for Community Packages) (Image: FMIFlux Downloads)","category":"page"},{"location":"#How-can-I-use-FMIFlux.jl?","page":"Introduction","title":"How can I use FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"1. Open a Julia-REPL, switch to package mode using ], activate your preferred environment.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"2. Install  FMIFlux.jl:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(@v1) pkg> add FMIFlux","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"3. If you want to check that everything works correctly, you can run the tests bundled with FMIFlux.jl:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(@v1) pkg> test FMIFlux","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"4. Have a look inside the examples folder in the examples branch or the examples section of the documentation. All examples are available as Julia-Script (.jl), Jupyter-Notebook (.ipynb) and Markdown (.md).","category":"page"},{"location":"#What-is-currently-supported-in-FMIFlux.jl?","page":"Introduction","title":"What is currently supported in FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"building and training ME-NeuralFMUs (NeuralODEs) with support for event-handling (DiffEqCallbacks.jl) and discontinuous sensitivity analysis (SciMLSensitivity.jl)\nbuilding and training CS-NeuralFMUs \nbuilding and training NeuralFMUs consisiting of multiple FMUs\nbuilding and training FMUINNs (PINNs)\ndifferent AD-frameworks: ForwardDiff.jl (CI-tested), ReverseDiff.jl (CI-tested, default setting), FiniteDiff.jl (not CI-tested) and Zygote.jl (not CI-tested)\nuse Flux.jl optimisers as well as the ones from Optim.jl\nusing the entire DifferentialEquations.jl solver suite (autodiff=false for implicit solvers)\n...","category":"page"},{"location":"#(Current)-Limitations","page":"Introduction","title":"(Current) Limitations","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Sensitivity information over state change by event partial x^+  partial x^- can't be accessed in FMI. ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"These sensitivities are simplified on basis of one of the following assumptions (defined by user): (1) the state after event depends on nothing, so sensitivities are zero or  (2) the state after event instance only depends on the same state before the event instance The second is often correct for e.g. mechanical contacts, but may lead to wrong gradients for arbitrary discontinuous systems.  However even if the gradient might not be 100% correct in any case, gradients are often usable for optimization tasks.  This issue is also part of the OpenScaling research project.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Discontinuous systems with implicite solvers use continuous adjoints instead of automatic differentiation through the ODE solver.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"This might lead to issues, because FMUs are by design not simulatable backward in time.  On the other hand, many FMUs are capabale of doing so. This issue is also part of the OpenScaling research project.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Implicit solvers using autodiff=true is not supported (now), but you can use implicit solvers with autodiff=false.\nFor now, only FMI version 2.0 is supported, but FMI 3.0 support is coming with the OpenScaling research project.","category":"page"},{"location":"#What-is-under-development-in-FMIFlux.jl?","page":"Introduction","title":"What is under development in FMIFlux.jl?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"performance optimizations\nmulti threaded CPU training\nimproved documentation\nmore examples\nFMI3 integration\n...","category":"page"},{"location":"#What-Platforms-are-supported?","page":"Introduction","title":"What Platforms are supported?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"FMIFlux.jl is tested (and testing) under Julia versions v1.6 (LTS) and v1 (latest) on Windows (latest) and Ubuntu (latest). MacOS should work, but untested. All shipped examples are automatically tested under Julia version v1 (latest) on Windows (latest).","category":"page"},{"location":"#What-FMI.jl-Library-should-I-use?","page":"Introduction","title":"What FMI.jl-Library should I use?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: FMI.jl Family) To keep dependencies nice and clean, the original package FMI.jl had been split into new packages:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"FMI.jl: High level loading, manipulating, saving or building entire FMUs from scratch\nFMIImport.jl: Importing FMUs into Julia\nFMIExport.jl: Exporting stand-alone FMUs from Julia Code\nFMICore.jl: C-code wrapper for the FMI-standard\nFMISensitivity.jl: Static and dynamic sensitivities over FMUs\nFMIBuild.jl: Compiler/Compilation dependencies for FMIExport.jl\nFMIFlux.jl: Machine Learning with FMUs (differentiation over FMUs)\nFMIZoo.jl: A collection of testing and example FMUs","category":"page"},{"location":"#How-to-cite?","page":"Introduction","title":"How to cite?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Tobias Thummerer, Johannes Stoljar and Lars Mikelsons. 2022. NeuralFMU: presenting a workflow for integrating hybrid NeuralODEs into real-world applications. Electronics 11, 19, 3202. DOI: 10.3390/electronics11193202","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Tobias Thummerer, Lars Mikelsons and Josef Kircher. 2021. NeuralFMU: towards structural integration of FMUs into neural networks. Martin Sjölund, Lena Buffoni, Adrian Pop and Lennart Ochel (Ed.). Proceedings of 14th Modelica Conference 2021, Linköping, Sweden, September 20-24, 2021. Linköping University Electronic Press, Linköping (Linköping Electronic Conference Proceedings ; 181), 297-306. DOI: 10.3384/ecp21181297","category":"page"},{"location":"#Related-publications?","page":"Introduction","title":"Related publications?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Tobias Thummerer, Johannes Tintenherr, Lars Mikelsons 2021. Hybrid modeling of the human cardiovascular system using NeuralFMUs Journal of Physics: Conference Series 2090, 1, 012155. DOI: 10.1088/1742-6596/2090/1/012155","category":"page"}]
}
