{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NeuralODEs in real life applications\n",
    "-----\n",
    "Tutorial by Tobias Thummerer | Last edit: 07-21-2023\n",
    "\n",
    "This workshop was held at the JuliaCon 2023 | 07-25-2023 | MIT (Boston, USA)\n",
    "\n",
    "Keywords: *#NeuralODE, #NeuralFMU, #PeNODE, #HybridModeling*\n",
    "\n",
    "## Introduction\n",
    "NeuralODEs lead to amazing results in academic examples. But the expectations are often being disappointed as soon as one tries to adapt this concept for real life use cases. Bad convergence behavior, handling of discontinuities and/or instabilities are just some of the stumbling blocks that might pop up during the first steps. During the workshop, we want to show how to integrate real life industrial models in NeuralODEs using FMI and present sophisticated training strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023 Tobias Thummerer, Lars Mikelsons\n",
    "# Licensed under the MIT license. \n",
    "# See LICENSE (https://github.com/thummeto/FMIFlux.jl/blob/main/LICENSE) file in the project root for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional libraries\n",
    "using FMI           # import FMUs into Julia \n",
    "using FMIFlux       # build NeuralFMUs\n",
    "using FMIZoo        # a collection of demo models, including the VLDM\n",
    "using FMIFlux.Flux  # Machine Learning in Julia\n",
    "\n",
    "# saving/loading\n",
    "using JLD2          # data format for saving/loading parameters\n",
    "\n",
    "# plotting\n",
    "using Plots         # default plotting framework\n",
    "import PlotlyJS     # interactive plotting\n",
    "Plots.plotlyjs()    # actiavte PlotlyJS as default plotting backend\n",
    "\n",
    "# Let's fix the random seed to make our program determinsitic (ANN layers are initialized indeterminsitic otherwise)\n",
    "import Random \n",
    "Random.seed!(1234)\n",
    "\n",
    "# a helper file with some predefined functions to make \"things look nicer\", but are not really relevant to the topic\n",
    "include(joinpath(@__DIR__, \"workshop_helpers.jl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading FMU & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our FMU (we take one from the FMIZoo.jl, exported with Dymola 2022x)\n",
    "fmu = fmiLoad(\"VLDM\", \"Dymola\", \"2020x\"; type=:ME, logLevel=:info)  # \"Log everything that might be interesting!\", default is `:warn`\n",
    "\n",
    "# let's have a look on the model meta data\n",
    "fmiInfo(fmu)\n",
    "\n",
    "# load data from FMIZoo.jl, gather simulation parameters for FMU\n",
    "data = FMIZoo.VLDM(:train) \n",
    "tStart = data.consumption_t[1]\n",
    "tStop = data.consumption_t[end]\n",
    "tSave = data.consumption_t\n",
    "\n",
    "# have a look on the FMU parameters (these are the file paths to the characteristic maps)\n",
    "display(data.params)\n",
    "\n",
    "# let's run a simulation from `tStart` to `tStop`, use the parameters we just viewed for the simulation run\n",
    "resultFMU = fmiSimulate(fmu, (tStart, tStop); parameters=data.params)\n",
    "display(resultFMU)\n",
    "\n",
    "fig = plot(resultFMU)                                                                        # Plot it, but this is a bit too much, so ...\n",
    "fig = plot(resultFMU; stateIndices=6:6)                                                      # ... only plot the state #6 and ...\n",
    "fig = plot(resultFMU; stateIndices=6:6, ylabel=\"Cumulative consumption [Ws]\", label=\"FMU\")   # ... add some helpful labels!\n",
    "\n",
    "# further plot the (measurement) data values `consumption_val` and deviation between measurements `consumption_dev`\n",
    "plot!(fig, data.cumconsumption_t, data.cumconsumption_val; label=\"Data\", ribbon=data.cumconsumption_dev, fillalpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NeuralFMU setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable we want to manipulate - why we are picking exactly these three is shown a few lines later ;-)\n",
    "manipulatedDerVars = [\"der(dynamics.accelerationCalculation.integrator.y)\",\n",
    "                      \"der(dynamics.accelerationCalculation.limIntegrator.y)\",\n",
    "                      \"der(result.integrator.y)\"]\n",
    "# alternative: manipulatedDerVars = fmu.modelDescription.derivativeValueReferences[4:6]\n",
    "\n",
    "# reference simulation to record the derivatives \n",
    "resultFMU = fmiSimulate(fmu, (tStart, tStop), parameters=data.params, recordValues=:derivatives, recordEigenvalues=true, saveat=tSave) \n",
    "manipulatedDerVals = fmiGetSolutionValue(resultFMU, manipulatedDerVars)\n",
    "\n",
    "# what happens without propper transformation between FMU- and ANN-domain?\n",
    "plot(resultFMU.values.t, manipulatedDerVals[1,:][1]; label=\"vehicle velocity\");\n",
    "plot!(resultFMU.values.t, tanh.(manipulatedDerVals[1,:][1]); label=\"tanh(velocity)\")\n",
    "\n",
    "# setup shift/scale layers for pre-processing\n",
    "preProcess = ShiftScale(manipulatedDerVals)\n",
    "\n",
    "# check what it's doing now ...\n",
    "testVals = collect(preProcess(collect(val[t] for val in manipulatedDerVals))[1] for t in 1:length(resultFMU.values.t))\n",
    "plot(resultFMU.values.t, testVals; label=\"velocity (pre-processed)\");\n",
    "plot!(resultFMU.values.t, tanh.(testVals); label=\"tanh(velocity)\")\n",
    "\n",
    "# add some additional \"buffer\"\n",
    "preProcess.scale[:] *= 0.25 \n",
    "\n",
    "# and check again what it's doing now ...\n",
    "testVals = collect(preProcess(collect(val[t] for val in manipulatedDerVals))[1] for t in 1:length(resultFMU.values.t))\n",
    "plot(resultFMU.values.t, testVals; label=\"velocity (pre-processed)\");\n",
    "plot!(resultFMU.values.t, tanh.(testVals); label=\"tanh(velocity)\")\n",
    "\n",
    "# ... also check the consumption\n",
    "testVals = collect(preProcess(collect(val[t] for val in manipulatedDerVals))[3] for t in 1:length(resultFMU.values.t))\n",
    "plot(resultFMU.values.t, testVals; label=\"vehicle consumption (pre-processed)\");\n",
    "plot!(resultFMU.values.t, tanh.(testVals); label=\"tanh(consumption)\")\n",
    "\n",
    "# setup scale/shift layer (inverse transformation) for post-processing\n",
    "# we don't an inverse transform for the entire preProcess, only for the 2nd element (acceleration)\n",
    "postProcess = ScaleShift(preProcess; indices=2:3) \n",
    "\n",
    "# setup cache layers \n",
    "cache = CacheLayer()\n",
    "cacheRetrieve = CacheRetrieveLayer(cache)\n",
    "\n",
    "gates = ScaleSum([1.0, 1.0, 0.0, 0.0], [[1,3], [2,4]]) # signal from FMU (#1 = 1.0), signal from ANN (#2 = 0.0)\n",
    "\n",
    "# setup the NeuralFMU topology\n",
    "net = Chain(x -> fmu(; x=x),                    # take `x`, put it into the FMU, retrieve `dx`\n",
    "            dx -> cache(dx),                    # cache `dx`\n",
    "            dx -> dx[4:6],                      # forward only dx[4, 5, 6]\n",
    "            preProcess,                         # pre-process `dx`\n",
    "            Dense(3, 32, tanh),                 # Dense Layer 3 -> 32 with `tanh` activasion\n",
    "            Dense(32, 2, tanh),                 # Dense Layer 32 -> 2 with `tanh` activasion \n",
    "            postProcess,                        # post process `dx`\n",
    "            dx -> cacheRetrieve(5:6, dx),       # dynamics FMU | dynamics ANN\n",
    "            gates,                              # compute resulting dx from ANN + FMU\n",
    "            dx -> cacheRetrieve(1:4, dx))       # stack together: dx[1,2,3,4] from cache + dx[5:6] from ANN\n",
    "\n",
    "# build NeuralFMU\n",
    "neuralFMU = ME_NeuralFMU(fmu, net, (tStart, tStop); saveat=tSave)\n",
    "neuralFMU.modifiedState = false # speed optimization (no ANN before the FMU)\n",
    "\n",
    "# get start state vector from data (FMIZoo)\n",
    "x0 = FMIZoo.getStateVector(data, tStart)\n",
    "\n",
    "########\n",
    "\n",
    "# simulate and plot the (uninitialized) NeuralFMU\n",
    "resultNFMU_original = neuralFMU(x0, (tStart, tStop); parameters=data.params, showProgress=true) \n",
    "display(resultNFMU_original)\n",
    "\n",
    "fig = plot(resultNFMU_original; stateIndices=5:5, label=\"NeuralFMU (original)\", ylabel=\"velocity [m/s]\")\n",
    "\n",
    "# plot the original FMU and data\n",
    "plot!(fig, resultFMU; stateIndices=5:5, values=false, stateEvents=false)\n",
    "plot!(fig, data.speed_t, data.speed_val, label=\"Data\")\n",
    "\n",
    "fig = plot(resultNFMU_original; stateIndices=6:6, stateEvents=false, timeEvents=false, label=\"NeuralFMU (original)\", ylabel=\"velocity [m/s]\")\n",
    "plot!(fig, resultFMU; stateIndices=6:6, values=false, stateEvents=false, timeEvents=false, label=\"FMU\")\n",
    "plot!(fig, data.cumconsumption_t, data.cumconsumption_val, label=\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the NeuralFMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data (array of arrays required)\n",
    "train_data = collect([d] for d in data.cumconsumption_val)\n",
    "train_t = data.consumption_t \n",
    "\n",
    "# switch to a more efficient execution configuration, allocate only a single FMU instance, see:\n",
    "# https://thummeto.github.io/FMI.jl/dev/features/#Execution-Configuration\n",
    "fmu.executionConfig = FMI.FMIImport.FMU2_EXECUTION_CONFIGURATION_NOTHING\n",
    "c, _ = FMIFlux.prepareSolveFMU(neuralFMU.fmu, nothing, neuralFMU.fmu.type, true, false, false, false, true, data.params; x0=x0)\n",
    "\n",
    "# batch the data (time, targets), train only on model output index 6, plot batch elements\n",
    "batch = batchDataSolution(neuralFMU, t -> FMIZoo.getStateVector(data, t), train_t, train_data;\n",
    "    batchDuration=BATCHDUR, indicesModel=6:6, plot=false, parameters=data.params, recordEigenvalues=true, recordEigenvaluesSensitivity=:ForwardDiff, showProgress=true) # try `plot=true` to show the batch elements, try `showProgress=true` to display simulation progress\n",
    "\n",
    "# limit the maximum number of solver steps to 1e5 and maximum simulation/training duration to 30s\n",
    "solverKwargsTrain = Dict{Symbol, Any}(:maxiters => round(Int, 100*BATCHDUR*10), :dtmin => 1e-128) # , :dtmin => 1e-6) # , :max_execution_duration => 60.0)\n",
    "# for dt=10.0s, this equals 10 000 steps per second and \n",
    "\n",
    "cumconsumption_scale = 1.0 / (max(data.cumconsumption_val...)-min(data.cumconsumption_val...))\n",
    "min_eig = min(collect(min(resultFMU.eigenvalues.saveval[i]...) for i in 2:length(resultFMU.eigenvalues.saveval))...)\n",
    "allowedStiffness = (min_eig, 0.0)\n",
    "function lossFct(solution::FMI.FMU2Solution, _data=data, _LOSS=LOSS, _EIGENLOSS=EIGENLOSS, _STIFFNESSRATIO=STIFFNESSRATIO)\n",
    "\n",
    "    if !solution.success\n",
    "        return [Inf]\n",
    "    end\n",
    "\n",
    "    #speeds = fmiGetSolutionState(solution, 5; isIndex=true)\n",
    "    cumconsumption = fmiGetSolutionState(solution, 6; isIndex=true)\n",
    "\n",
    "    dt = 0.1\n",
    "\n",
    "    ts = 1+round(Int, solution.states.t[1]/dt)\n",
    "    te = 1+round(Int, solution.states.t[end]/dt)\n",
    "    num = te-ts+1\n",
    "\n",
    "    target_cumconsumption = _data.cumconsumption_val[ts:te]\n",
    "\n",
    "    Δcumconsumption = abs.(target_cumconsumption .- cumconsumption)\n",
    "    Δcumconsumption -= _data.cumconsumption_dev[ts:te]\n",
    "    Δcumconsumption = collect(max(cumconsumption, 0.0) for cumconsumption in Δcumconsumption)\n",
    "\n",
    "    if _LOSS == :MAE\n",
    "        Δcumconsumption = sum(Δcumconsumption) / num\n",
    "    elseif _LOSS == :MSE\n",
    "        Δcumconsumption = sum(Δcumconsumption .^ 2) / num\n",
    "    else\n",
    "        @assert false, \"unknown LOSS\"\n",
    "    end\n",
    "\n",
    "    eigen_loss = nothing\n",
    "    if _EIGENLOSS == :MAE\n",
    "        eigen_loss = FMIFlux.Losses.stiffness_corridor(solution, _STIFFNESSRATIO .* allowedStiffness; lossFct=Flux.Losses.mae)\n",
    "    elseif _EIGENLOSS == :MSE\n",
    "        eigen_loss = FMIFlux.Losses.stiffness_corridor(solution, _STIFFNESSRATIO .* allowedStiffness; lossFct=Flux.Losses.mse)\n",
    "    elseif _EIGENLOSS == :OFF\n",
    "        eigenLoss = 0.0\n",
    "    else\n",
    "        @assert false, \"unknown EIGEN LOSS: $(_EIGEN_LOSS)\"\n",
    "    end\n",
    "    \n",
    "    if _EIGENLOSS == :OFF\n",
    "        return [Δcumconsumption * cumconsumption_scale]\n",
    "    else\n",
    "        return [Δcumconsumption * cumconsumption_scale, eigen_loss]\n",
    "    end\n",
    "end\n",
    "\n",
    "# initialize a \"worst error growth scheduler\" (updates all batch losses, pick the batch element with largest error increase)\n",
    "# apply the scheduler after every training step, plot the current status every 25 steps and update all batch element losses every 5 steps\n",
    "#scheduler = LossAccumulationScheduler(neuralFMU, batch, lossFct; applyStep=1, plotStep=1, updateStep=1)\n",
    "scheduler = nothing\n",
    "if SCHEDULER == :Random\n",
    "    scheduler = RandomScheduler(neuralFMU, batch; applyStep=1, plotStep=1)\n",
    "elseif SCHEDULER == :Sequential\n",
    "    scheduler = SequentialScheduler(neuralFMU, batch; applyStep=1, plotStep=1)\n",
    "elseif SCHEDULER == :LossAccumulation\n",
    "    scheduler = LossAccumulationScheduler(neuralFMU, batch, lossFct; applyStep=1, plotStep=1, updateStep=5)\n",
    "else\n",
    "    @assert false, \"unknown SCHEDULER\"\n",
    "end\n",
    "updateScheduler = () -> update!(scheduler)\n",
    "\n",
    "# defines a loss for the entire batch (accumulate error of batch elements)\n",
    "batch_loss = p -> FMIFlux.Losses.batch_loss(neuralFMU, batch; \n",
    "    showProgress=true, p=p, parameters=data.params, recordEigenvalues=true, update=true, lossFct=lossFct, logLoss=true, solverKwargsTrain...) # try `showProgress=true` to display simulation progress\n",
    "\n",
    "# loss for training, take element from the worst element scheduler\n",
    "loss = p -> FMIFlux.Losses.loss(neuralFMU, batch; \n",
    "    showProgress=true, p=p, parameters=data.params, recordEigenvalues=true, recordEigenvaluesSensitivity=:ForwardDiff, lossFct=lossFct, batchIndex=scheduler.elementIndex, logLoss=true, solverKwargsTrain...) # try `showProgress=true` to display simulation progress\n",
    "\n",
    "# gather the parameters from the NeuralFMU\n",
    "_params = FMIFlux.params(neuralFMU)\n",
    "\n",
    "# let's check the loss we are starting with ...\n",
    "loss_before = batch_loss(_params[1])\n",
    "checkLoss(true)\n",
    "\n",
    "batchLen = length(batch)\n",
    "\n",
    "# initialize the scheduler \n",
    "Random.seed!(1234)\n",
    "initialize!(scheduler; parameters=data.params, p=_params[1], showProgress=false)\n",
    "\n",
    "function gateCallback()\n",
    "    @info \"\\nAcc. FMU-Gate: $(round(_params[1][end-3]*100; digits=2))% | ANN-Gate: $(round(_params[1][end-1]*100; digits=2))%\\n\" * \n",
    "            \"Con. FMU-Gate: $(round(_params[1][end-2]*100; digits=2))% | ANN-Gate: $(round(_params[1][end  ]*100; digits=2))%\"\n",
    "end\n",
    "\n",
    "optim = Adam(ETA, (BETA1, BETA2))\n",
    "\n",
    "# we use ForwardDiff for gradinet determination, because the FMU throws multiple events per time instant (this is not supported by reverse mode AD)\n",
    "# the chunk_size controls the nuber of forward evaluations of the model (the bigger, the less evaluations)\n",
    "FMIFlux.train!(loss, _params, Iterators.repeated((), TRAINSTEPS), optim; gradient=:ForwardDiff, chunk_size=32, cb=[updateScheduler, gateCallback], multiObjective=true, proceed_on_assert=true) \n",
    "loss_after = batch_loss(_params[1])\n",
    "checkLoss(true)\n",
    "checkLoss(true;cycle=:test)\n",
    "\n",
    "# save the parameters (so we can use them tomorrow again)\n",
    "# paramsPath = joinpath(@__DIR__, \"params_$(scheduler.step)steps.jld2\")\n",
    "# fmiSaveParameters(neuralFMU, paramsPath)\n",
    "\n",
    "# switch back to the default execution configuration, see:\n",
    "# https://thummeto.github.io/FMI.jl/dev/features/#Execution-Configuration\n",
    "fmu.executionConfig = FMI.FMIImport.FMU2_EXECUTION_CONFIGURATION_NO_RESET\n",
    "FMIFlux.finishSolveFMU(neuralFMU.fmu, c, false, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "Unload the FMU and release the linked binaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean-up\n",
    "fmiUnload(fmu) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
